\documentclass[12pt]{scrartcl}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{ wasysym }
\usepackage{accents}
\usepackage{extpfeil}
\usepackage{graphicx}
\usepackage{scalerel}
\usepackage[dvipsnames]{xcolor}
\usepackage[a4paper,top=5mm, bottom=5mm, left=10mm, right=2mm]{geometry}
%Markup
\newcommand{\TYPE}[1]{\textcolor{NavyBlue}{\mathtt{#1}}}
\newcommand{\FUNC}[1]{\textcolor{Cerulean}{\mathtt{#1}}}
\newcommand{\LOGIC}[1]{\textcolor{Blue}{\mathtt{#1}}}
\newcommand{\THM}[1]{\textcolor{Maroon}{\mathtt{#1}}}
%META
\renewcommand{\.}{\; . \;}
\newcommand{\de}{: \kern 0.1pc =}
\newcommand{\where}{\LOGIC{where}}
\newcommand{\If}{\LOGIC{if} \;}
\newcommand{\Then}{ \; \LOGIC{then} \;}
\newcommand{\Else}{\; \LOGIC{else} \;}
\newcommand{\Act}[1]{\left( #1 \right)}
\newcommand{\Theorem}[2]{& \THM{#1} \, :: \, #2 \\ & \Proof = \\ } 
\newcommand{\DeclareType}[2]{& \TYPE{#1} \, :: \, #2 \\} 
\newcommand{\DefineType}[3]{& #1 : \TYPE{#2} \iff #3 \\} 
\newcommand{\DefineNamedType}[4]{& #1 : \TYPE{#2} \iff #3 \iff #4 \\} 
\newcommand{\DeclareFunc}[2]{& \FUNC{#1} \, :: \, #2 \\}  
\newcommand{\DefineFunc}[3]{&  \FUNC{#1}\Act{#2} \de #3 \\} 
\newcommand{\DefineNamedFunc}[4]{&  \FUNC{#1}\Act{#2} = #3 \de #4 \\} 
\newcommand{\NewLine}{\\ & \kern 1pc}
\newcommand{\Page}[1]{ \begin{align*} #1 \end{align*}   }
\newcommand{ \bd }{ \ByDef }
\newcommand{\NoProof}{ & \ldots \\ \EndProof}
\newcommand{\Explain}[1]{& \text{#1.} \\}
\newcommand{\ExplainFurther}[1]{& \text{#1} \\}
\newcommand{\Exclaim}[1]{& \text{#1!} \\}
%LOGIC
\renewcommand{\And}{\; \& \;}
\newcommand{\ForEach}[3]{\forall #1 : #2 \. #3 }
\newcommand{\Exist}[2]{\exists #1 : #2}
\newcommand{\Imply}{\Rightarrow} 
%TYPE THEORY
\newcommand{\DFunc}[3]{\prod #1 : #2 \. #3 }
\newcommand{\DPair}[3]{\sum #1 : #2 \. #3}
\newcommand{\Type}{\TYPE{Type}}
\newcommand{\Class}{\TYPE{Kind}}
%%STD
\newcommand{\Int}{\mathbb{Z} }
\newcommand{\NNInt}{\mathbb{Z}_{+} }
\newcommand{\Reals}{\mathbb{R} }
\newcommand{\Complex}{\mathbb{C}}
\renewcommand{\Re}{\mathrm{Re}\;}
\renewcommand{\Im}{\mathrm{Im}\;}
\newcommand{\Rats}{\mathbb{Q} }
\newcommand{\Nat}{\mathbb{N} }
\newcommand{\EReals}{\stackrel{\mathclap{\infty}}{\mathbb{R}}}
\newcommand{\ERealsn}[1]{\stackrel{\mathclap{\infty}}{\mathbb{R}}^{#1}}
\DeclareMathOperator*{\centr}{center}
\DeclareMathOperator*{\argmin}{arg\,min}
\renewcommand{\i}{\mathrm{i}}
%%Set Theory
\DeclareMathOperator*{\id}{id}
\DeclareMathOperator*{\im}{Im}
\DeclareMathOperator*{\supp}{supp}
\newcommand{\Eq}{\TYPE{Equivalence}}
\newcommand{\EqClass}[1]{\TYPE{EquivalenceClass}\left( #1 \right)}
\newcommand{\End}{\mathrm{End}}
\newcommand{\Aut}{\mathrm{Aut}}
\newcommand{\Func}[2]{\TYPE{Functor}\left( #1, #2 \right)}
\mathchardef\hyph="2D
\newcommand{\Surj}{\TYPE{Surjective}}
\newcommand{\Inj}{\TYPE{Injective}}
\newcommand{\ToInj}{\hookrightarrow}
\newcommand{\ToMono}{\xhookrightarrow}
\newcommand{\ToSurj}{\twoheadrightarrow}
\newcommand{\ToEpi}{\xtwoheadrightarrow}
\newcommand{\ToBij}{\leftrightarrow}
\newcommand{\ToIso}{\xleftrightarrow}
\newcommand{\Arrow}{\xrightarrow}
\newcommand{\Set}{\TYPE{Set}}
\newcommand{\Ideal}{\TYPE{Ideal}}
\newcommand{\du}{\; \triangle \;}
\newcommand{\Finites}{\TYPE{FiniteSubset}}
\newcommand{\Countables}{\TYPE{CountableSubset}}
\renewcommand{\c}{\complement}
\newcommand{\Cover}{\TYPE{Cover}}
\newcommand{\Ultrafilter}{\TYPE{Ultrafilter}}
\newcommand{\Finite}{\TYPE{Finite}}
\newcommand{\SA}{\TYPE{\sigma \hyph Algebra}}
%%ProofWritting
\newcommand{\Say}[3]{& #1 \de #2 : #3, \\}
\newcommand{\SayIn}[3]{& #1 \de #2 \in #3, \\}
\newcommand{\Conclude}[3]{& #1 \de #2 : #3; \\}
\newcommand{\ConcludeIn}[3]{& #1 \de #2 \in #3; \\}
\newcommand{\Derive}[3]{& \leadsto #1 \de #2 : #3, \\}
\newcommand{\DeriveIn}[3]{& \leadsto #1 \de #2 \in #3, \\}
\newcommand{\DeriveConclude}[3]{& \leadsto #1 \de #2 : #3 ; \\} 
\newcommand{\DeriveConcludeIn}[3]{& \leadsto #1 \de #2 \in #3 ; \\} 
\newcommand{\Assume}[2]{& \LOGIC{Assume} \; #1 : #2, \\}
\newcommand{\AssumeIn}[2]{& \LOGIC{Assume} \; #1 \in #2, \\}
\newcommand{\As}{\; \LOGIC{as } \;} 
\newcommand{\Intro}{\LOGIC{I}}
\newcommand{\Elim}{\LOGIC{E}}
\newcommand{\QED}{\; \square}
\newcommand{\EndProof}{& \QED \\}
\newcommand{\ByDef}{\eth} 
\newcommand{\ByConstr}{\jmath}  
\newcommand{\Alt}{\LOGIC{Alternative} \;}
\newcommand{\CL}{\LOGIC{Close} \;}
\newcommand{\More}{\LOGIC{Another} \;}
\newcommand{\Proof}{\LOGIC{Proof} \; }
%CategoryTheory
%Types
\newcommand{\Cov}{\TYPE{Covariant}}
\newcommand{\Contra}{\TYPE{Contravariant}}
\newcommand{\NT}{\TYPE{NaturalTransform}}
\newcommand{\UMP}{\TYPE{UnversalMappingProperty}}
\newcommand{\CMP}{\TYPE{CouniversalMappingProperty}}
\newcommand{\paral}{\rightrightarrows}
%functions
\newcommand{\op}{\mathrm{op}}
\newcommand{\obj}{\mathrm{obj}}
\DeclareMathOperator*{\dom}{dom}
\DeclareMathOperator*{\codom}{codom}
\DeclareMathOperator*{\colim}{colim}
%variable
\renewcommand{\C}{\mathcal{C}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\I}{\mathcal{I}}
\newcommand{\J}{\mathcal{J}}
\newcommand{\R}{\mathrm{R}}
%Cats
\newcommand{\CAT}{\mathsf{CAT}}
\newcommand{\SET}{\mathsf{SET}}
\newcommand{\PARALLEL}{\bullet \paral \bullet}
\newcommand{\WEDGE}{\bullet \to \bullet \leftarrow \bullet}
\newcommand{\VEE}{\bullet \leftarrow \bullet \to \bullet}
%Topology
%General Topology
%Types
\newcommand{\Top}{\TYPE{Topology}}
\newcommand{\Homeo}{\TYPE{Homeomorphism}}
\newcommand{\TS}{\TYPE{TopologicalSpace}} 
\newcommand{\NbhdBase}{\TYPE{NeighborhoodBase}}
\newcommand{\LF}{\TYPE{LocallyFinite}}
\newcommand{\PN}{\TYPE{PerfectlyNormal}}
\newcommand{\CR}{\TYPE{CompletelyRegular}}
\newcommand{\OM}{\TYPE{OpenMap}}
\newcommand{\Filter}{\TYPE{Filter}}
\newcommand{\Filterbase}{\TYPE{Filterbase}}
\newcommand{\CFilterbase}{\TYPE{ConvergentFilterbase}}
\newcommand{\Dense}{\TYPE{Dense}}
\newcommand{\Separable}{\TYPE{Separable}}
\newcommand{\ND}{\TYPE{NowhereDense}}
\newcommand{\Open}{\TYPE{Open}}
\newcommand{\Net}{\TYPE{Net}}
\newcommand{\Closed}{\TYPE{Closed}}
\newcommand{\Clopen}{\TYPE{Clopen}}
\newcommand{\Nbhd}{\TYPE{Neighborhood}}
\newcommand{\Compact}{\TYPE{Compact}}
\newcommand{\Compacts}{\TYPE{CompactSubset}}
\newcommand{\OpenC}{\TYPE{OpenCover}}
\newcommand{\Cluster}{\TYPE{Cluster}}
\newcommand{\Convergent}{\TYPE{Convergent}}
%\newcommand{\LC}{\TYPE{LocallyCompact}}
\newcommand{\Locally}{\TYPE{Locally}}
\newcommand{\Bair}{\TYPE{BaireSpace}}
\newcommand{\Meager}{\TYPE{Meager}}
\newcommand{\Connected}{\TYPE{Connected}}
\newcommand{\ED}{\TYPE{ExtemellyDisconnected}}
%FUNC
\DeclareMathOperator*{\intx}{int}
\DeclareMathOperator*{\cl}{cl} 
\DeclareMathOperator*{\boundary}{\partial} 
\DeclareMathOperator{\combo}{\triangledown} 
%\DeclareMathOperator{\diag}{\triangle} 
\DeclareMathOperator{\rem}{rem}
%CATS
\newcommand{\TOP}{\mathsf{TOP}}
\newcommand{\HC}{\mathsf{HC}}
\newcommand{\CG}{\mathsf{CG}}
%Symbols
\newcommand{\T}{\mathcal{T}}
\newcommand{\N}{\mathcal{N}}
\renewcommand{\U}{\mathcal{U}}
\renewcommand{\O}{\mathcal{O}}
\renewcommand{\d}{\mathrm{d}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\X}{\mathcal{X}}
%\newcommand{\d}{\mathrm{d}}
%Metric Topology
\newcommand{\Bounded}{\TYPE{Bounded}}
%FUNC
\DeclareMathOperator{\diam}{diam}
\newcommand{\Cell}{\mathbb{B}}
\newcommand{\Disc}{\mathbb{D}}
%CATS
\newcommand{\Semiiso}{\mathsf{SMS}_{\circ \to \cdot}}
\newcommand{\Iso}{{\mathsf{MS}_{\circ \to \cdot}}}
\newcommand{\SMS}{\mathsf{SMS}}
\newcommand{\MS}{\mathsf{MS}}
\newcommand{\UNI}{\mathsf{UNI}}
\newcommand{\UNIS}{\mathsf{UNIS}}
\newcommand{\TG}{\mathsf{TG}}
\newcommand{\CSeq}{\TYPE{CauchySequence}}
\newcommand{\Complete}{\TYPE{Complete}}
%Descriptive Set Theory
%TYPE
%Descriptive Set Theory
%TYPE
%\newcommand{\Bool}{\mathbb{B}}
%\newcommand{\IS}{\TYPE{InitialSegement}}
\newcommand{\FS}[1]{{#1}{}^*}
\newcommand{\Ext}{\TYPE{Extension}}
\newcommand{\Tree}{\TYPE{Tree}}
\newcommand{\Pruned}{\TYPE{Pruned}}
\newcommand{\PTM}{\TYPE{ProperTreeMorphism}}
%\newcommand{\LTM}{\TYPE{LipschitzTreeMorphism}}
\newcommand{\Polish}{\TYPE{Polish}}
\newcommand{\IIPG}{\TYPE{InfiniteIterativeTwoPlayersGame}}
\newcommand{\FPS}{\TYPE{FirstPlayerStrategy}}
\newcommand{\SPS}{\TYPE{SecondPlayerStrategy}}
\newcommand{\FPWS}{\TYPE{FirstPlayerWinningStrategy}}
\newcommand{\SPWS}{\TYPE{SecondPlayerWinningStrategy}}
\newcommand{\CS}{\TYPE{ChoquetSpace}}
\newcommand{\SCS}{\TYPE{StrongChoquetSpace}}
\newcommand{\BP}{\mathbf{BP}}
\newcommand{\MGR}{\mathbf{MGR}}
\newcommand{\cat}{\mathbf{CAT}}
\newcommand{\BM}{\TYPE{BairMeasurable}}
\newcommand{\CGSA}{\TYPE{CountablyGeneratedSigmaAlgebra}}
\newcommand{\MC}{\TYPE{MonotonicClass}}
\newcommand{\PSA}{\TYPE{PointSeparatingAlgebra}}
\newcommand{\SBS}{\TYPE{StandardBorelSpace}}
%FUNC
\DeclareMathOperator{\len}{len}
\newcommand{\inits}[2]{{#1}_{|\left[1,\ldots,#2\right]}}
\DeclareMathOperator{\lb}{lb}
\DeclareMathOperator{\WFpart}{WF}
\DeclareMathOperator{\Tr}{Tr}
\DeclareMathOperator{\PTr}{PTr}
\DeclareMathOperator*{\Tll}{{T\;\underline{lim}}}
\DeclareMathOperator*{\Tul}{{T\;\overline{lim}}}
\DeclareMathOperator*{\Tl}{{T\;lim}}
\DeclareMathOperator{\rankcb}{rank_{CB}}
\DeclareMathOperator{\lp}{lp}
\newcommand{\alg}{\mathsf{A}}
%CATS
\newcommand{\TREE}{\mathsf{TREE}}
\newcommand{\FSF}{\mathsf{FS}}
\newcommand{\CRONE}{\mathsf{CRONE}}
\newcommand{\BODY}{\mathsf{BODY}}
\newcommand{\BOR}{\mathsf{BOR}}
\newcommand{\bor}{\mathsf{B}}
\newcommand{\Effros}{\mathsf{EFF}}
%symbols
\newcommand{\K}{\mathsf{K}}
\renewcommand{\H}{\mathrm{H}}
\renewcommand{\L}{\mathcal{L}}
\renewcommand{\P}{\mathcal{P}}
\renewcommand{\S}{\mathcal{S}}
%Algebra
%Groups
%Types
\newcommand{\Group}{\TYPE{Group}}
\newcommand{\Abel}{\TYPE{Abelean}}
\newcommand{\Sgrp}{\subset_{\mathsf{GRP}}}
\newcommand{\Nrml}{\vartriangleleft}
\newcommand{\FG}{\TYPE{FiniteGroup}}
\newcommand{\Stab}{\mathrm{Stab}}
\newcommand{\FGA}{\TYPE{FinitelyGeneratedAbelean}}
\newcommand{\DN}{\TYPE{DirectedNormality}}
\newcommand{\Sphere}{\mathbb{S}}
\newcommand{\Torus}{\mathbb{T}}
%Func
\newcommand{\ActOn}{\curvearrowright}
\DeclareMathOperator{\tor}{tor}
\DeclareMathOperator{\bool}{bool}
\DeclareMathOperator{\rank}{rank}
%Cats
\newcommand{\GRP}{\mathsf{GRP}}
\newcommand{\ABEL}{\mathsf{ABEL}}
%LINEAR
%LINEAR
%Linear Algebra
%Types
\newcommand{\Basis}{\TYPE{Basis}} % Basis of the linear space
\newcommand{\submod}[1]{\subset_{\LMOD{#1}}}% submodule as a subset
\newcommand{\subvec}[1]{\subset_{\VS{#1}}}% vector subspace as a subset
\newcommand{\FGM}{\TYPE{FinitelyGeneratedModule}}% Finitely generated module
\newcommand{\LI}{\TYPE{LinearlyIndependent}}
\newcommand{\LIS}{\TYPE{LinearlyIndependentSet}}
\newcommand{\FM}{\TYPE{FreeModule}}
\newcommand{\IBP}{\TYPE{InvariantBasisProperty}}
\newcommand{\UTM}{\TYPE{UpperTriangularMatrix}}
\newcommand{\LTM}{\TYPE{LowerTriangularMatrix}}
\newcommand{\Diag}{\TYPE{DiagonalMatrix}}
\newcommand{\FP }{\TYPE{FinitelyPresented}}
\newcommand{\GL}{\mathbf{GL}}% General Linear Group
\newcommand{\SL}{\mathbf{SL}}% Special Linear group
\newcommand{\SO}{\mathbf{SO}}
\newcommand{\SU}{\mathbf{SU}}
\newcommand{\prsubvec}[1]{\subsetneq_{\VS{#1}}}	% poper vector subspace as a subset
\newcommand{\LC}{\TYPE{LinearComplement}} 
\newcommand{\IS}{\TYPE{InvariantSubspace}}
\newcommand{\RP}{\TYPE{ReducingPair}}
\newcommand{\RCF}{\TYPE{RationalCanonicalForm}}
\newcommand{\JCF}{\TYPE{JordanCanonicalForm}}
\newcommand{\Diagble}{\TYPE{Diagonalizable}}
\newcommand{\UT}{\TYPE{UpperTriangulizable}}
\newcommand{\LT}{\TYPE{LowerTriangulizable}}
%\newcommand{\IPS}{\TYPE{InnerProductSpace}}
\newcommand{\OBasis}{\TYPE{OrthonormalBasis}}
\newcommand{\FDIPS}{\TYPE{FiniteDimensionalInnerProductSpace}}
\newcommand{\NO}{\TYPE{NormalOperator}}
\newcommand{\NM}{\TYPE{NormalMatrix}}
%\newcommand{\SA}{\TYPE{SelfAdjoint}}
%\newcommand{\SSA}{\TYPE{SkewSelfAdjoint}}
%\newcommand{\PI}{\TYPE{Pseudoinverse}}
%\newcommand{\OVS}{\TYPE{OrthogonalVectorSpace}}
%\newcommand{\SVS}{\TYPE{SymplecticVectorSpace}}
%\newcommand{\MVS}{\TYPE{MetricVectorSpace}}
%\newcommand{\FDMVS}{\TYPE{FiniteDimensionalMetricVectorSpace}}
%\newcommand{\Sp}{\mathbf{Sp}}
%Func
\DeclareMathOperator{\Span}{span} % spann by subset
\DeclareMathOperator{\Ann}{Ann}   % annihilator
\DeclareMathOperator{\Ass}{Ass}   % associated primes
\DeclareMathOperator{\diag}{diag} % diagonal
\DeclareMathOperator{\adj}{adj}   % an adjoint matrix
\DeclareMathOperator{\tr}{tr}     % trace
\DeclareMathOperator{\codim}{codim} % codimension
%\DeclareMathOperator{\Cell}{\mathbf{C}} % a componion matrix
\DeclareMathOperator{\JC}{\mathbf{J}}  % a Jordan cell
\DeclareMathOperator{\bigboxplus}{\scalerel*{\boxplus}{\sum}} % a direct sum of operators in the sence of the reducing a pair
\DeclareMathOperator{\Spec}{Spec} % Spectre
\DeclareMathOperator{\bigbot}{\scalerel*{\bot}{\sum}} % an othogonal direct sum
\DeclareMathOperator{\GS}{\mathbf{GS}} %Gramm-Smmidt process
\DeclareMathOperator{\NGS}{\mathbf{NGS}} %Normalized Gramm-Smmidt process
\DeclareMathOperator{\WI}{\mathrm{WI}} %Witt Index
%Cats
\newcommand{\VS}[1]{#1\hyph\mathsf{VS}} % a category of vector spaces (Field)
\newcommand{\FDVS}[1]{#1\hyph\mathsf{FDVS}} % a category of finite-dimensional vector spaces (Field)
\newcommand{\LMOD}[1]{#1\hyph\mathsf{MOD}} % a category of the left modules (Ring)
\newcommand{\RMOD}[1]{\mathsf{MOD}\hyph#1} % a category of the right modules (Ring)
\newcommand{\LLMAP}[1]{#1\hyph\mathsf{LMAP}} % a cagory of based linear maps with the left scalar multiplication (Ring)
\newcommand{\LMAT}[1]{#1\hyph\mathsf{MAT}}  % a category of based matrices with the left scalar multiplication (Ring)
\newcommand{\NMAT}[1]{#1\hyph\mathbb{N}} % a category of finite matrices (Field)
%Symbols
\renewcommand{\L}{\mathcal{L}}
\renewcommand{\O}{\mathbf{O}}
%\newcommand{\U}{\mathbf{U}}
\renewcommand{\S}{\mathbf{S}}
%FIELDS
\newcommand{\Field}{\TYPE{Field}}
\newcommand{\ACF}{\TYPE{AlgebraicallyClosedField}}
%Functional Analysis
%TYPES
\newcommand{\PLF}{\TYPE{PositiveLinearFunctional}}
\newcommand{\NS}{\TYPE{NormedSpace}}
\newcommand{\SNS}{\TYPE{SeminormedSpace}}
\newcommand{\Banach}{\TYPE{Banach}}
\newcommand{\IPS}{\TYPE{InnerProductSpace}}
\newcommand{\Hilbert}{\TYPE{Hilbert}}
\newcommand{\TopC}{\TYPE{TopologicalyCompletable}}
\newcommand{\AbsC}{\TYPE{AbsolutelyConvergent}}
\newcommand{\PNS}{\TYPE{PolynormedSpace}}
\newcommand{\CNS}{\TYPE{CountablyNormedSpace}}
%CATS
\newcommand{\NORM}{\textsf{NORM}}
\newcommand{\NORMI}{{\textsf{NORM}_{\circ \to \cdot}}}
\newcommand{\BAN}{\textsf{BAN}}
\newcommand{\BANI}{{\textsf{BAN}_{\circ \to \cdot}}}
\newcommand{\HIL}[1]{#1\hyph\textsf{HIL}}
\newcommand{\HILI}{{\textsf{HIL}_{\circ \to \cdot}}}
%Simbols
\newcommand{\w}{\mathbf{w}}
%Convex
%
\newcommand{\Convex}{\TYPE{Convex}}
\newcommand{\CB}{\TYPE{ConvexBody}}
\newcommand{\CC}{\TYPE{ConvexCone}}
\newcommand{\Mink}{\TYPE{MinkowskySpace}}
\newcommand{\Euc}{\TYPE{EucledeanSpace}}
\newcommand{\Cone}{\TYPE{Cone}}
\newcommand{\Wedge}{\TYPE{Wedge}}
\newcommand{\PVS}{\TYPE{PreorderedVectorSpace}}
\newcommand{\OVS}{\TYPE{OrderedVectorSpace}}
\newcommand{\OU}{\TYPE{OrderUnit}}
\newcommand{\AVS}{\TYPE{ArchemedeanVectorSpace}}
\newcommand{\RS}{\TYPE{RieszSpace}}
%FUNC
\newcommand{\rint}{{\mathrm{rel}  \intx}}
\DeclareMathOperator{\lina}{lina}
\DeclareMathOperator{\lin}{lin}
\DeclareMathOperator{\core}{core}
\DeclareMathOperator{\conv}{conv}
\DeclareMathOperator{\cone}{cone}
\DeclareMathOperator{\cconv}{\overline{conv}}
\DeclareMathOperator{\CCONV}{\mathsf{CCONV}}
\renewcommand{\H}{\mathrm{H}}
%TOPALG
%\TYPES
\newcommand{\Connector}{\TYPE{Connector}}
\newcommand{\CConnector}{\TYPE{ClosedConnector}}
\newcommand{\Unif}{\TYPE{Uniformity}}
\newcommand{\US}{\TYPE{UniformSpace}}
\newcommand{\UB}{\TYPE{UniformBase}}
\newcommand{\Sym}{\TYPE{SymmetricConnector}}
\newcommand{\SB}{\TYPE{SymmetricBase}}
\newcommand{\BofU}{\TYPE{BaseOfUniformity}}
\newcommand{\UNbhd}{\TYPE{UniformNeighborhood}}
\newcommand{\UC}{\TYPE{UniformlyContinuous}}
\newcommand{\UHomeo}{\TYPE{Unimorphism}}
\newcommand{\UniCov}{\TYPE{UniformCover}}
\newcommand{\CF}{\TYPE{CauchyFilterbase}}
\newcommand{\CUS}{\TYPE{CompleteUniformSpace}}
\newcommand{\SCUS}{\TYPE{SequenceCompleteUniformSpace}}
\newcommand{\Small}{\TYPE{Small}}
\newcommand{\TB}{\TYPE{TotallyBounded}}
\newcommand{\MUS}{\TYPE{MetrizableUniformSpace}}
\newcommand{\Completion}{\TYPE{Completion}}
\newcommand{\SCompletion}{\TYPE{SeparableCompletion}}
\newcommand{\pt}{\mathrm{pt}}
\newcommand{\EqC}{\TYPE{Equicontinuous}}
\newcommand{\UEqC}{\TYPE{UnifomlyEquicontinuous}}
\newcommand{\LIM}{\TYPE{LeftInvariantMetric}}
\newcommand{\RIM}{\TYPE{RightInvariantMetric}}
\newcommand{\TIM}{\TYPE{TwosidedInvariantMetric}}
\renewcommand{\SS}{\TYPE{SymmetricSet}}
\newcommand{\veemetric}{\TYPE{\vee\hyph Semimetric}}
\newcommand{\TGC}{\TYPE{TopologicalGroupCompletion}}
\newcommand{\BG}{\TYPE{BaireGroup}}
\newcommand{\PG}{\TYPE{PolishGroup}}
\newcommand{\Borg}{\TYPE{BorelGroup}}
\newcommand{\cli}{\TYPE{cli}}
\newcommand{\Selector}{\TYPE{Selector}}
\newcommand{\Transversal}{\TYPE{Transversal}}
\newcommand{\SBG}{\TYPE{StandardBorelGroup}}
\newcommand{\Polishable}{\TYPE{Polishable}}
\newcommand{\SIN}{\TYPE{SIN}}
%FUNC
\newcommand{\inv}{\mathrm{inv}}
\DeclareMathOperator{\perm}{\mathrm{perm}}
%\CAT
\newcommand{\TGRP}{\mathsf{TGRP}}
\newcommand{\PGRP}{\mathsf{PGRP}}
%\Symbol
\newcommand{\V}{\mathcal{V}}
\newcommand{\W}{\mathcal{W}}
\renewcommand{\L}{\mathcal{L}}
\renewcommand{\R}{\mathcal{R}}
\renewcommand{\S}{\mathcal{S}}
\newcommand{\OComplete}{\TYPE{OrderDedekindComplete}}
%TopologicalVectorSpaces
%TYPES
\newcommand{\TopField}{\TYPE{TopologicalField}}
\newcommand{\TopVS}{\TYPE{TopologicalVectorSpace}}
\newcommand{\Vect}{\TYPE{Vector}}
\newcommand{\AVF}{\TYPE{AbsoluteValueField}}
\newcommand{\LConv}{\TYPE{LocallyConvexSpace}}
\newcommand{\TC}{\TYPE{TopologicalComplement}}
\newcommand{\MaxS}{\TYPE{MaximalSubspace}}
\newcommand{\AKC}{\TYPE{AbsolutelyKConvex}}
\newcommand{\KC}{\TYPE{KConvex}}
\newcommand{\LKConv}{\TYPE{LocallyKConvexSpace}}
\newcommand{\CCompact}{\TYPE{CCompact}}
\newcommand{\Seminorm}{\TYPE{Seminorm}}
\newcommand{\LCCompact}{\TYPE{LocallyCCompact}}
\newcommand{\LO}{\TYPE{LocallyBounded}}
\newcommand{\Homog}{\TYPE{Homogeneous}}
\newcommand{\Born}{\TYPE{Bornology}}
\newcommand{\BS}{\TYPE{BoundedStructure}}
\newcommand{\BB}{\TYPE{BornologyBase}}
\newcommand{\PS}{\TYPE{PairedSpace}}
\newcommand{\DP}{\TYPE{DualPair}}
%Cats
\newcommand{\TVS}[1]{{#1}\hyph\mathsf{TVS}}
\newcommand{\HTVS}[1]{{#1}\hyph\mathsf{HTVS}}
\newcommand{\LCS}[1]{{#1}\hyph\mathsf{LCS}}
\newcommand{\LCHS}[1]{{#1}\hyph\mathsf{LCHS}}
\newcommand{\SMN}{\mathsf{SMN}}
\newcommand{\BORN}{\mathsf{BORN}}
%FUNC
\DeclareMathOperator{\bal}{\mathrm{bal}}
\newcommand{\kconv}{K\hyph\mathrm{conv}\;}
\DeclareMathOperator{\ssc}{ssc}
\DeclareMathOperator{\suc}{suc}
\title{Topological Vector Spaces 2}
\author{Uncultured Tramp}
\begin{document}
\maketitle
\newpage
\tableofcontents
\newpage
\section{Abstract Topological Vector Spaces}
\subsection{Minkowski's Theory}
\subsubsection{Intro and Definition}
\Page{
	\DeclareType{\TopVS}{\prod k : \TopField \. ? \sum_{V \in \VS{k}} \Top(V)}
	\DefineType{(V,\tau)}{\TopVS}{\
		\cdot_V \in \TOP\Big( k \times (V,\tau),(V,\tau)\Big) \And 
		+_V \in \TOP\Big( (V,\tau) \times (V,\tau),(V,\tau)\Big)
	}
	\\
	& k :: \TopField ;\\
	\\
	\Conclude{\Vect\Top}{\Lambda V \in \VS{k} \. \TopVS(V)}
	{\prod_{V \in \VS{k}} V \. ? \Top(V)} 
	\\
	\DeclareFunc{categoryOfTopologicalVectorSpaces}
	{
		\TopField \to \CAT
	}
	\DefineNamedFunc{categoryOfTopologicalVectorSpaces}{k}{\TVS{k}}
	{
		\NewLine \de		
		(\TopVS(k),\VS{k} \cap \TOP,\circ,\id)
	}
	\\
	\DeclareFunc{categoryOfTopologicalVectorSpaces}
	{
		\TopField \to \CAT
	}
	\DefineNamedFunc{categoryOfHausdorffTopologicalVectorSpaces}{k}{\HTVS{k}}
	{
		\NewLine \de		
		(\TopVS(k) \And \TYPE{T2},\VS{k} \cap \TOP,\circ,\id)
	}
	\\
	\DeclareFunc{asTopologicalGroup}
	{
		\TVS{k} \to \TGRP
	}
	\DefineNamedFunc{asTopologicalGroup}{V}{V}{V}
	\\
	\\
	\DeclareFunc{asVectorSpace}
	{
		\TVS{k} \to \VS{k}
	}
	\DefineNamedFunc{asVectorSpace}{V}{V}{V}
	\\
}
\newpage
\subsubsection{Absorbent and Balanced Sets}
\Page{
	& k :: \AVF(\Reals) ;\\
	\\
	\DeclareType{Balanced}{ \prod_{V : \TVS{k} } ??V }
	\DefineType{B}{Balanced}{\Disc_k(0,1)B \subset B}
	\\
	\DeclareType{Absorbent}{\prod k : \AVF(\Reals) \. \prod_{V : \TVS{k} } ??V }
	\DefineType{A}{Absorbent}{
		\forall v \in V \. 
		\exists \rho \in \Reals_{++} \. 
		\forall \alpha \in \Disc_k(0,\rho) \.
		\alpha v \in A
	}
	\\
	\Theorem{VectorSubspaceIsBalanced}
	{
		\forall V \in \TVS{k} \.
		\forall U \subset_{\VS{k}} V \.
		\TYPE{Balanced}(V,U)
	}
	\Explain{ Obvious}
	\EndProof
	\\
	\Theorem{AbsorbentVectorSubspaceIswhole}
	{
		\forall V \in \TVS{k} \.
		\forall U \subset_{\VS{k}} V \.
		\TYPE{Absorbent}(V,U) \Imply V
	}
	\Explain{ Take $v \in V$}
	\Explain{ By definition of absorbent there is $\alpha \in k_*$ such that $\alpha v \in U$}
	\Explain{ But then  $ v = \alpha^{-1} \alpha v \in U$}
	\Explain{ So, $U = V$}
	\EndProof
	\\
	\Theorem{BalancedSetsAreDedikindComplete}
	{
		\forall V \in \TVS{k} \. \OComplete\Big( \TYPE{Balanced}(V)\Big)
	}
	\Explain{Assume $\beta$ is a set of balanced sets in $V$}
	\Explain{ If $v \in \bigcup \beta$, then there is a $B \in \beta$ such that $v \in B$}
	\Explain{ 
	And by definition of balanced $\alpha v \in B \subset \bigcup \beta $ 
	for any $\alpha \in \Cell_k(0,1)$}
	\Explain{
		So $\bigcup \beta$ is Balanced}
	\Explain{ if $v \in \bigcap \beta$, then $v \in B$ for any $B \in \beta$}
	\Explain{ 
	And by definition of balanced $\alpha v \in B \subset \bigcup \beta $ 
	for any $\alpha \in \Cell_k(0,1)$ and for all $B \in \beta$}
	\Explain{
		So $\bigcap \beta$ is Balanced}
	\EndProof
	\\
	\Theorem{AbsorbentAreClosedUnderUnions}
	{
		\forall V \in \TVS{k} \. \forall \alpha : ?\TYPE{Absorbent}(V) \. 
		\TYPE{Absorbent}\left(V,\bigcup\alpha \right)
	}
	\Explain{  This is obvious}
	\EndProof
}\Page{
	\Theorem{AbsorbentAreClosedUnderFiniteIntersections}
	{
		\NewLine ::		
		\forall V \in \TVS{k} \. \forall \alpha : \Finite\Big(\TYPE{Absorbent}(V)\Big) \. 
		\TYPE{Absorbent}\left(V,\bigcap\alpha \right)
	}
	\Explain{  Say $n = |\alpha|$}
	\Explain{ if $n = 0$, then $\bigcap \alpha = V$ which is always absorbent}
	\Explain{
		otherwisr represent $\alpha = \{A_1,\ldots, A_n\}$ and assume $v \in V$}
	\Explain{
		Select a finite sequence $\rho:\{1,\ldots,n\} \to \Reals_{++}$,
		with $\rho_i$ absorbing $v$ for $A_i$}
	\Explain{
	Let $\sigma = \min \{\rho_1,\ldots,\rho_n\}$}
	\Explain{
		Then $\sigma$ is absorbing for every $A_i$, so it is absorbing for $\bigcap \alpha$}
	\EndProof
	\Explain{
		In case of infinite intersiction the minimum may not exit}
	\\
	\DeclareFunc{balancedHull}{\prod_{V : \TVS{k}} 2^V \to \TYPE{Balanced}(V)}
	\DefineNamedFunc{balancedHull}{A}{\bal A}
	{
		\bigcap \Big\{ B : \TYPE{Balanced}(V),  A \subset B \Big\}
	}
	\\
	\Theorem{BalancedHullProductExpression}
	{
		\forall_{V \in \TVS{k}}  \forall A \subset V \. \bal A = \Cell_k(0,1) A
	}
	\Explain{
		Clearly $\Cell_k(0,1)A$ is balanced}
	\Explain{
		Assume that $B$ is a balanced set such that $A \subset B$
	}
	\Explain{
		Then $\Cell_k(0,1) A \subset \Cell_k(0,1) B \subset B$ as
		$B$ as balanced}
	\Explain{
		This proves the result as balanced hull of $A$ may beviewed as the smallest
		balanced set containing $A$}
	\EndProof 
	\\
	\DeclareFunc{balancedCore}{\prod_{V : \TVS{k}} 2^V \to \TYPE{Balanced}(V)}
	\DefineNamedFunc{balancedCore}{A}{ A^{\bal}}
	{
		\bigcup \Big\{ B : \TYPE{Balanced}(V),  B \subset A \Big\}
	}
	\\
	\Theorem{BalancedCoreAsIntersction}
	{
		\forall_{V \in \TVS{k}}  \forall A \subset V \. \bal A = \bigcap_{\alpha \in \Cell_k^\c(0,1)} \alpha A
	}
	\Explain{Firstly, I show that $B = \bigcap_{\alpha \in \Cell_k^\c(0,1)} \alpha A$ is balanced}
	\Explain{
		Assume $v \in B$}
	\Explain{
		Then,  $v \in \alpha A $ for all $\alpha \in \Cell_k^\c(0,1)$}
	\Explain{
		Thus $\Cell_k(0,1)v \subset A$}
	\Explain{
		By definition $A^{\bal}$ as a union this means, that $v \in A^{\bal}$, so 
		$B \subset A^{\bal}$}
	\Explain{
			Assume now that $v \in A^{\bal}$}
	\Explain{
			Then $\Cell_k(0,1) v \subset \Cell_k(0,1)A^{\bal} \subset A^{\bal} \subset A$
			As $A^{\bal}$ is a union of subsets}
	\Explain{
		But this mean that $v \in B$
	, so $A = B$}
	\EndProof
}\Page{
	\Theorem{ClosedBalancedCoreIsOpen}
	{
		\forall V : \TVS{k} \. 
		\forall F : \Closed(V) \.
		\Closed(V,F^{\bal})  
	}
	\Explain{ Multiplication by non-zero scalar is a homeomorphism}	
	\Explain{ So result follows from intersection representation as $\alpha F$ will be closed}
	\EndProof
	\\
	\Theorem{LinearMapsBalancedToBalanced}
	{
		\NewLine ::		
		\forall V,W : \TVS{k} \.
		\forall T \in \VS{k}(V,W) \.
		\forall B : \TYPE{Balanced}(V) \.
		\TYPE{Balanced}\Big(W, T(B) \Big)
	}
	\Explain{ 
		Assume $w \in T(B)$ and $\alpha \in \Disc_k(0,1)$}
	\Explain{  
		Then there is $v \in B$ such that $T(v) = w$}
	\Explain{
		as $B$ is balanced $\alpha v \in B$}
	\Explain{
		Thus $\alpha w = \alpha T(v) = T(\alpha v) \in T(B)$
	}
	\Explain{
		This proves that $T(B)$ is balanced}
	\EndProof
	\\
	\Theorem{LinearSurjectiveMapsAbsorbentToAbsorbent}
	{
		\NewLine ::		
		\forall V,W : \TVS{k} \.
		\forall T \in \VS{k} \And \Surj(V,W) \.
		\forall A : \TYPE{Absorbent}(V) \.
		\TYPE{Absorbent}\Big(W, T(A) \Big)
	}
	\Explain{ 
		Assume $w \in W$}
	\Explain{
		Then there is $v \in V$ such that $T(v) = w$ as $T$ is surjective}
	\Explain{  
		Then there exists $\rho \in \Reals_{++}$ such that $\Disc(0,\rho)v \subset A$
		as $A$ is absorbent}
	\Explain{
		Take $\alpha \in \Disc(0,\rho)$}
	\Explain{
		Then $\alpha w = \alpha T(v) = T(\alpha v) \in T(A)$}
	\Explain{
		This proves that $T(A)$ is absorbent}
	\EndProof
	\\
	\Theorem{BalancedPreimageIsBalanced}{
		\NewLine ::		
		\forall V,W : \TVS{k} \.
		\forall T \in \VS{k}(V,W) \.
		\forall B : \TYPE{Balanced}(W) \.
		\TYPE{Balanced}\Big(V, T^{-1}(B) \Big)
	}
	\Explain{
		Take $v \in T^{-1}(B)$ and $\alpha \in \Disc_k(0,1)$}
	\Explain{
		Then $T(v) \in B$, but also $ T(\alpha v) = \alpha T(v) \in B$ as
		$B$ is balanced }
	\Explain{
		But this means that $\alpha v \in T^{-1}(B)$}
	\EndProof
	\\
	\Theorem{BalancedPreimageIsBalanced}{
		\NewLine ::		
		\forall V,W : \TVS{k} \.
		\forall T \in \VS{k}(V,W) \.
		\forall A: \TYPE{Absorbent}(W) \.
		\TYPE{Absorbent}\Big(V, T^{-1}(A) \Big)
	}
	\Explain{
		Take $v \in V$}
	\Explain{
		Then there is $\rho \in \Reals_{++}$ such that 
		$ T(\alpha v) =  \alpha T(v) \in A$ for any $\alpha \in \Disc_k(0,\rho)$ 
		as $A$ is absorbent}
	\Explain{
		But this means that $\alpha v \in T^{-1}(A)$
	}
	\EndProof
}
\newpage
\subsubsection{Topology and Convexity}
\Page{
	\Conclude{\TYPE{Disc}}{ \Lambda V \in \TVS{k} \. \Convex \And \TYPE{Balanced}(V) }
	{
		\prod_{V \in \TVS{k}} ??V
	}
	\\
	\Theorem{DiscCharacterization}
	{
		\NewLine ::		
		\forall V \in \TVS{k} \.
		\forall D \subset V \.
		\TYPE{Disc}(V,D)
		\iff
		\forall v,w \in D \.
		\forall \alpha, \beta \in k \.
		|\alpha| + |\beta| \le 1
		\Imply
		\alpha v + \beta w \in D 
	}
	\Explain{ Firstly, assume that $D$ is a Disc}
	\Explain{ 
		Take $v,w \in D$ and $\alpha, \beta \in k$ such that $|\alpha| + |\beta| \le 1$}
	\Explain{
		$\alpha v, \beta w \in D$ as $D$ is balanced}
	\Explain{
		So if $\alpha = 0$ or $\beta = 0$ then $\alpha v + \beta w = \alpha v \in V$ or
		$\alpha v + \beta w  = \beta w \in V$}
	\Explain{
		Otherwise, $|\alpha| + |\beta| \neq 0$ and  $ \frac{|\alpha|}{|\alpha| + |\beta|} +  
			\frac{|\beta|}{|\alpha| + |\beta|} = 1$}
	\Explain{
		Also, $\frac{|\alpha| + |\beta|}{|\alpha|} \alpha v, 
		\frac{|\alpha| + |\beta|}{|\beta|} \beta w \in D$
		as $|\alpha| + |\beta| \le 1$ and $D$ is absorbent}
	\Explain{
		Then 
		$\alpha v + \beta w = 
		\frac{|\alpha|}{|\alpha| + |\beta|} \frac{|\alpha| + |\beta|}{|\alpha|} \alpha v +  
		\frac{|\beta|}{|\alpha| + |\beta|}	\frac{|\alpha| + |\beta|}{|\beta|} \beta w \in D
		$ as $D$ is convex}
	\Explain{
		Now assume that the condition holds}
	\Explain{
		Then convexity and being balanced is obvious}
	\EndProof
	\\
	\Theorem{DiskedHull}
	{
		\forall V \in \TVS{K} \.
		\forall A \subset V \.
		\bigcap \Big\{ D : \TYPE{Disc}(V), A \subset D  \Big\} = 
		\conv \bal A
	}
	\Explain{
		Firstly we need to show that $\conv \bal A$ is balanced}
	\Explain{
		Assume $v \in \conv \bal A$ and $\alpha \in \Disc_k(0,1)$}
	\Explain{
		If $\alpha = 0$ then $\alpha v = 0 \in \bal A \subset \conv \bal A$}	
	\Explain{
		Otherwise, if $C$ is convex in $V$, 
		then $ \frac{\alpha}{|\alpha|} C$ is also convex}
	\Explain{
		Also if $\bal A \subset C$ then $ \bal A =  \frac{\alpha}{|\alpha|} \bal A \subset 
		\frac{\alpha}{|\alpha|} C$ as $\bal A$ is balanced}
	\Explain{
		Thus, $\frac{\alpha}{|\alpha|} v \in \conv \bal A $}
	\Explain{
		Also, as it was said $0 \in \bal A \subset \conv \bal A$}
	\Explain{
		So $\alpha v =  \frac{|\alpha|}{|\alpha|}  \alpha v  + \Big(1 - |\alpha|\Big)0 \in \conv \bal A$
		as $\conv \bal A$ is convex}
	\Explain{
		So $\conv \bal A$ is a disk and 
		$B = \bigcap \Big\{ D : \TYPE{Disc}(V), A \subset D  \Big\}   \subset \conv \bal A$}
	\Explain{
		Now assume that $D$ is a disk such that $A \subset D$}
	\Explain{
		Then $\bal A \subset D$ as $D$ is balanced}
	\Explain{
		Furthermore, $\conv \bal A \subset D$ as $D$ is convex}
	\Explain{
	 	Thus $\conv \bal A = B$}
	\EndProof
}\Page{
	\Theorem{TVSIsConnected}
	{
		\forall V \in \TVS{k} \.		
		\Connected(k)
		\Imply
		\Connected(V)
	}
	\Explain{
		Note that $V = \bigcup_{v \in V} kv $}
	\Explain{
		Each $kv$ is connected as continuous image of connected $k$}
	\Explain{
		Then all lines $kv$ intersect at $0$, so  $V$ is connected}
	\EndProof
	\\
	\Theorem{AbsorbentNeighborhoodsOfZero}
	{
		\forall V \in \TVS{k} \.
		\forall U \in \U_V(0) \.
		\TYPE{Absorbent}(V,U)		
	}
	\Explain{ Assume $v \in V$}
	\Explain{
		Then $\lim_{\alpha \to 0} \alpha v = 0$}
	\Explain{
			So, there exists $\rho \in \Reals_{++}$
			such that $\Cell_k(0,\rho) v  \subset U$}
	\Explain{
		Then   $\Disc_k\left(0,\frac{\rho}{2}\right) v \subset  \Cell_k(0,\rho) v  \subset U$}
	\Explain{
		Thus, $U$ is absorbent}
	\EndProof
	\\
	\Theorem{NeighborhoodsOfZeroScaling}
	{
		\forall V \in \TVS{k} \.
		\forall U \in \U_V(0) \.
		\forall \alpha \in k_* \.
		\alpha U \in \U_V(0)
	}
	\Explain{
		$\alpha \cdot \bullet$ is a homeomorphism,
		so $\alpha U$ i	s open
	}
	\Explain{
		Obviously, $0 = \alpha 0 \in \alpha U$ as $0 \in U$}
	\Explain{
		Thus, $U \in \U_V(0)$}
	\EndProof
	\\
	\Theorem{EachNeighborhoodsOfZeroContainsBalancedNeighborhoods}
	{
		\NewLine ::
		\forall V \in \TVS{k} \.
		\forall U \in \U_V(0) \.
		\exists W \in \U_V(0) \.
		W \subset U \And \TYPE{Balanced}(V,W)
	}
	\Explain{
		$(\cdot)^{-1}(U)$ is open in $k \times V$}
	\Explain{
		So there exist $W \in \U_V(0)$ and $\rho \in \Reals_{++}$
		such that $\Cell_k(0,\rho) \times W \subset (\cdot)^{-1}(U) $
		as $0 \in  (\cdot)^{-1}(U)$}
	\Explain{
		This means that $\Cell_k(0,\rho) W \subset U$}
	\Explain{
		Also, note that $\Cell_k(0,\rho) W = \bigcup_{|\alpha| < \rho} \alpha W \in \U_V(0)$}
	\Explain{
		Assume $v \in \Cell_k(0,\rho) W$ and $\alpha \in \Disc_k(0,1)$}
	\Explain{
		Then there is 
		$w \in W$  and $\beta \in \Cell_k(0,\rho)$ such that $v = w\beta$}
	\Explain{
		But $\alpha \beta$ is also in $\Cell_k(0,\rho)$ and
		so $\alpha v = \alpha \beta w \in \Cell_k(0,\rho) W$}
	\Explain{
		Thus, $\Cell_k(0,\rho) W$ is balanced}
	\EndProof
	\\
	\Theorem{ClosedAndBlancedNeighborhoodBase}
	{
		\NewLine ::		
		\forall V \in \TVS{k} \.
		\exists \F : \TYPE{Filterbase}(V,\U_V(0)) \.
		\forall F \in \F \. 
		\Closed \And \TYPE{Balanced}(V,F)
	}
	\Explain{Pretty obvious}
	\EndProof
}\Page{
	\DeclareType{\LConv}
	{
		? \TVS{k}
	}
	\DefineType{V}{\LConv}{
		\exists \F : \TYPE{Filterbase}\Big(V,\N_V(0)\Big) \.
		\forall F \in \F \. \Convex(F,\F)
	}
	\\
	\DeclareFunc{categoryOfLocallyConvexSpaces}
	{
		\AVF(\Reals) \to \CAT
	}
	\DefineNamedFunc{categoryOfLocallyConvexSpaces}{k}{\LCS{k}}
	{
		\NewLine \de		
		(\LConv(k),\VS{k} \cap \TOP,\circ,\id)
	}
	\\
	\DeclareFunc{categoryOfTopologicalVectorSpaces}
	{
		\AVF(\Reals) \to \CAT
	}
	\DefineNamedFunc{categoryOfHausdorffTopologicalVectorSpaces}{k}{\LCHS{k}}
	{
		\NewLine \de		
		(\LConv(k) \And \TYPE{T2},\VS{k} \cap \TOP,\circ,\id)
	}
	\\
	\Theorem{NormedSpaceIsLocallyConvex}
	{
		\NORM(k) \subset \LCHS{k}
	}
	\Explain{ Balls in normed spaces are convex}
	\Explain{
		Also they are metric space, hence Hausdorff}
	\EndProof
	\\
	\Theorem{NormedSpaceIsLocallyConvex}
	{
		\NORM(k) \subset \LCHS{k}
	}
	\Explain{ Balls in normed spaces are convex}
	\Explain{
		Also they are metric space, hence Hausdorff}
	\EndProof
	\\
	\Theorem{LCSHasDiscBase}
	{
		\forall V \in \LCS{k} \.
		\exists \F : \TYPE{Filterbase}\Big(V,\N_V(0), \F\Big) \.
		\forall F \in \F \. \TYPE{Disc}(V,F)
	}
	\Explain{
		Take $U \in \N_V(0)$}
	\Explain{
		Then there exists a convex neighborhood $C \in \N_V(0)$
		with $C \subset U$ as $V$ is locally convex}
	\Explain{
		Then there is $B \subset C$ which is a balanced neiborhood 
		which was proved for all topological vector spaces}
	\Explain{
		Then $\conv B \subset C$ is convex and still an neighborhood of zero}
	\Explain{
		But convex hull of the balanced set is balanced,hence $\conv B$ is a disc
	}
	\EndProof
	\\
	\Theorem{LCSHasOpenDiscBase}
	{
		\forall V \in \LCS{k} \.
		\exists \F : \TYPE{Filterbase}\Big(V,\N_V(0), \F\Big) \.
		\forall F \in \F \. \TYPE{Disc} \And \Open(V,F)
	}
	\NoProof
	\\
	\Theorem{LCSHasClosedDiscBase}
	{
		\forall V \in \LCS{k} \.
		\exists \F : \TYPE{Filterbase}\Big(V,\N_V(0), \F\Big) \.
		\forall F \in \F \. \TYPE{Disc} \And \Closed(V,F)
	}
	\NoProof
}\Page{
	 \Theorem{VectorTopologyByAbsorbentAndBalancedSets}
	 {
		\NewLine ::	 	
	 	\forall V \in \VS{k} \.
	 	\forall \F : \TYPE{GroupFilterbase}(V) \.
	 	\forall \aleph : \F \subset \TYPE{Balanced} \And \TYPE{Absorbent}(V) \.
	 	\Big( V  , \langle \F \rangle_{\TGRP} \Big) \in \TVS{k} 
	 }
	 \Explain{
	 	As $F \in \F$ is balanced, then
	 	$F = -F$, so $ \langle \F \rangle_{\TGRP}$ is a 
	  group topology for $(V,+)$}
	 \Explain{
	 	Now assume $F \in \F$ and $\alpha \in k_*$}
	 \Explain{
	 	Then there exists balanced $U \in \langle \F \rangle_{\TGRP}$
	 	such that $0 \in U$ and $2U \subset U + U \subset F$}
	  \Explain{
	 	Then there exists balanced $U \in \langle \F \rangle_{\TGRP}$
	 	such that $0 \in U$ and $2U \subset U + U \subset F$}
	 \Explain{
	 	This can be generalized to th case when
	 	 $U \in \langle \F \rangle_{\TGRP}$ and
	 	 $2^n U \subset  F$}
	 \Explain{
	 		So, we can take such $U$ that $|\alpha| \le 2^n$ and $\alpha U \subset 2^n U \subset F$
	 		for any $\alpha \in k_*$ and $F \in \F$}
	 \Explain{
	 	Now consider $\alpha \in k_*$, $v \in V$ and $F \in \F$}	
	 \Explain{
	 	There exists $U \in \F(0)$ such that $U + U + U \subset F$}
	 \Explain{
	 	As $U$ is absorbent there is $\rho \in (0,1)$ 
	 	such that $\Cell(0,\rho)v \subset U \subset F$}
	 \Explain{
	 	Thus,
	 	$Cell(0,\rho)(v + U) = \Cell(0,\rho)v + \Cell(0,\rho)U = U + U \subset F$
	 }
	 \Explain{
	 	Now, assume $\alpha \neq 0$
	 }
	 \Explain{
	 	There is $U' \in \F$ such that $\alpha U' \subset U$
	 }
	 \Explain{
	 	Then there is also a $W \in \F$ such that $W \subset U' \cap U$
	 }
	 \Explain{
	 	Thus,
	 	$
	 		\Cell(\alpha,\rho)(v + W)  = 
	 		\alpha v +   \alpha W  + 	\Cell(0,\rho)(v + W) \subset
	 		\alpha v + U + U + U \subset \alpha v + F
	 	$
	 }
	 \Explain{
	 	This proves that scalar multiplication is continuous}
	 \EndProof
	 \\
	 \Theorem{LocallyConvexTopologyByDiscFilterbase}
	 {
		\NewLine ::	 	
	 	\forall V \in \VS{k} \.
	 	\forall \F : \TYPE{Filterbase}(V) \.
	 	\forall \aleph : \F \subset \TYPE{Disc} \And \TYPE{Absorbent} (V) \. \NewLine \.
	 	\forall \beth : \forall F \in \F \. \exists \alpha \in (0,1/2) \. \alpha F \in \F  \. 
	 	\Big( V  , \langle \F \rangle_{\TGRP} \Big) \in \LCS{k} 
	 }
	 \Explain{
	 	We need to show that $\F$ is a group filterbase}
	 \Explain{	Assume $F \in \F$}
	 \Explain{ By assumption there are $\alpha \in (0,1/2)$
	 	such that $\alpha F \in \F$} 
	 \Explain{
	 	Then, as $\alpha F$ is convex and $F$ is absorbent
	 	$\alpha F + \alpha F = 2 \alpha F \subset F$}
	 \Explain{
	 	Thus, by previous theorem $\Big( V  , \langle \F \rangle_{\TGRP} \Big)$
	 	is a topolofical vector space
	 }
	 \Explain{
	 	And it is locally convex as there is a filterbase consising of disks 
	 	by construction}
	 \EndProof
}
\newpage
\subsubsection{Semimetrization}
\Page{
	\DeclareType{FSeminorm}
	{
		\prod V \in \VS{k} \. ?(V \to \Reals_+)
	}
	\DefineType{\sigma}{FSeminorm}
	{
		\Big(
			\forall \alpha \in \Disc_k(0,1) \. 
			\forall v \in V \.
			\sigma(\alpha v) \le \sigma(v)
		\Big)
		\And  \NewLine \And
		\left(
			\forall v \in V \.
			\lim_{n \to \infty} \sigma\left(\frac{v}{n}\right)
		\right)
		\And 
		\left(
			\forall v,w \in V \.
			\sigma(v + w) \le \sigma(v) + \sigma(w)
		\right)
	}
	\\
	\DeclareType{FNorm}
	{
			\prod V \in \VS{k} \. ?\TYPE{FSeminorm}(V)
	}
	\DefineType{\sigma}{FNorm}
	{
		\forall v \in V \. \sigma(v) = 0 \iff v = 0
	}
	\\
	\Theorem{FSeminormSemimetrization}
	{
		\forall V \in \VS{k} \.
		\forall \sigma : \TYPE{FSeminorm} \.
		\exists \tau : \Vect\Top(V) \.
		\sigma \in C(V,\tau)
	}
	\Explain{ I will show that $\sigma$ is a value}
	\Explain{
		Firstly, note that 
		$\sigma(-v)\le \sigma(v)$
		and
		$\sigma(v) \le \sigma(-v)$, so
		$\sigma(v) = \sigma(-v$
	}
	\Explain{
		Also $\sigma(0) = \sigma\left( \frac{0}{n} \right) \to 0$,
		so $\sigma(0)$}
	\Explain{
		Other properties of value follows trivially by commutativity of $+_V$}
	\Explain{
		Now I show that scalar multiplication is continuous
		in topology defined by semimetric $\rho(v,w) = \sigma(v-w)$}
	\Explain{
		There are neighborgoods of zero defined by relation $\sigma(v) < \varepsilon$}
	\Explain{
		By first property of F-seminorm these balls are ballanced
	}
	\Explain{
		And by second property of F-seminorm these balls are absorbent}
	\Explain{
		So produced topology of $\rho$ is a vector space topplogy}
	\EndProof
	\\
	\Theorem{FNormSemimetrization}
	{
		\forall V \in \VS{k} \.
		\forall \sigma : \TYPE{FNorm} \.
		\exists \tau : \Vect\Top(V) \.
		\sigma \in C(V,\tau) \And \TYPE{T2}(V,\tau)
	}
	\Explain{In this case $\rho$ is a metric, so resulting topology musy be Hausdorff}
	\EndProof
	\\
	\DeclareFunc{subspaceSeminorm}
	{
		\prod V  \in \VS{k} \.
		\prod U \subset_{\VS{k}}  V \.
		\TYPE{FSeminorm}(V) \to \TYPE{FSeminorm}\left(\frac{V}{U}\right)
	}
	\DefineNamedFunc{subspaceSeminorm}{\sigma}{[\sigma]_U}
	{
		\Lambda [v] \in \frac{V}{U} \.  \inf_{u \in U} \sigma(v + u)	
	}
	\\
	\Theorem{SubspaceSemimetrization}{
		\forall  V \in \TVS{k} \And \TYPE{Semimetrizable} \.
		\forall U \subset_{\VS{k}} V \.
		 \TYPE{Semimetrizable}\left( \frac{V}{U} \right)
	}
	\NoProof
}
\newpage
\subsubsection{Completion}
\Page{
	\DeclareType{Completion}{
		\prod_{V \in \TVS{k}} ?\sum_{W \in \TVS{k} } \TYPE{TopologicalEmbedding}(V,W)     
	} 
	\DefineType{(W,\iota)}{Completion}{\TYPE{Complete}(V) \And \Dense\Big(W,\iota(V)\Big)}
	\\
	\Theorem{EveryTVSHasACompletion}
	{
		\forall V \in \TVS{k} \.
		\exists \TYPE{Completion}(V)
	}
	\Explain{As with topological Groups}
	\EndProof
	\\
	\DeclareType{TopologicalVectorSpaceSubset}
	{
		\prod_{V \in \TVS{k}} ??V
	}
	\DefineNamedType{U}{TopologicalVectorSpaceSubset}
	{
		U \subset_{\TVS{k}} V
	}
	{
		U \subset_{\VS{k}} V \And \Closed(V,U)
	}
	\\
	\Theorem{CompleteteQuotient}
	{
		\forall V \in \TVS{k} \.
		\forall U \subset{\TVS{k}} V \.
		\Complete(V) \Imply \Complete\left(\frac{V}{U}\right)
	}
	\Explain{As with topological groups}
	\EndProof
	\\
	\Theorem{BalancedHullOfTotallyBoundedIsTotallyBounded}
	{
		\NewLine ::
		\forall V \in \TVS{k} \. 
		\forall B : \TB(V) \.
		\TB(V, \bal B)
	}
	\Explain{ 
		Embed $B$ in a completion of $\hat V$ of $V$}
	\Explain{
		Then $\cl B$ is a compact in $\hat V$}
	\Explain{
		As $\Disc_k(0,1)$ is comapct in $k$, then
		$\Disc_k(0,1){\cl}_{\hat V} B$ is compact is continuous image
		of compact $\Disc_k(0,1) \times {\cl}_{\hat V} B$}
	\Explain{
		Then $\bal B = \Disc_k(0,1) B $ is totally bounded as 
		a subset of compact $\Disc_k(0,1){\cl}_{\hat V} B$}
	\EndProof
	\\
	\Theorem{BalancedHullOfCompactIsCompacts}
	{
		\NewLine ::
		\forall V \in \TVS{k} \. 
		\forall K : \Compacts(V) \.
		\Compacts(V, \bal  K)
	}
	\Explain{ $\Disc_k(0,1)K$ is compact as am image of compact $\Disc_k(0,1) \times K$}
	\EndProof
}\Page{
	\Theorem{ConvexHullofTotallyBoundedAsTotallyBounded}
	{
		\NewLine ::
		\forall V \in \LCS{k} \.
		\forall B : \TB(V) \.
		\TB(V, \conv B)
	}
	\ExplainFurther{
		In order to show that $\conv B$ is totally bounded
		we need to show that $conv B$ can be covered}
	\Explain{
		by finite number of translates $(U + v_i)^n_{i=1}$		
		for any $U \in \U_V(0)$
	}
	\Explain{
		Select disc $D \in \U_V(0)$ such that $D + D \subset U$}
	\Explain{
		This is possible as $V$ is loclly convex}
	\Explain{
		As $K$ totally bounded there are a finite set of translates such that
		$K \subset (D + v_i)^n_{i=1} \subset \conv \{ v_1, \ldots, v_n \} + D$}
	\Explain{
		As sum of convex sets is convex $\conv K \subset \conv \{ v_1, \ldots, v_n \} + D$
	}
	\ExplainFurther{
		As $\conv \{ v_1, \ldots, v_n \} $ is compact it is possible to select a finite set
		of  $m$ translates $u_i$ of $D$ such that} 
	\Explain{	$\conv K \subset  \bigcup_{i=1}^m (D+u_i)$}
	\Explain{
		So $\conv K$ is totally bounded}
	\EndProof	
	\\
	\Theorem{ConvexHullofTotallyBoundedAsTotallyBounded}
	{
		\NewLine ::
		\forall V \in \LCS{k} \and \Complete \.
		\forall K : \Compacts(V) \.
		\Compacts(V, \conv K)
	}
	\Explain{$\conv K$ is closed}
	\Explain{
		And as it was shown in the previous theorem $\conv K$ is also totally bounded,
	hence compact}
	\EndProof
}
\newpage
\subsubsection{Continuous Decompositions}
\Page{
	\DeclareType{TopologicalComplement}
	{
		\prod V : \TVS{k} \. ?\LC(V)
	}
	\DefineNamedType{(U,W)}{TopologicalComplement}{V =_{\TVS{k}} U \oplus W}
	{
		\NewLine \iff		
		\Homeo\Big(U\oplus W, V, \Lambda(u,w) \in U \oplus W \. u  + w  \Big)  
	}
	\\
	\Theorem{TopologicalComplementsByContinuousProjection}
	{
		\NewLine ::		
		\forall V  \in \TVS{k} \.
		\forall U,W : \LC(V) \. 
		U \oplus W =_{\TVS{k}} V
		\iff
		P_{U,W} \in \End_{\TOP}(V) 		
	}
	\Explain{
		Define $T : U \oplus W \to V$ by $T(u,w) = u + w$}
	\Explain{ 
		$(\Rightarrow):$ Assume that $T$ is a homeomorphism}
	\ExplainFurther{ 
		There is an expression $P_{U,W} = T^{-1} P_1 I_U$,
		where $P_1 : U \oplus W \to U$ is a projection,}
	\Explain{ 
		and $I_U : U \to V$ is a natural embedding}
	\Explain{
		Thus, $P_{U,W}$ is continuous as composition 
		of continuous functions}
	\Explain{
		$(\Leftarrow):$Assume $(\Delta, u_\delta + w_\delta)$ is a net in $V$ 
		converging to $0$
	}
	\Explain{
		Then by continuity 
		$
			0 = P_{U,W}(0) = 
			P_{U,W}(\lim_{\delta \in \Delta} u_\delta + w_\delta)  =
			\lim_{\delta \in \Delta} P_{U,W} (u_\delta + w_\delta) = 
			\lim_{\delta \in \Delta} u_\delta
		$}
	\Explain{
		Also $E - P_{U,W} = P_{W,U}$ is continuous}
	\Explain{
		So by the argument similar to one above $\lim_{\delta \in \Delta} w_\delta = 0$}
	\Explain{
		Thus, $\lim_{\delta \in \Delta} (u_\delta,w_\delta) = 0$ and $T^{-1}$ is  
		continuous meaning that $T$ is homeomorphism}
		\EndProof
	\\
	\Theorem{TopologicalComplementsByIsomorphicQuotient}
	{
		\NewLine ::		
		\forall V  \in \TVS{k} \.
		\forall U,W : \LC(V) \. 
		U \oplus W =_{\TVS{k}} V
		\iff
		\Homeo\left(W,\frac{V}{U}, \pi_{U|W} \right)
	}
	\Explain{ 
		$\pi_U$ is a quotient map, and hence continuous}
	\Explain{
		$(\Rightarrow):$Assume $(\Delta,[U + w_\delta])$ is a net in $\frac{V}{U}$ converging to zero}
	\Explain{
			But this means that $\lim_\delta w_\delta = 0$ 
			and $\lim_\delta \pi_{U|W}^{-1}[U + \w_\delta] = \lim_\delta w_\delta= 0$}
	\Explain{
		So $\pi_{U|W}$ is homeomorphism}
	\Explain{
		$(\Leftarrow):$ write $P_{U,W} = \pi_{U} \pi_{U|W}^{-1} I_W$}
	\Explain{
		This is continuous a as composition of continuous functions}
	\Explain{
		So by the previous theorem $V = U \oplus_{\TVS{k}} W$}
	\EndProof
	\\
	\Theorem{ComplementedImpliesClosed}
	{
		\forall V \in \TVS{k}
		\forall (U,W) : \TC(V) \.
		\Closed(V,U)
	}
	\Explain{ 
		By previous theorem $P_{W,U}$ is continuous}
	\Explain{
		Thus, $U = \ker P_{W,U}$ is closed}
	\EndProof
}\Page{
		\DeclareType{\MaxS}{\prod_{V \in \VS{k}} ?\TYPE{VectorSubspace}(V) }
		\DefineType{U}{\MaxS}{\forall W \subvec{k} V \. U \subsetneq W \Imply W = V }
		\\
		\Theorem{MaximalClosedSubspace}
		{
			\NewLine ::			
			\forall V \in \TVS{k} \.
			\forall U \subvec{k} V \.	 \NewLine \.	
			\MaxS \And \Closed(V,U) 
			\iff
			\exists f \in \TOP(V,k) \. 
			U = \ker f \And f \neq 0
		}
		\Explain{ 
			$(\Rightarrow):$ Assume $U$ is closed and maximal subspace in $V$}
		\Explain{
			As $U$ is maximal it should have a codimension 1}
		\Explain{
			So where exists $v \in U^\c$ such that $V = U \oplus \langle v \rangle$}
		\Explain{
			As $U$ is closed, where exists a balanced open subset $O \in \U_V(0)$
			such that $(O + v) \cap U = \emptyset$}
		\Explain{
			assume $u + \alpha v \in O$ is such that $|\alpha| > 1$ and $u \in U$
		}
		\Explain{
			Then, as $O$ is balanced, $\alpha^{-1} u + v \in O$
		}
		\Explain{
			But, then  $(\alpha^{-1} u + v) - v = \alpha^{-1} u \in (O + v) \cap U$,
			which is a contradiction}
		\Explain{
			Thus, $u + \alpha t \in \sigma O$ implies that $|\alpha| < |\sigma|$}
		\Explain{
			Define $f(u + \alpha v) = \alpha : V \to k$}
		\Explain{ 
			Consider a net $v_\delta = u_\delta + \alpha_\delta v$ converging to zero with $u_\delta$ 
			in $U$}
		\Explain{
			But the previous remark shows that $f(v_\delta) = \alpha_\delta$  converges to zero}
		\\
		\Theorem{SchroederBernsteinTHM}
		{
			\NewLine ::			
			\forall V,V' \in \TVS{k} \.
			\forall \aleph : V \cong_{\TVS{k}} V \oplus V \.
			\forall \beth :  V' \cong_{\TVS{k}} V' \oplus V' \. \NewLine \.
			\forall \gimel :  \TC(V,V') \.
			\forall \daleth : \TC(V',V') \.
			V \cong_{\TVS{k}} V'
		}
		\Explain{
			Write  
			$V \cong V' \oplus U = (V' \oplus V') \oplus U \cong V'  \oplus (V' \oplus U) \cong V' \oplus V$
		}
		\Explain{ 
			Symmetricaly, $V' \cong V' \oplus V$ 
		}
		\Explain{
			Thus, $V \cong V \oplus V' \cong V'$
		}
		\EndProof
}
\newpage
\subsubsection{Finite Dimension Conditions}
\Page{
	\Theorem{OneDimTVS}
	{
		\forall V \in \HTVS{k} \.
		\dim V = 1 \iff V \cong_{\TVS{k}} k
	}
	\Explain{
		As dimension is invarint for linear isomorphism $(\Leftarrow)$ is obvious }
	\Explain{
		$(\Rightarrow):$ As $\dim V = 1$ there is a $v \in V$ such that $v \neq 0$ 
		and $V = kv$}
	\Explain{ 
		Then the map	$T(\alpha v) = \alpha$ is a linear isomorphism
	}
	\Explain{
		fix some $\rho \in \Reals_{++}$}
	\Explain{
		As $V$ is Hausdorff there must exist 
		an open set $U \in \U_V(0)$ such that $\rho v \not \in U$}
	\Explain{
		Furthermore, $U$ must have a balanced subset 
		$W \in \U_V(0)$}
	\Explain{
		As $W$ is balanced, $W \subset \Cell(0,\rho)v$
	}
	\Explain{
		So,  $\alpha_\delta v \to 0 \iff \alpha_\delta \to 0$ 
	}
	\Explain{
		Thus, $T$ must be a homeomorphism}
	\EndProof
	\\
	\Theorem{FinDimIsomorphism}
	{
		\NewLine		
		\forall V \in \HTVS{k} \. \forall n \in \Nat \.
		\dim V = n \iff V \cong_{\TVS{k}} (k^n,\|\bullet\|_\infty)
	}
	\Explain{
		I modify the proof of the previous theorem}
	\Explain{
		By algebraic there must exist a base $\mathbf{e} = (e_1,\ldots, e_n)$ of $V$
	}
	\Explain{
		fix $\rho$ in $\Reals_{++}$}
	\Explain{
		As $V$ is Hausdorff and each $e_i \neq 0$ there 
		$U \subset \U_V(0)$ such $\rho e_i \not \in U$ for any $i \in \{1,\ldots,n\}$}
	\Explain{
		So there exists a blanced subset $W$ of $U$ such that
		$W \subset \Cell_{k^n,\|\bullet\|_\infty}(0,\rho)\cdot \mathbf{e}$}
	\Explain{
		Thus, the mapping $\mathbf{\alpha \cdot e} \mapsto \mathbf{\alpha}$
		is continuous}
	\ExplainFurther{
		Also, if $U \in \U_V(0)$ the set $U$ must be absorbent,}
	\Explain{ so there is a sequence $\rho_1,\ldots,\rho_n \in \Reals_{++}$ such that
		$\Disc_k(0,\rho_i) e_i \subset U$}
	\Explain{
		Let $\sigma = \min(e_1,\ldots,e_n) \in \Reals_{++}$}
	\Explain{
		Then $\Cell_{k^n,\|\bullet\|_\infty}(0,\sigma) \cdot \mathbf{e} \subset U$
	}
	\Explain{
		So, the inverse $\alpha \mapsto \alpha \cdot \mathbf{e}$ is also continuous}
	\EndProof
	\\
	\Theorem{FDimdSubspaceIsClosed}
	{
			\forall V \in \HTVS{k} \.
			\forall U \subvec{k} V \.
			\dim U  < \infty \Imply \Closed(V,U)
	}
	\Explain{ 
		$U$ is Hausdorff as a subset of Hausdorff space}
	\Explain{
		Then $U$ is isomorphic to $\ell^\infty_{k,\dim U}$ which is complete}
	\Explain{
		So, $U$ can be viewed as an uniform embedding of complete space into
		$V$, and hence must be closed}
	\EndProof
}\Page{
	\Theorem{ClosedFDimSum}
	{
		\forall V \in \TVS{k} \.
		\forall U \subset_{\TVS{k}} V \.
		\forall W \subvec{k} V \.
		\dim W < \infty \Imply \Closed(V,U + W)
	}
	\Explain{ 
		As $U$ is closed in $V$ the quotient $\frac{V}{U}$ must be Hausdorff}
	\Explain{ 
		As $\dim P_U(W) \le \dim \dim W$ the image $P_U(W)$ is still finite dimensional}
	\Explain{ 
		So by previous theorem $P_U(W)$ is closed in $\frac{V}{U}$}
	\Explain{ But then the preimage $ U + W  = P^{-1}_U P_U(W)$
		is closed as quotient map  $P_U$ is continuous}
	\EndProof
	\\
	\Theorem{FiniteDimensionalDomain}
	{
		\forall V,U \in \HTVS{k} \.
		\forall T \in \VS{k}(V,U) \. \NewLine \.
		\dim V < \infty  \Imply 
		T \in \TVS{k}(V,U)
	}
	\Explain{
		$\dim T(V) \le \dim V$, thus $T(V)$ must be finite dimensional}
	\Explain{
		Thus both $V$ and $T(V)$ are isomorphic to copies of 
		$l^\infty_k$ with coresponding finite dimensions}
	\Explain{
		And $T$ must be continuous as any mapping between such spaces does}
	\\
	\Theorem{FiniteDimensionalCodomain}
	{
		\forall V,U \in \HTVS{k} \.
		\forall T \in \TVS{k} \And \Surj(V,U) \. \NewLine \.
		\dim U < \infty  \Imply 
		\Open(V,U,T)
	}
	\Explain{
		By isomorphism theorem
		$\frac{V}{\ker T} \cong_{\VS{k}} T(V) = U$ 
	}
	\Explain{
		So $\dim \frac{V}{\ker T} < \infty$
	}
	\Explain{
		Also $\frac{V}{\ker T} $ is Haussdorf as $T$ is continuous
	}
	\Explain{
		So by prvious theorem the isomorphism must 
		$\frac{V}{\ker T} \cong_{\VS{k}} U$ must be continuous}
	\Explain{
		So $U$ is also finite dimensional Hausdorff  this bijection is homeomorphism 
		and so $\frac{V}{\ker T} \cong_{\TVS{k}} U$}
	\Explain{
		Denote this homeomorphism by $S$}
	\Explain{
		Then $T$ factors as $P_{\ker T} S$ and both these maps are open}
	\EndProof
}\Page{
	\Theorem{FDimIffLocallyCompact}
	{
		\forall V \in \HTVS{k} \.
		\dim V < \infty 
		\iff
		\TYPE{LocallyCompact}(V)
	}
	\Explain{$(\Rightarrow): V$ is homeomorphic to $l^{\infty}_{k,\dim V}$
		and this space is locally compact.}
	\Explain{
		This can be easily shown by considering a base of closed cubes}
	\Explain{
		So $V$ is locally compact}
	\Explain{
		$(\Leftarrow):$ now consider the case when $V$ is locally compact}
	\Explain{
		Then there exists a compact balansed neighborhood of zero, say $K$}
	\Explain{
		Take $K$ to be any another open neighborhood and choose
		$W \in \U_V(0)$ such balanced set that $W+W \subset U$
	}
	\Explain{
		As $K$ is compact, it is totally bounded and hence can be covered by
		a finite set of translates $K \subset \bigcup^n_{i=1} W + v_i$}
	\Explain{
		As $W$ is absorbent and balanced there is $\rho \in (1,+\infty)$ 
		such that each $v_i \in \rho U$}
	\Explain{
		Then $K \subset \bigcup^n_{i=1} W + v_i \subset W + \rho W \subset \rho W  + \rho W = 
			\rho( W + W) \subset \rho U		
		$
	}
	\Explain{ 
		Thus, sets of form $2^{-n} K$ form base at zero}
		\Explain{
		As $K$ is totally bounded it can can be covered by
		a finite set of translates $K \subset \bigcup^n_{i=1} \frac{1}{2}K + e_i$}
		\Explain{
			$F  = \Span e$ is finite-dimensional and hence closed}
		\Explain{ 
			 $K \subset \bigcup n_{i=1} \frac{1}{2}K + e_i \subset \frac{1}{2} K + F$}
		\Explain{
			But also 
			$\alpha F = F$
			or any non-zero scalar $\alpha$}
		\Explain{
			So $\frac{1}{2}K \subset \frac{1}{4} K + F$
		}
		\Explain{
			Iterating this relation  and substituting we get the result
			that
			$K \subset \frac{1}{2^n} K + F$ for any $n \in \Nat$}
		\Explain{
			This can be rewriten as $K \subset \bigcap^\infty_{n=1} \frac{1}{2^n} K + F = F$  
		}
		\Explain{
			But $K$ spans whole $V$, and so $V = F$ which is finite dimensional}
		\EndProof
		\\
		\Theorem{FDimCompactConvexHullIsCompact}
		{
			\NewLine ::			
			\forall V \in \TVS{k} \.
			\forall K : \Compacts(V) \.
			\dim V < \infty \Imply \Compacts(V,\conv K) \.
		}
		\Explain{
			Let $n = \dim V$}
		\Explain{
			$\conv K$ consists of convex combination of form  
			$\sum^{2n + 1}_{i=1} \lambda_i x_i$ where $\lambda \ge 0$
			and $\sum^{2n + 1}_{i=1} \lambda_i = 1$ and $x_i \in K$  
		}
		\Explain{
			This condition can be express as $\lambda \in \du_{2n+1} \subset k^{2n+1}$}
		\Explain{
			But $\du_{2n+1} $ is also compact, ans so is $\du_{2n+1} \times K^{2n+1}$
			by Tychonoff's theorem}
		\Explain{
			So $\conv K = (\cdot)(\du_{2n+1} \times K^{2n+1})$ 
			is compact as a continuous image of  a compact}
		\EndProof
}
\newpage
\subsubsection{Case of Ultravalued Field}
\Page{
	& k : \TYPE{UltravaluedField}; \\
	\\
	\DeclareType{\AKC}{\prod_{V : \TVS{k}} ??V}
	\DefineType{A}{\AKC}{
		\Disc_k(0,1)A +\Disc_k(0,1)A = A	
	}
	\\
	\DeclareType{\KC}{\prod_{V : \TVS{k}} ??V}
	\DefineType{V}{\KC}{
		\exists v \in V \. \exists A : \AKC(V) \. C = A + v	
	}
	\\
	\Theorem{AbsolutelyKConvexByZeroContaintment}
	{
		\forall V \in \TVS{k} \.
		\forall C : \KC(V) \.
		0 \in C \Imply \AKC(V,C)
	}
	\Explain{ $C$ must be a translate of absolutely K-Convex set, so write $C = A + v$}
	\Explain{
			As $A$ is absolutely K-Convex, then
			$\alpha(x + v) + \beta(y + v) - v \in C$ for any $x,y \in C$ and $\alpha,\beta \in \Disc_k(0,1)$}
	\Explain{
		Take $\alpha = \beta =1, y=0$}
	\Explain{
		Then the expression above reduces to $x + v \in C$}
	\Explain{
		But this means that $ A \subset C$}
	\Explain{
		On the other hand,  $\alpha(x + v) + \beta(y + v) \in A$
		for any $x,y \in C$ and $\alpha,\beta \in \Disc_k(0,1)$}
	\Explain{
		Taking $\alpha = 1, \beta = -1, y=0$, produces $x \in A$}
	\Explain{
		Thus $C \subset A$ and $C = A$ is absolutely K-convex}
	\EndProof
	\\
	\Theorem{TripleCombinationKConvexityCondition}
	{
		\NewLine ::		
		\forall V \in \TVS{k} \.
		\forall C \subset V \. \NewLine \.
		\KC(V,C)
		\iff
		\forall x,y,z \in C \.
		\forall \alpha, \beta,\gamma \in \Disc_k(0,1) \.
		\alpha + \beta + \gamma = 1
		\Imply
		\alpha x + \beta y + \gamma z \in C				
	}
	\Explain{ 1 $(\Rightarrow):$ assume that $C$ is K-convex}
	\Explain{ 1.1 $C$ must be a translate of absolutely K-Convex set, so write $C = A + v$}
	\Explain{
		1.2 Then
		$
			\alpha x + \beta y + \gamma z  =
			\alpha (x - v) + \beta (y - v) + \gamma (z - v)  + v \in C
		$}
	\Explain{ 2 $(\Leftarrow)$}
	\Explain{ 2.1 If $C = \emptyset$ then it is trivially K-convex, so assume the contrary}
	\Explain{ 2.2 Take $v \in V$ and let $A = C - v$}
	\Explain{ 2.3 $A$ is absolutely K-convex}
	\Explain{ 2.3.1 Assume $x,y \in C$ and $\alpha,\beta \in \Disc_k(0,1)$}
	\Explain{ 2.3.2 $1 - \alpha - \beta \in \Disc_k(0,1)$ }
	\Explain{ 2.3.2.1 $| 1 - \alpha - \beta| \le \max\Big(1,|\alpha|,|\beta|\Big) = 1$ }
	\Explain{ 2.3.3 Then by the hypothesis
		$ \alpha x + \beta y  + (1 - \alpha - \beta) v \in C  $  }
	\Explain{ 2.3.4 Translating by $-v$ gives
		$ \alpha (x - v) +  \beta (y -v) =  \alpha x + \beta y   + (1 - \alpha - \beta) v - v \in A  $  }
	\EndProof
}\Page{
\Theorem{convexCombinationKConvexityCondition}
	{
		\NewLine ::		
		\forall V \in \TVS{k} \.
		\forall \aleph : \mathrm{res}\;\mathrm{char} \; k \neq 2 \.
		\forall C \subset V \. \NewLine \.
		\KC(V,C)
		\iff
		\forall x,y \in C \.
		\forall \alpha \in \Disc_k(0,1) \.
		\alpha x + (1 - \alpha) y + \gamma z \in C				
	}
	\Explain{ 1 $(\Rightarrow)$ This direction is obvious}
	\Explain{ 1.1 The convex combination is a weaker form of triple combination in the previous result}
	\Explain{ 2 $(\Leftarrow)$ }
	\Explain{ 2.1 If $C = \emptyset$ then it is trivially K-convex, so assume the contrary}
	\Explain{ 2.2 Take $v \in V$ and let $A = C - v$}
	\Explain{ 2.3 $A$ is absolutely K-convex}
	\Explain{ 2.3.1  Assume $x,y \in C$ and $\alpha,\beta \in \Disc_k(0,1)$}
	\Explain{
		2.3.2 Rewrite $\alpha (x - v) + \beta (y - v) + v =  
		\frac{1}{2}\big( 2 \alpha x  + (1-2\alpha) v \big)
		+ \frac{1}{2}\big( 2 \beta y  + (1-2\beta) v \big)$}
	\Explain{
		2.3.3 Both $\frac{1}{2}\big( 2 \alpha x  + (1-2\alpha) v \big)$ and
		$\frac{1}{2}\big( 2 \beta y  + (1-2\beta) v \big)$ in $C$}
	\Explain{
		2.3.3.1 for ultravalue $|2 \alpha | = |\alpha + \alpha| \le |\alpha| = 1$
	}
	\Explain{
		2.3.3.2 Same holds for $\beta$}
	\Explain{
		2.3.3.3 So the convex combination hypothesis can be applied}
	\Explain{ 2.3.4 clearlly $\frac{1}{2} + \frac{1}{2} = 1$, so
		$ \alpha (x - v) + \beta (y - v)  \in A$
	}
	\Explain{ 2.3.4.1   
		$\left|\frac{1}{2}\right| = 1$ as residual characteristic of the field is not $2$}
	\EndProof
	\\
	\Theorem{AbsolutelyKConvexIntersection}
	{
		\forall V : \TVS{k} \.
		\forall I \in \SET \. \NewLine \.
		\forall A : I \to \AKC(V) \.
		\AKC\left(V, \bigcap_{i \in I} A_i \right)
	}
	\Explain{ Obvious}
	\EndProof
}\Page{
	\Theorem{KConvexIntersection}
	{
		\forall V : \TVS{k} \.
		\forall I \in \SET \. \NewLine \.
		\forall C : I \to \KC(V) \.
		\KC\left(V, \bigcap_{i \in I} C_i \right)
	}
	\Explain{ 1 
		Assume that $\bigcap_{i \in I} C_i \neq \emptyset$}
	\Explain{ 1.1
		Otherwise the condition is trivial}
	\Explain{ 2
		Take any $v \in \bigcap_{i \in I} C_i $}
	\Explain{ 3 
		Then  $\left(\bigcap_{i \in I} C_i\right) -v$ is absolutely K-convex and 
		$\bigcap_{i \in I} C_i$ is K-convex}
	\Explain{ 3.1
		$\left(\bigcap_{i \in I} C_i\right) -v = \bigcap_{i \in I} (C_i - v) $
		as translation by $v$ is bijective}
	\Explain{ 3.2
		Then every $C_i - v$ are K-convex sets, which contain zero, so they are absolutely K-Convex}
	\Explain{ 3.3
		So, the intersection $\bigcap_{i \in I} (C_i - v)$ is also absoluterly K-Convex}
	\EndProof
	\\
	\DeclareFunc{kConvexHull}
	{
		\prod_{V : \TVS{k}} (?V) \to \KC(V)
	}
	\DefineNamedFunc{kConvexHull}{X}{\kconv X}
	{
		\bigcap \Big\{  C : \KC(V)  , X \subset C \Big\}	
	}
	\\
	\Theorem{KConvexHullByLinearCombinations}
	{
		\NewLine ::		
		\forall V \in \TVS{k} \. 
		\forall X \subset V \. \NewLine \.
		\kconv X =  \left\{
			  x_{n+1} + \sum^{n}_{i=1} \alpha_i ( x_i - x_{n+1}) \Big|
			  n \in \Int_+,  \alpha : \{1,\ldots,n\} \to \Disc_k(0,1),
			  x : \{1,\ldots,n + 1\} \to X          
		\right\}}
	\Explain{ 1
		Let $B$ denote the set defined above}
	\Explain{ 2
		$B$ is K-Convex}
	\Explain{ 2.1
		Note, that $x_{n+1}$ in definition can be fixed}
	\Explain{ 2.2
		Then $B - x_{n+1}$ is obviously absolutely K-convex}
	\Explain{ 3
		$X \subset B$
	}
	\Explain{ 3.1
		Just take $n=1,\alpha_1 = 1$}
	\Explain{ 4
		So $\kconv X \subset B$
	}
	\Explain{ 5
		If $C$ is K-convex, then $B \subset C$}
	\Explain{ 5.1
		Some $x_{n+1} \in X$ must also be contained in $C$
	}
	\Explain{ 5.2
		So $C - x_{n+1}$ is absolutely K-convex.
	}
	\Explain{ 5.3
		So by induction $\sum^n_{i=1} \alpha_i (x_i - x_{n+1} ) \in C - x_{n+1}  $
	}
	\Explain{ 6
		Thus, $B \subset \kconv X$, and so $B = \kconv X$
	}
	\EndProof
}\Page{
		\DeclareFunc{kDiskHull}
	{
		\prod_{V : \TVS{k}} (?V) \to \AKC(V)
	}
	\DefineNamedFunc{kDiscHull}{X}{K\hyph\mathrm{disc}\; X}
	{
		\bigcap \Big\{  C : \AKC(V)  , X \subset C \Big\}	
	}
	\\
	\Theorem{AbsolutelyKConvexInterior}
	{
		\forall V : \TVS{k} \.
		\forall A : \AKC(V) \.
		\intx A = \emptyset | \intx A = A
	}
	\Explain{ 1 assume $\intx A \neq \emptyset$}
	\Explain{ 2 Take $v \in \intx A$}
	\Explain{ 3 Without loss of generality assume $v = 0$}
	\Explain{ 3.1 Then $A - v$ is an isomorphic absolutely convex set with $0 \in \intx A $}
	\Explain{ 4 Take any $U \in \U_V(0)$ such that $U \subset \intx A \subset A$}
	\Explain{ 5 Now take arbitrary $v \in A$}
	\Explain{ 6 Then $U + v \subset A$ }
	\Explain{ 6.1 $U + v$ consists of elements $u + v$ with $u \in U \subset A$}
	\Explain{ 6.2 As $v \in A$ also and $A$ is absolutely K-convex it must be the case that $u + v \in A$}
	\Explain{ 7 As translation is a homeomorphism $U + v$ is open and so $v \in \intx A$}
	\EndProof
	\\
	\Theorem{OpenKDiscHull}
	{
		\forall V : \TVS{k} \.
		\forall U : \Open(V) \.
		\Open(V,K\hyph\mathrm{disc}\;U)
	}
	\Explain{ 1 $ K\hyph\mathrm{disc}\;U$ is absolutely K-convex}
	\Explain{ 2 $ U \subset   K\hyph\mathrm{disc}\;U$, so $\intx  K\hyph\mathrm{disc}\;U \neq 0$}
	\Explain{ 3 But this means that $K\hyph\mathrm{disc}\;U$ is open}
	\EndProof
	\\
	\DeclareType{\LKConv}{?\TVS{k}}
	\DefineType{V}{\LKConv}
	{
		\exists \F : \TYPE{Filterbase}\Big(V,\U_V(0)\Big) \. \forall F \in \F \. \KC(V,F)
	}
}\Page{
	\Theorem{NonarchimedeanVSHasZeroTopDim}
	{
		\forall V : \LKConv(k) \And \TYPE{T2} \. \dim_\TOP V = 0
	}
	\Explain{ 1 $V$  has a base of closed K-discs}
	\Explain{ 1.1 Consider $U \in \U_V(0)$}
	\Explain{ 1.2 Then there exists an open K-disic $D$ such that $0 \in D \subset \overline{D} \subset U$}
	\Explain{ 1.3 Then $\overline{D}$ is a K-disk}
	\Explain{ 1.3.1 If $u,v \in \overline{D}$ it means that every their open neighborhood meet $D$ }
	\Explain{ 1.3.2 Assume $\alpha,\beta \in \Disc_k(0,1)$ }
	\Explain{ 1.3.3 Consider an open neighborhood $W$ of $\alpha u + \beta v$}
	\Explain{ 1.3.4 Then there is  an open neighborhood of zero  $O + O \subset W - \alpha u- \beta v $}
	\Explain{ 1.3.5 Consider the case $\alpha \neq 0 \neq \beta$}
	\Explain{ 1.3.6 Then there must be some $u' \in D \cap \frac{1}{\alpha}(O + \alpha u)$}
	\Explain{ 1.3.7 Then there is also $v' \in  D \cap \frac{1}{\beta}(O + \beta v)$}
	\Explain{ 1.3.8 Then $\alpha u' + \beta v' \in D$ as $D$ is absoluterly K-convex}
	\Explain{ 1.3.9 Also $\alpha u' + \beta  v' \in O + O + \alpha u + \beta v \subset W$}
	\Explain{ 1.3.10 As $W$ was arbitrary this means that $\alpha u + \beta v \in \overline{D}$}
	\Explain{ 1.4  $\overline{D} \subset U$}
	\Explain{ 1.4.1 This is true as $V$ is Hausdorff, and Hence regular}
	\Explain{ 2 But then every K-disc in this base is clopen}
	\Explain{ 2.1 To be in base every K-disc $D$ should contain an element of $U_V(0)$}
	\Explain{ 2.2 Hence $D$ has non-empty interior}
	\Explain{ 2.3 But This means that $D$ is open}
	\Explain{ 3 Thus $\dim_\TOP V = 0$}
	\EndProof 
	\\
	\DeclareType{RelativelyKConvex}
	{
		 \prod_{V_\TVS{k}}  \prod_{A \subset V} ??A
	}
	\DefineType{R}{RelativelyKConvex}
	{
			\exists C : \KC(K) \.  R = C \cap A
	} 
	\\
	\DeclareType{KConvexFilterbase}
	{
		 \prod V : \TVS{k} \. \prod_{A \subset V} ?\TYPE{Filterbase}(A) 
	}
	\DefineType{\F}{KConvexFilterbase}
	{
		\forall F \in \F \. \TYPE{RelativelyKConvex}(V,A,F)
	}
	\\
	\DeclareType{CCompact}
	{
		 \prod_{V_\TVS{k}}  ??V
	}
	\DefineType{K}{CCompact}
	{
		\forall \F : \TYPE{KConvexFilterbase}(V,K) \.
		\exists \TYPE{AdherencePoint}\Big(V, \F \Big)	
	} 
	\\
	& |\cdot| \neq  \Lambda \alpha \in k \. [\alpha \neq 0] \\ 
}\Page{
	\Theorem{EveryCompactIsCCompact}
	{
		\forall V : \TVS{k} \. 
		\forall K : \Compact(V,K) \.
		 \CCompact(V,K)
	}
	\Explain{ 1 Assume $\F$ is a K-Convex filterbase on $K$}
	\Explain{ 2 Then associated ultrafilter must have a limit}
	\Explain{ 3 This limit is an adherence point of $\F$}
	\EndProof
	\\
	\Theorem{ClosedSubsetOfCCompact}
	{	
		\forall V : \HTVS{k} \.
		\forall K  : \CCompact(V) \.
		\forall L : \Closed(K) \And \KC(V) \. \NewLine \.
		\CCompact(V,L)
	}
	\Explain{ 1 Assume $\F$ is a K-Convex filterbase on $L$}
	\Explain{ 2 Then the $\F$ is also a K-Convex filterbase for $K$}
	\Explain{ 3 Then, there is an adherence poiint $p \in K$ fo $\F'$}
	\Explain{ 4 $p$ is also an adherence point for $\F$}
	\Explain{ 4.1  Take any $U \in \U_V(p)$  }
	\Explain{ 4.2  Then $F \cap K \cap U \neq \emptyset$ for any $F \in \F$ }
	\Explain{ 4.3  Bat  all these $F \subset L$}
	\Explain{ 4.4 Thus $p \in \cl_K L = L$}
	\EndProof
	\\
	\Theorem{MaximalConvexFilterbase}
	{
		\NewLine :: 			
		\forall V : \LKConv(k) \.
		\forall C : \KC(V) \.
		\forall \F \in \max \TYPE{KConvexFilterbase}(V,C) \. \NewLine \.
		\forall p \in \C \.
		\TYPE{AherencePoint}(C,\F, p)
		\iff
		\lim \F = p
	}
	\Explain{ 1  $(\Rightarrow):$ Assume $p$ is an adherence point for $\F$ in $\C$}
	\Explain{ 1.1 Then $\forall F \in \. \forall U \in \U_V(p) \. U \cap F \neq \emptyset$ }
	\Explain{ 1.2 Assume that $U \in \U_C(p)$}
	\Explain{ 1.3 Then there exist a K-convex $D$ and open $W \in \U_C(p)$ 
	such that $W \subset D \subset V$}
	\Explain{ 1.4 Then $\forall F \in \F \.  D \cap F  \neq \emptyset$}
	\Explain{ 1.4.1 $\forall F \in \F \.  W \cap F \neq \emptyset$}
	\Explain{ 1.4.2 $W \subset D$ }
	\Explain{ 1.5 As $\F$ is maximal $D \in \F$}
	\Explain{ 1.6 Thus, $p = \lim \F$}
	\Explain{ 2 $(\Leftarrow):$ Now Assume $p = \lim \F$}
	\Explain{ 2.1 Then  $\forall U \in \U_C(p) \. \exists F \in \F \. F \subset U$}
	\Explain{ 2.2 Take arbitrary $U \in \U_C(p)$ and $F \in \F$}
	\Explain{ 2.3 Then by $(2.1)$ there exits $G \in \F$ such that $G \subset Y$}
	\Explain{ 2.4 As $\F$ is a filterbase $G \cap F \neq \emptyset$}
	\Explain{ 2.5 Thus $F \cap U \neq \emptyset$}
	\Explain{ 2.6 This proves that $p$ is and adherence point for $\F$}
	\EndProof
}\Page{
	\Theorem{KConvexAndCcompactIsClosed}
	{
		\NewLine ::		
		\forall V : \LKConv(k) \.
		\forall K : \CCompact \And \KC(V) \.
		\Closed(V,K)
	}
	\Explain{ 1 Assume $p$ is a Limit point for $K$}
	\Explain{ 2 Then there exists an filter $\F$ in $K$ such that $p = \lim \F$ }
	\Explain{ 2.1 Take $\N_V(p) \cap K$ for example}
	\Explain{ 3 Then $p$ is an adherence point of $\F$}
	\Explain{ 4 construct a K-convex filterbase $\C$ from $\F$}
	\Explain{ 4.1 For example, use the fact that $V$ is locally K-convex}
	\Explain{ 4.2 Let $C$ be the intersections of $K$ and K-convex neighborhoods of $p$}
	\Explain{ 5 Then $p$ is still a limit point of $\C$ in $V$}
	\Explain{ 6 There also must exist an adherence point of $\C$ in $K$, say $q$}
	\Explain{ 7 But as $V$ is Hausdorff and $\C$ has a limit it must be the case $q = p$}
	\Explain{ 8 Thus $K$ has all its limit points and must be closed}
	\EndProof
	\\
	\Theorem{CCompactProduct}
	{
		\forall I \in \Set \.
		\forall V : I \to \TVS{k} \.
		\forall C : \prod_{i \in I} \CCompact(V_i) \.
		\CCompact\left(\prod_{i \in I}V_i,\prod_{i \in I} C_i \right)
	}
	\Explain{
		Same proof as Tychonoff's theorem's proof with filters, but with $k$-convex sets}
	\EndProof
	\\
	\Theorem{CCompactCombination}
	{
		\forall V : \LKConv{k} \.
		\forall n \in \Int_+ \. \NewLine \.
		\forall D : \{1,\ldots,n\} \to \AKC \And \CCompact(V) \.
		\CCompact\left(V ,\kconv \bigcup^n_{i=1} D_i\right) 
	}
	\Explain{ 1 I will give a proof by induction}
	\Explain{ 2 $\kconv \bigcup^n_{i=1} D_i = \emptyset$ in case $n= 0$ 
		and  is trivially c-compact}
	\Explain{ 3  $\kconv \bigcup^{n+1}_{i=1} D_i = 
		\kconv \left( D_{n+1} + \bigcup^{n}_{i=1} D_i\right)$ by the result
		expressing K-convex hulls by linear combinations}
	\Explain{ 4 So for the induction step we need to prove case 
		of two -compacts $D_1$ and $D_2$}
	\Explain{ 5 assume $\F$ is a closed k-convex filterbase on $\kconv D_1 \cup D_2$ }
	\Explain{ 6 Let $\F' = \Big\{ \{ (x,y) \in D_1 \times D_2 : 
				\exists \alpha,\beta \in \Disc_k(0,1) \. \alpha x + \beta y \in F    \}   
				\Big| F \in \F \Big\}$} 
	\Explain{ 7 Then $\F'$ is a k-convex fiterbase on $D_1 \times D_2$}
	\Explain{ 8 $D_1 \times D_2$ is c-compact}
	\Explain{ 9 So there is an adherence point $(x,y)$ of $\F'$}
	\Explain{ 10 Let $C = K\hyph\mathrm{disc}\{ x, y\}$}
	\Explain{ 11 Then $C$ is c-compact K-disc}
	\Explain{ 12 Then $\overline{F} \cap C \neq \emptyset$ fo all $F \in \F$}
	\Explain{ 13 So $\F'' = \{ \overline{F} \cap C | F \in \F  \}$ is a filterbas on $C$}
	\Explain{ 14 So there exists and adherence point $P$ of $\F''$}
	\Explain{ 15 But $p$ is als an adherence point of $\F$ then}
	\EndProof
}\Page{
	\Theorem{CCompactIffSphericallyComplete}
	{
		\CCompact(k) \iff \TYPE{SphericallyComplete}(k)
	}
	\Explain{ 1 $(\Rightarrow):$ Assume that $k$ is c-compact}
	\Explain{ 1.1 Let $B:\Nat \to 2^k$ be a deacrising sequence of closed balls}
	\Explain{ 1.2 Then $\B =\{B_i | i \in \Nat\}$ is a $k$-convex filter}
	\Explain{ 1.3 So there must exist and adherence point $\beta$ of $\B$}
	\Explain{ 1.4 Then $\beta \in B_n$ for every $n \in \Nat$}
	\Explain{ 1.4.1 $B_n \cap U \neq \emptyset$for every $U \in \U_k(\beta)$}
	\Explain{ 1.4.2 This means that $\beta \in \overline{B}_n$}
	\Explain{ 1.4.3 But $B_n = \overline{B}_n$ as $B_n$ is closed}
	\Explain{ 1.5 Which can be rendered as $\beta \in \bigcap^\infty_{n=1} B$}
	\Explain{ 2  $(\Rightarrow):$ Assume that $k$ is sphercally complete}
	\Explain{ 2.1  we claim that every $k$-convex set in $k$ is either 
		$\emptyset$ or a ball}
	\Explain{ 2.1.1 Assume $A$ is an absolutely $k$-convex set such that 
		$\emptyset \neq A \neq k$}
	\Explain{ 2.1.2 Take $\omega \in A^\c$}
	\Explain{ 2.1.3 Then $\omega \neq 0$}
	\Explain{ 2.1.4 Then every $\omega'$ such that $|\omega| \le |\omega'|$ is not in $A$} 
	\Explain{ 2.1.4.1 Assume there is some $\omega' \in A$ such that $|\omega| \le |\omega'|$}
	\Explain{ 2.1.4.2 Then $\left| \frac{\omega}{\omega'}\right| \le 1$}	
	\Explain{ 2.1.4.3 Thus, as $A$ is a k-disc, $\omega = \frac{\omega}{\omega'}\omega' \in A$}
	\Explain{ 2.1.5 So the set $R = \Big\{ |\omega| \Big| \omega \in A^\c\Big\}$
		is bounded from above} 
	\Explain{ 2.1.6 Let $r = \sup R$}
	\Explain{ 2.1.7 Take $\alpha \in A$ and $\beta \in k$ with $|\beta| \le |\alpha|$}
	\Explain{ 2.1.8 Then $\beta \in A$}
	\Explain{ 2.1.9 so $A$ is a ball of radius $r$ open or closed depending on iclusion of $r$ to $R$}
	\Explain{ 2.2 Also note, 
		that in non-archimedian space any balls are either disjoin or contained in one or another}
	\Explain{
		2.3 So any $k$-convex filterbase $\F$ in $k$ can be represented as 
		a decreasing sequence of balls, closed or open}
	\Explain{
		2.4 Construct sequence of closed balls $\B$ by taking closures}
	\Explain{
		2.4.1 radii of balls will form a set $R$ bounded from below by $0$}
	\Explain{
		2.4.2 let $\delta = \inf R$}
	\Explain{
		2.4.3 Then there exists a decreasing sequence of balls $B$ with respective radi $r$
		such that $\lim_{n\to\infty} r_n = \delta$}
	\Explain{
		2.4.3.1 This is true as all elements in the filterbase $\F$ must have non-empty intersecion}
	\Explain{
		2.5 Then there exists $\beta \in \bigcap \B$}
	\Explain{
		2.4.4 Take $\B = \{ B_n | n \in \Nat\}$
	}
	\Explain{
		2.6 $\beta$ is an adherence point of $\F$
	}
	\Explain{
		2.6.1 There is some $B \in \B$ such $\beta \in B \subset \overline{F}$ for very element $F \in \F$}
	\Explain{
		2.6.2 Then $F \cap U \neq \emptyset$ for every $U \in \U_k(\beta)$}
	\EndProof
}
\newpage
\subsubsection{Some Interesting Examples}
\Page{
	& k :: \AVF(\Reals) \\
	\\
	\Theorem{NonLocallyConvexSpace}{
		\exists V : \TVS{k} \.  
		\neg\LConv(V)
	}
	\Explain{ 1 Let $V = L^p(\Reals,\lambda)$ for $p \in (0,1)$}
	\Explain{ 2 Its topology can be metrized by the metroc $\rho(f,g) = \int |f- g|^p$  }
	\Explain{ 2.1 we use inequelity of form 
		$\left( \sum^n_{i=1} \alpha_i \right)^p \le \sum^n_{i=1} \alpha_i$
			for 	$\alpha_i > 0$}
	\Explain{ 3 on the other hand $\conv \Cell_V(0,\sigma) \subset \Cell_V(0,2^{p-1}\sigma)$ }
	\Explain{ 3.1 Assume $f \in \Cell_V(0,\sigma)$}
	\Explain{ 3.2 Define $F(t) = \int_{-\infty}^t |f|^p$}
	\Explain{ 3.3 Then $F$ is a continuos function on $[-\infty,+\infty]$ 
		such that $F(-\infty) = 0$ and $F(+\infty) = \rho(0,f)$ }
	\Explain{ 3.4 By intermidieat value theorem there exists $t \in \Reals$
		such that $F(t) = \frac{\rho(0,f)}{2}$
	}
	\Explain{ 3.5 Let $g(x) = f(x)\delta_x(-\infty,t), h(x) = f(x)\delta_x(t,+\infty)$}
	\Explain{ 3.6 Then  $\rho(g,0) \le \frac{\sigma}{2}$ and  $\rho(h,0) \le \frac{\sigma}{2}$
		and $f = h + g = \frac{2}{2}f + \frac{2}{2}g$}
	\Explain{ 3.7 But $2g,2h \in \Cell_V(0,2^{2p-1}\sigma)$, so $f \in \conv \Cell_V(0,2^{2p-1}\sigma)$ }
	\Explain{ 4 By iterating one gets $\conv \Cell_V(0,\sigma) = V$}
	\Explain{ 5 So there are no non-trivial convex neighborhoods of $0$}
	\EndProof
	\\
	\Theorem{NonCompactConvexHullOfTheCompact}
	{
		\exists V  : \TVS{k} \.
		\exists K : \Compacts(V) \.
		\neg \Compacts(V, \conv K)
	}
	\Explain{ 1 Let $V = \ell^1$ }
	\Explain{ 2 Let $K = \left\{0, \delta_1^\bullet,\ldots, \frac{1}{n} \delta_{n}^\bullet  ,\ldots \right\}$}
	\Explain{ 3 Define $\xi_n = 
		\frac{1}{\sum^n_{i=1} 2^{-i}  } \sum^n_{t=1} \frac{2^{-t}}{t} \delta_{t}^\bullet
			\in \conv K$}
	\Explain{ 4 Then $\zeta = 
		\lim_{n \to \infty} \xi_n =  \sum^\infty_{t=1} \frac{2^{-t}}{t} \delta_{t}^\bullet$
	}
	\Explain{ 5 But then $\zeta_i \neq 0$ for all $i \in \Nat$,
		but this means that $\zeta \not \in \conv K$, so $K$ is not compact}
	\EndProof
}\Page{
	\Theorem{NoncomplimentedClosedSubpaceExist}
	{
		\exists V : \TVS{k} \.
		\exists U \subset_{\TVS{k}} V \.
		\neg  \TC(V,U)
	}
	\Explain{ 1 Let $V = \ell^\infty$ }
	\Explain{ 2 Let $U = c_0$}
	\NoProof
	\\
	& k :: \TYPE{UltravaluedField} \\
	\\
	\Theorem{PathologicalConvexSet}
	{
		\NewLine ::		
		\mathrm{res}\;k = \mathbb{F}_2
		\Imply
		\exists V : \TVS{k} \.
		\exists A : \neg \KC(V) \.
		\forall a,b \in A \.
		\forall \lambda \in \Disc_k(0,1) \.
		\lambda a + (1 - \lambda)b \in A
	}
	\Explain{ 1 Let $V = k^3$ and let 
		$A = \Big\{ a \in \Disc_k(0,1) : \exists i \in \{1,2,3\} \. a_i \in \Cell_k(0,1) \Big\}$}
	\Explain{2 $A$ has desired property for convex combinations of two elements}	
	\Explain{ 2.1 Assume $\lambda \in \Disc_k(0,1)$ and $a,b \in A$}
	\Explain{ 2.2 Note, 
		either $|\lambda|=1$ or $|1-\lambda| = 1$}
	\Explain{ 2.2.1 $ 1 = [1] = [1 - \lambda  + \lambda] = [1 - \lambda] + [\lambda]$ 
		in a residue1 field $\mathbb{F}_2$ }
	\Explain{ 2.3 There exists some $i,j \in \{1,2,3\}$ such that $|a_i| < 1$ and $|b_j| < 1$}
	\Explain{ 2.4 So $|\lambda a_i| = |\lambda||a_i| < 1$ and $|(1-\lambda)b_j| = 
		|1-\lambda||b_j| < 1$}
	\Explain{ 2.5 so either $| \lambda a_i + (1-\lambda) b_i | < 1 $ or 
					$| \lambda a_j + (1-\lambda) b_j | < 1 $}
	\Explain{ 3 $A$ is not K-convex}
	\Explain{ 3.1 $(-1,1,1) \not \in A$}
	\Explain{ 3.1.1 $|-1| = |1| = 1$ }
	\Explain{ 3.2 on the othe hand $(-1,1,1) =  -1 \cdot e_1 + 1\cdot e_2 + 1 \cdot e_3 \in \kconv A $ }
	\EndProof
}
\newpage
\subsubsection{Seminorms}
\Page{
	& k :: \AVF(\Reals) \\
	\\
	\DeclareType{Seminorm}
	{
		\prod V : \VS{k} \.
		?(V \to \Reals_{++})
	}
	\DefineType{\nu}{Seminorm}
	{
		\forall v,w \in V \. \nu(v + w) \le \nu(v) + \nu(w) 
		\And
		\forall v \in V \. \forall \lambda \in k \. \nu(\lambda v) = |\lambda|\nu(v)
	}
	\\
	\Theorem{ZeroSeminorm}
	{
		\forall V : \VS{k} \.
		\forall \nu : \Seminorm(V) \. 
		\nu(0) = 0
	}
	\Explain{1  $\nu(0) = \nu(\lambda 0) = |\lambda|\nu(0)$ for any $\lambda \in k$}
	\Explain{2 This means that $\nu(0)$ is not invertible in $k$}
	\Explain{3 So $\nu(0) = 0$ }
	\EndProof
	\\
	\Theorem{SymmetricSeminorm}
	{
		\forall V : \VS{k} \.
		\forall \nu : \Seminorm(V) \.
		\forall v \in V \. 
		\nu(-v) = \nu(v)
	}
	\Explain{1  $\nu(-v) = |-1|\nu(v) = \nu(v)$}
	\EndProof
	\\
	\Theorem{SumOfSeminorms}
	{
		\forall V : \VS{k} \.
		\forall n \in \Nat \.
		\forall \nu : \{1,\ldots,n\} \to \Seminorm(V) \.
		\Seminorm\left(V, \sum^n_{i=1} \nu_i \right)
	}
	\Explain{ Obvious}
	\EndProof
	\\
	\Theorem{MaxOfSeminorms}
	{
		\forall V : \VS{k} \.
		\forall n \in \Nat \.
		\forall \nu : \{1,\ldots,n\} \to \Seminorm(V) \.
		\Seminorm(v, \max_{1\le i \le n} \nu_i )
	}
	\Explain{ Obvious}
	\EndProof
	\\
	\Explain{Note: this means that seminorms over $V$ form an ordered tropical semirng
		with $0 = -\infty$}
	\\
	\DeclareFunc{seminormsFunctor}{\Contra(\VS{k},\mathsf{TSRING})}
	\DefineNamedFunc{seminormsFunctor}{V}{\mathsf{SMN}(V)}{\TYPE{Seminorm}(V)}
	\DefineNamedFunc{seminormsFunctor}{V,W,T}{\mathsf{SMN}_{V,W}(T)}{T^*}
}\Page{
	\DeclareFunc{seminormCell}
	{
		\prod V  \in \VS{k} \.
		\Seminorm(V) \to ?V
	}
	\DefineNamedFunc{seminormCell}{\nu}{\Cell(\nu)}
	{
		\{ v \in V : \nu(v) < 1  \}
	}               
	\\
	\DeclareFunc{seminormDisc}
	{
		\prod V  \in \VS{k} \.
		\Seminorm(V) \to ?V
	}
	\DefineNamedFunc{seminormDisc}{\nu}{\Disc(\nu)}
	{
		\{ v \in V : \nu(v) \le 1  \}
	}
	\\
	\Theorem{SeminormIneq}
	{
		\forall V \in \VS{k} \.
		\forall \nu,\nu' : \Seminorm(V) \.
		\nu \le \nu' 
		\iff
		\Cell(\nu') \subset \Cell(\nu)
	}
	\Explain{ Obvious}
	\EndProof
	\\
	\Explain{ Note: This means that $\Cell$ is an antitone map or functor  $\SMN(V) \to 2^V$}
	\Explain{ Moreover, both $\Cell$ and $\Disc$ are natural transform from $\SMN$
		to the lattice of absorbent discs}
	\\
	\Theorem{SeminormScalling}
	{
		\forall V \in \VS{k} \.
		\forall \nu \in \SMN(V) \.
		\forall \lambda \in \Reals_{++} \.
		\lambda\Cell(\nu) = \Cell(\lambda^{-1}\nu)
	}
	\Explain{ Obvious}
	\EndProof
	\\
	\Theorem{SeminormCellIsAbsobentDisc}
	{
		\forall V \in \VS{k} 
		\forall \nu \in \SMN(V) \.
		\TYPE{Absorbent} \And \TYPE{Disc}\Big(V,\Cell(\nu)\Big)
	}
	\Explain{Obvious}
	\EndProof
	\\
	\Theorem{SeminormCellClosureTheorem}
	{
		\forall V \in \TVS{k} \.
		\forall \nu \in \SMN \And C(V) \.
		{\cl}_V \Cell(\nu) = \Disc(\nu) 
	}
	\Explain{ 1 Assume $v \in \Disc(\nu)$}
	\Explain{ 2 then the sequence $u_n = \left(1-\frac{1}{n}\right)v \in \Cell(\nu)$
		has limit $v$}
	\Explain{ 3 So $\Disc(\nu) \subset {\cl}_V \Cell(\nu)$}
	\Explain{ 4 On the other hand $\Disc(\nu) = \nu^{-1}[0,1]$ is closed}
	\Explain{ 5 So ${\cl}_V \Cell(\nu) \subset \Disc(\nu)$ and $\Disc(\nu) = {\cl}_V \Cell(\nu)$}
	\EndProof
}\Page{
	\Theorem{SeminormContinuity}
	{
		\forall V : \TVS{k} \.
		\forall \nu \in \SMN(V) \. \NewLine 
		(1) \;\nu \in \UNI(V,\Reals)
		\iff \NewLine
		(2) \; \Cell(\nu) \in \T(V)
		\iff \NewLine
		(3) \; \Disc(\nu) \in \N(V)
		\iff \NewLine
		(4) \; \TYPE{ContinuousAt}(V,\Reals, 0, \nu)
	}
	\Explain{ 1 $(1) \Imply (2) \Imply (3)$ obvious}
	\Explain{ 2 $(3) \Imply (4)$}
	\Explain{ 2.1 As non-zero scalar multiplication is a homeomorphism
	$\lambda \Disc(\nu) \in \N(V)$ for all $\lambda \in \Reals_{++}$}
	\Explain{ 
			2.2 consider a net $v$ such that $\lim_\delta v_\delta = 0$} 
	\Explain{
			2.3 Eventualy  $v_\delta \in \lambda \Disc(\nu)$ for any $\lambda \in \Reals_{++}$
	}
	\Explain{ 2.4
		This means that $\lim_\delta \nu(v_\delta) = 0$}
	\Explain{ 3 $(4) \Imply (1)$}
	\Explain{  3.1 $\nu^{-1}[0,\lambda)$ is open for any $\lambda \in \Reals_{++}$}
	\Explain{ 3.2 As $V$ is a topological group there is $U \in \U_V(0)$
		such that  $U - U \subset \nu^{-1}[0,\lambda)$}
	\Explain{ 3.3 Thus, $\nu(x - y) < \lambda$ for any $x,y \in U$}
	\Explain{ 3.4  Let $v \in V$ be arbitraty  }
	\Explain{ 3.5 Take $u \in v + U$}
	\Explain{
				3.6 Then 
				$  
					 \nu(u) = \nu(u + v - v) \le \nu(u -v) + \nu(v) \le \nu(v) + \lambda)$}
	\Explain{
			  3.7 On the other hand
			  $\nu(u) \ge \nu(v) - \nu(u-v) \ge \nu(v) - \lambda$
			  as
			  $\nu(v) = \nu(v -u + u) \le  \nu(u) + \nu(u - v)$}
	\Explain{
			3.8 So $\Big|\nu(u) - \nu(v)\Big| \le \lambda$}
	\EndProof
	\\
	\Theorem{SeminormContinuityByDomination}
	{
		\NewLine ::		
		\forall V : \TVS{k} \.
		\forall \nu \in \SMN(V) \. 
		\forall \mu \in \SMN \And C(V)  \.
		\nu \le \mu 
		\Imply
		\nu \in \UNI(V,\Reals)
	}
	\Explain{
		By antitonicity $\Cell(\mu) \subset \Cell(\nu) \subset \Disc(\nu)$
	}
	\Explain{
		But $\Cell(\mu)$ is open, so $\Disc(\nu) \in \N_V(0)$
	}
	\Explain{
		Thus $\nu$ is uniformly continuous}
	\EndProof
}\Page{
	\Theorem{GaugesOfDiscsProduceSeminorms}
	{
		\forall V \in \VS{k} \.
		\forall D : \TYPE{Disc} \And \TYPE{Absorbent}(D) \.
		\gamma(\bullet|D) \in \SMN(V)
	}
	\Explain{ 1 Discs are convex, so $\gamma(\bullet|D)$ is a convex function}
	\Explain{ 2 Take some $v \in V$}
	\Explain{ 2.1 Let $I_v= \{ \lambda \in \Reals_{++} : \lambda^{-1} v \in D\}$}
	\Explain{ 2.2 As $D$ is absorbent, $I_v \neq \emptyset$}
	\Explain{ 2.3 As $D$ is balanced then if $\alpha \in I_v$ and $\beta \ge \alpha$, 
		then  $\beta \in I$}
	\Explain{ 2.4
		Thus, $I_v = \Big( \gamma(v|D)   ,+\infty)$ }
	\Explain{
		2.5 Then it is clear that $I_{\lambda v} = \lambda I_v = 
			\Big( \lambda \gamma(v|D),+\infty) = \Big( \gamma(\lambda v|D),+\infty\Big)$ 
	}
	\Explain{ 3 So $\gamma(\bullet|D)$ is positively homogeneous}
	\Explain{ 4 $\gamma(\bullet|D)$ is subadditive}
	\Explain{ 4.1 Take some $v,w \in V$}
	\Explain{ 4.2 
		Write $\gamma(v+ w|D) = \gamma\left( \frac{2}{2}v + \frac{2}{2}w | D  \right)
			\le   \frac{1}{2} \gamma(2v|D) + \frac{1}{2}\gamma(2w|D) =
			\gamma(v|D) + \gamma(w|D)	$}
	\EndProof
	\\
	\Explain{ 
		Note: Cells and gauges produce a Functor isomorphism}
	\Explain{
		This isomorphism is   
		between $\SMN : \VS{k} \to \mathsf{ORD}$ and some absorbent disc functor, open or closed}
	\\
	\Theorem{GaugeContinuity}
	{
		\forall V \in \TVS{k} \.
		\forall D : \TYPE{Disc} \And \TYPE{Absorbent}(D) \.
		\gamma(\bullet|D) \in C(V)
		\iff
		D \in \N_V(0)
	}
	\Explain{ 1 This follows from seminorm continuity theorem as 
		$\Cell(\gamma(\bullet|D)) \subset    D \subset \Disc(\gamma(\bullet|D))$}
	\EndProof
	\\
	\DeclareType{Sublinear}
	{
		\prod V : \VS{k} \. 
		?(V \to \Reals)
	}
	\DefineNamedType{\phi}{Sublinear}{\phi \in \S\L(V)}
	{
		\forall v,w \in V \. \phi(v + w) \le \phi(v) + \phi(w)
		\And \forall v \in V \. \forall \alpha \in \Reals_{++} \.
		\phi(\alpha v) = \alpha \phi(v)
	}
	\\
	\DeclareFunc{seminormFromSublinear}
	{
		\prod V : \VS{k} \.
		\TYPE{Sublinear}(V) \to \SMN(V)
	}
	\DefineNamedFunc{seminormFromSublinear}
	{\phi}{\nu_\phi}{\Lambda v \in V \. \max\Big( \phi(v), \phi(-v)  \Big)}
	\Explain{ 1 Either $\phi(v)\ge 0$ or $\phi(-v)\ge 0$}	
	\Explain{ 1.1 From positive homogenity $\phi(0) = 0$}
	\Explain{ 1.2 Write $0 = \phi(0) = \phi(v-v) \le \phi(v) + \phi(-v)$}
	\Explain{ 2 So $\nu_\phi$ has positive range }
	\Explain{ 3 Minkowsky Inequality holds also}
	\ExplainFurther{
		3.1 
		$\nu_\phi(v + w) = max\Big(\phi(v + w), \phi(-v-w)\Big) \le 
		\max\Big( \phi(v) + \phi(w), \phi(-v) + \phi(-w) \Big) \le$}
	\Explain{ 
		$ \quad \quad \le \max\Big(\phi(v),\phi(-v)\Big) + \max\Big(\phi(w),\phi(-w)\Big) = 
		\nu_\phi(v) + \nu_\phi(w)$}
	\EndProof
}
\newpage
\subsubsection{Topology of Locally Convex Space}
\Page{
	\DeclareFunc{seminormTopology}{
		\prod_{V \in \VS{k}} ?\SMN(V) \to	 \Vect\Top(V)
	}
	\DefineNamedFunc{seminormTopology}{\N}{\T(\N)}
	{
		\W_V(\N,\Reals,\id)
	}
	\\
	\Theorem{HausdorffSeminormTopology}
	{
		\NewLine ::		
		\forall V \in \VS{k} \.
		\forall \N \subset \SMN(V) \.
		\TYPE{T2}\Big(V, \T(\N)\Big)
		\iff 
		\forall v \in \V \. 
		v \neq 0 \Imply \exists \nu \in \N \. \nu(v) \neq 0
	}
	\Explain{ 1 If such norm $\nu$ exists then $v$ can be sparated from $0$ by an open set}
	\Explain{ 2 For topological group $(V,+)$ this is enough}
	\EndProof
	\\
	\Theorem{SeminormTopologyBase}
	{
		\NewLine ::		
		\forall V \in \VS{k} \.
		\forall \N \subset \SMN(V) \.
		\TYPE{Base}\bigg( V, \T(\N), 
			\Big\{ \lambda \Cell(\nu) \Big| \lambda \in \Reals_{++}, \nu \in \N  \Big\} \bigg)
	}
	\Explain{1 Seems obvious by weak topology definition}
	\EndProof
	\\
	\Theorem{SeminormTopologyIsLC}
	{
		\forall V \in \VS{k} \.
		\forall \N \subset \SMN(V) \.
		\Big( V, \T(\N) \Big) \in \LCS{k}
	}
	\Explain{1 This holds as the base is convex}
	\EndProof
	\\
	\Theorem{EveryLCSHasSeminormTopology}
	{
		\forall V \in \LCS{k} \.
		\exists \N \subset \SMN(V) \.
		\T_V = \T(\N)
	}
	\Explain{ 1 As we working with froup topologies it is enough to work with zero equivalence}
	\Explain{ 2 Take $U \in \U_V(0)$}
	\Explain{ 3 Then there exists a disc $D \subset U$}
	\Explain{ 4 $\gamma(\bullet|D)$ is continuous gauge for $V$}
	\Explain{ 5 So $U \in \T\Big(\Big\{\gamma(\bullet|D)\Big\} \Big)$}
	\Explain{ 6 Define $\N$ to be set of all such gauges}
	\Explain{ 7 Then $\T_V \subset \T(\N)$}
	\Explain{ 8 On the other hand $\T(\N) \subset \T_V$ as all gauges are continuous}
	\EndProof
	\\
	\Explain{ Note: There should exists a $\VS{k} \to \mathsf{ORD}$  functor equivalence}
 	\Explain{ Take functors of saturated seminorm cones an locally convex topologies}
}\Page{
	\DeclareType{Saturated}{\prod_{V \in \VS{k}} ??\SMN(k)}
	\DefineNamedType{\N}{Saturated}
	{
		\forall \nu,\mu \in \N \. \max(\nu,\mu) \in \N	
	}
	\\	
	\DeclareFunc{saturatedSeminormCones}
	{\Cov( \VS{k}, \mathsf{ORD}  )}
	\DefineNamedFunc{saturatedSeminormCones}{V}{\mathsf{SSC}(V)}
	{
		\TYPE{Saturated}(V) \And \CC\Big( \S\L(V)\Big) 
	}
	\DefineNamedFunc{saturatedSeminormCones}{V,W,*}{\mathsf{SSC}_{V,W}(T)}
	{
		(T^*)^{-1}
	}
	\\
	\Theorem{SeminormedProductTopolgy}
	{
		\NewLine		
		\forall I \in \SET \.
		\forall V : I \to \TVS{k} \. 
		\forall \N : \prod_{i \in I} ?\SMN(V) \.
		\prod_{i \in \I} \Big( V_i, \T(\N_i) \Big) 
		\cong_\TOP 
		\left( \prod_{i \in I} V_i,  \Big\{ \pi_i^* \nu \Big| i \in I, \nu \in \N_i  \Big\} \right)
	}
	\Explain{ 1 This may be seen as functorial eqiavalence interacting with limits}
	\Explain{ 2 And weak topologies are limits}	
	\EndProof
	\\
	\Theorem{LocallyConvexProduct}
	{
		\NewLine		
		\forall I \in \SET \.
		\forall V : I \to \LCS{k} \. 
		\prod_{i \in I} V_i \in \LCS{k}
	}
	\Explain{ 1 Now this is obvious}
	\EndProof
}\Page{
	\Theorem{LocallyConvexSemimetrizability}
	{
		\NewLine ::		
		\forall V \in \LCS{k} \.
		\TYPE{Semimetrizable}(V)
		\iff
		\exists \nu : \Nat \uparrow C(V) \And \SMN(V) \. 
		\T_V = \T(\im \nu)
	}
	\Explain{ 1$(\Rightarrow)$ assume $V$ is semimetrizable}
	\Explain{ 1.1 Then there exists a decreasing sequence of disked neighborhoods of unity $D$
		which generate the toplogy}
	\Explain{ 1.2 Then $\gamma(\bullet|D_n)$ is clearly a sequence of seminorms we seek}
	\Explain{ 2$(\Leftarrow)$ assume $\nu$ are seminorms of the hypothesis}
	\Explain{ 2.1 Define $\mu(x) = \sum^\infty_{n=1} 2^{1 - n} \frac{\nu_n(x)}{1 + \nu_n(x)}$}
	\Explain{ 2.2 Then $\mu$ is an F-seminorm} 
	\Explain{ 2.2.1 Assume $\alpha \in \Disc_k(0,1)$ and $v \in V$}
	\Explain{ 2.2.2 Then  
	  $\frac{\nu_n(\alpha v)}{1 + \nu_n(\alpha v)}
		=	\frac{|\alpha|\nu_n(v)}{1 + |\alpha|\nu_n(v)} \le 
			\frac{\nu_n(v)}{1 + \nu_n(v)}$   for any $n \in \Nat$}
	\Explain{ 2.2.2.1 Note, that $f(x) = \frac{x}{1 + x}$ is increasing for $x > 0$}
	\Explain{ 2.2.2.1.1 $f'(x) = \frac{1}{(1 + x)^2} > 0$}
	\Explain{  2.2.2.2 And $|\alpha|\nu_n(v) \le \nu_n(v)$ for any $n \in \Nat$}
	\Explain{ 2.2.3 Thus $\mu(\alpha v) \le \mu(v)$}
	\ExplainFurther{ 
		2.2.4 Also $\lim_{m \to\infty} \mu\left( \frac{v}{m} \right) =
					\lim_{m \to \infty} 
					\sum^\infty_{n=1} 2^{1 - n} \frac{\nu_n(v/m)}{1 + \nu_n(v/m)} =
					\sum^\infty_{n=1} \lim_{m \to \infty}  
					\frac{2^{1 - n}}{m} \frac{\nu_n(v)}{1 + \nu_n(v/m)}   = 0
		$} 
	\Explain{ by dominated convergence theorem
		with dominator $x_n = 2^{2-n}$}
	\ExplainFurther{ 2.2.5
		The Minkowsky inequality for $\mu$ is obvious from metric topology}
	\Explain{ 2.3
		By construction $\mu$ is continuous in a topology defined by $(\nu_n)^\infty_{n=1}$
		by construction}
	\Explain{ 2.3.1 $\mu$ is a uniform limit of continuous functions}
	\Explain{ 2.4 Also F-seminorm $2^{1-n} \frac{\nu_n}{\nu_n + 1} \le \mu $
		for each $n$}
	\Explain{
		2.5 so each F-seminorm $2^{1-n} \frac{\nu_n}{\nu_n + 1}$
		is continuous in the topology defined  by $\mu$}
	\Explain{
		2.6 But this means that each $\nu_n$ is also continuous in this topology
	}
	\EndProof
	\\
	\DeclareFunc{continuousDual}{\prod k : \TYPE{TopologicalField} \. \TVS{k} \to \VS{k}}
	\DefineNamedFunc{continiousDual}{ V  }{V'}{V^* \cap \TOP(V,k) }
	\\
	\Theorem{DiscontinuousFunctionalExists}
	{
		\forall  V \in \LCS{k} \.
		\forall \aleph : \TYPE{Semimetrizable}(V) \.
		\forall \beth : \dim V = \infty \.
		\exists	(V^* \setminus V')
	}
	\Explain{ 1 Let $\rho$ be a semimetric for $V$ }
	\Explain{ 2 Then there exists an infinite
		linearly independent sequence $(e_n)^\infty_{n=1}$}
	\Explain{ 3 Extend $(e_n)^\infty_{n=1}$ to a Hamel basis $H$}
	\Explain{ 4 As $V$ is semimetrizable it is possible to select a countables decreasing base
		of absorbent discs $(D_n)^\infty_{n=1}$}
	\Explain{ 5 Then it is possible to selecect $\lambda_n$ such that $\lambda_n e_n \in D_n$}
	\Explain{ 6 Obviously, then $\lim_{n \to \infty} \lambda_n e_n = 0$}
	\Explain{ 7 Define linear functional $f$ by $f(e_n) = \frac{1}{\lambda_n}$ and
		and $f(h) = 0$ if $h$ is linearly independent from all $e_n$}
	\Explain{ 8 Then clearly $lim_{n \to \infty} f(\lambda_n e_n) = 1$, so $f$ can't be contiuous}
	\EndProof
}\Page{
	\Theorem{FinitieDimensionByContinuousFunctionals}
	{
		\NewLine ::
		\forall V : \NS(k) \. 
		\dim V < \infty \iff V' = V^*
	}
	\Explain{1 As $V$ is metric and locally convex this follows from the precious result}
	\EndProof
	\\
	\Theorem{FinestLocallyConvexSpaceIsNotMetrizable}
	{
		\NewLine ::		
		\forall V \in \VS{k} \.
		\forall \aleph : \dim V = \infty \.
		\neg \TYPE{Metrizable}\Big( V, \W_V(V^*,k,\id)\Big)
	}
	\Explain{1 As $V$ is locally convex this follows from the precious result}
	\EndProof
	\\
	\DeclareFunc{defininigSeminorms}{\prod V \in  \LCS{k} \. \mathsf{SSC}(V) }
	\DefineNamedFunc{definingSeminorms}{   }{\ssc(V)}{\SMN(V) \cap \TOP(V,\Reals) }
	\\
	\Theorem{ConvergenceInLocallyConvexSpace}
	{	
		\NewLine ::		
		\forall V : \LCS{k} \.
		\forall (\Delta,x) : \TYPE{Net}(V) \.
		\forall v \in V \.
		\lim_{\delta \in \Delta} x_\delta = v \iff
		\forall \nu \in \ssc(V) \. \lim_{\delta \in \Delta} \nu(x_\delta - v) = 0
	}
	\Explain{ 1 $(\Rightarrow)$ This is obvious as each $\nu$ is continuous}
	\Explain{ 2 $(\Leftarrow)$  Assume $D$ is an open disc in $V$}
	\Explain{ 2.1 as $D$ is open disc then $\gamma(\bullet|D) \in \ssc(V)$ is continuous}
	\Explain{ 2.2 But this meand that $\lim_{\delta \in \Delta} \gamma(x_\delta -v| D) = 0$ }
	\Explain{ 2.3 So $x_\delta - v$ is eventually inside $D$}
	\Explain{ 2.4 As $D$ was arbitraty this means that $\lim_{\delta \in \Delta} x_\delta = v$ }
	\EndProof
	\\
	\Theorem{CauchyPropertyInLocallyConvexSpace}
	{	
		\NewLine ::		
		\forall V : \LCS{k} \.
		\forall (\Delta,x) : \TYPE{Cauchy}(V) \.
		\forall \nu \in \ssc(V) \.
		\TYPE{Cauchy}(V,\Delta , \nu(x))
	}
	\Explain{1 This is true as every $\nu$ is uniformly continuous}
	\EndProof
	\\
	\Theorem{LocallyConvexContinuityCriterion}
	{	
		\NewLine ::		
		\forall V,W : \LCS{k} \.
		\forall T \in \VS{k}(V,W) \.
		T \in \LCS{k} 
		\iff
		\forall \nu \in \ssc(W) \.
		\exists \mu \in \ssc(V) \.
		T^* \nu \le \mu 
	}
	\Explain{1 $(\Rightarrow)$ True as $T^* \nu$ is continuous as composition and 
		$T^* \nu \le T^* \nu$}
	\Explain{2 $(\Leftarrow)$ As $T* \nu \le \mu$ the seminorm $T^* \nu$ is continuous by domination}
	\Explain{2.1 Then the result follows by universal property of weak topology}
	\EndProof
}\Page{
	\Theorem{ContinuousIfBounded}
	{
		\NewLine ::
		\forall V,W : \NS(k) \.
		\forall T \in \VS{k}(V,W) \.
		T \in \TOP(V,W)
		\iff
		T \in \B(V,W)
	}
	\Explain{ 1 Now this is obvious specification of the previous result}
	\EndProof
	\\
	\ExplainFurther{Note:  This is intersting how the fundamental theorem 
		of elementary functional analysis} 
	\Explain{ can be seen as application of the universal property of weak topology}
	\\
	\Theorem{KernelSeparationLemma}
	{
		\forall V : \VS{k} \.
		\forall f \in V^* \.
		\forall v \in V \.
		\forall \aleph : f(v) = 1 \. \NewLine \.
		\forall U : \TYPE{Balanced}(V) \.
		(v + U) \cap \ker f = \emptyset
		\iff 
		\forall u \in U \. |f(u)| < 1
	}
	\Explain{   1 $(\Rightarrow)$ Assume $x + U \cap \ker f = \emptyset$ }
	\Explain{ 1.1 Assume there is $u \in U$ such that $|f(u)| \ge 1$ }
	\Explain{ 1.2 As $U$ is balanced, then $w = -\frac{u}{f(u)} \in U$}
	\Explain{ 1.3 But $f(v + w) = f(v) + f(w) = 1 - 1 = 0$, a contradiction !}
	\Explain{ 2 $(\Leftarrow)$ Assume $\forall u \in U \. |f(u)| < 1$ is the case}
	\Explain{ 2.1 $f(v) \neq - f(u)$ for any $u \in U$}
	\Explain{ 2.2 So $f(v + u) = f(v) + f(u) \neq 0$}
	\EndProof
	\\
	\Theorem{ContinuousByClosedKernel}
	{
		\forall V \in \TVS{k} \.
		\forall f \in V^* \.
		f \in V'
		\iff
		\Closed(V,\ker f) 
	}
	\Explain{ 1 $(\Rightarrow)$ This direction is obvious as $k$ is Hausdorff}
	\Explain{ 2 $(\Leftarrow)$ Now assume $\ker f$ is closed}
	\Explain{ 2.1 If $f = 0$ then continuity is trivial}
	\Explain{2.2 So assume there is $x$ such that $f(x) \neq 0$}
	\Explain{ 2.2.1  Without loss of generality assume $f(x) = 1$}
	\Explain{ 2.2.2 Then there is some balanced open $U$
		such that $U_\gamma +  x \cap \ker f = \emptyset $}
	\Explain{ 2.2.3 But this means that $\forall u \in U \. |f(u)| < 1$}
	\Explain{ 2.2.4 This means that $\Disc(|f|) \in \N_V(0)$}
	\Explain{ 2.3 So $f$ is continuous}
	\EndProof
	\\
	\Theorem{ContinuousByRealPart}
	{
		\forall V \in \TVS{\Complex} \.
		\forall f \in V^* \.
		f \in V'
		\iff
		\Re f \in C(V)
	}
	\Explain{ 1 write $f(v) = \Re f(v) - \i \Re f(\i v)$  }
	\EndProof
	\\
	\Theorem{ContinuousFunctionalIsOpen}
	{
		\forall V \in \TVS{k} \.
		\forall f \in V' \.
		f \neq 0
		\Imply
		\Open(V,k,f)
	}
	\Explain{ 1 As $f \neq 0$ this musbe the case that $f$ is surjective}
	\Explain{ 2 So $f$ is open as it linear, continuous and surjective}
	\EndProof
}
\newpage
\Page{
	\Theorem{ContinuityOfMultilinearMap}
	{
		\NewLine ::		
		\forall n \in \Nat \.
		\forall V : \{1,\ldots,n\} \to \LCS{k} \.
		\forall W \in \LCS{k} \.
		\forall A : \bigotimes^n_{i=1} V_i \to W \. \NewLine \.
		A \in \TVS{k}\left(  \bigotimes^n_{i=1} V_i ,  W \right)
		\iff
		\forall \nu : \prod_{i \in I} \ssc(V_i) \.
		\forall \mu \in \ssc(W) \.
		\exists \lambda \in \Reals_{++} \.
		A\mu \le \lambda \prod^n_{i=1} \nu_i 
	}
	\Explain{
		This follows from the theory of norms on tensor spaces}
	\EndProof
}
\subsubsection{Spaces of Continuous Functions}
\Page{
	\DeclareFunc{compactOpenTopology}
	{
		\prod X \in \TOP \. \Top\Big(\TOP(X,k)\Big)
	}
	\DefineNamedFunc{compactOpenTopology}{}{\kappa_X}
	{
		\T \Big( 
			\big\{ \Lambda f \in \TOP(X,k) \.  \sup_{x \in K} |f(x)| \big| K \in \K(X) \big\} \Big)		
	}
	\\
	\Theorem{SpaceWithCompactOpenTopology}
	{
		\forall X \in \TOP \. V = \Big( \TOP(X,k), \kappa_X \Big) \in \LCHS{k}
	}
	\Explain{ 1 Topology on $V$ is generated by seminorms, so $V$ is locally convex}
	\Explain{ 2 As sets $\{x\}$ are dcompact, 
		the evaluation seminorm $\epsilon_x : f \mapsto |f(x)|$ is continuous for $V$}
	\Explain{
		3 If $f \neq 0$ then there is some $x \in X$ such that $f(x) \neq 0$ 
	}
	\Explain{ 4 So $\epsilon_x(f) \neq 0$  and this means that $V$ is Hausdorff}
	\EndProof	
	\\
	\DeclareType{Hemicompact}{?\TOP}
	\DefineType{X}{Hemicompact}{
		\exists \C : \TYPE{Countable}\Big( \K(X) \Big) \. \forall K \in \K(X) \. \exists F \in \C \. K \subset F 
	}
	\\
	\Theorem{CompactOpenTopologyMetrization}
	{
		\forall X \in \TYPE{T3.5} \.
		\TYPE{Hemicompact}(X)
		\iff
		\TYPE{Metrizable}\Big( \TOP(X,k), \kappa_X \Big)
	}
	\Explain{ 1 $(\Rightarrow)$ Assume $X$ is hemicompact}
	\Explain{ 1.1 Then let $F$ be an enumeration of the set $\C$ from the definition of hemicompact}
	\Explain{ 1.2 Without loss of generality we may assume that $F$ is increasing}
	\Explain{ 1.3 Then $\nu_n(f) = \sup_{x \in F_n} |f(x)|$ is an increasing family of seminorms}
	\Explain{ 1.4 By hemicompactness $\nu_n$ defines $\kappa_X$}
	\Explain{ 1.5 So the $\kappa_X$ is metrizable}
	\Explain{ 2 $(\Leftarrow)$ now assume $\kappa_X$ is metrizable}
	\Explain{ 2.1 Then there is a countable base defined by sup-functionals for some compacts $F_n$}
	\Explain{ 2.2 Then for any compact $K$ its sup-functional is less then a scalar multiple of
		a sup-functional of some $F_n$}
	\Explain{ 2.3 Assune This is the case, but $K \not \subset F_n$ }
	\Explain{ 2.4 Then there is some $x \in K \setminus F_n$}
	\Explain{ 2.5 Also there is some $f \in \TOP(X,k)$ such that $f(x) = 1$ and $f(F_n)=\{0\}$}
	\Explain{ 2.5.1 This is true as $X$ is Tychonoff and Hausdorff}
	\Explain{ 2.6 Then $\sup_{x \in K} |f(x)| \ge \sup_{x \in \F_n} |f(x)|$ which is a contradiction}
	\Explain{ 2.7 So $X$ must be hemicompact}
	\EndProof 
	\\
	\DeclareType{KRSpace}{\TOP \to ?\TOP}
	\DefineType{X}{KRSpace}
	{
		\Lambda Y  \in \TOP		
		\forall f : X \to Y \. 
		\Big( \forall K \in \K(X) \. f_{|K} \in \TOP(K,Y) \Big)
		\Imply
		f \in \TOP(X,Y)
	}
}\Page{
	\Theorem{CompactOpenTopologyCompleteness}
	{
		\forall X : \TYPE{T3.5} \.
		\TYPE{KRSpace}(k,X)
		\iff
		\Complete\Big( \TOP(X,k),\kappa_X \Big)
	}
	\Explain{ 1 $(\Rightarrow)$: Assume $X$ is a KRSpaces for $k$}
	\Explain{ 1.1 Take $f$ to be a Cauchy sequence for $\kappa_X$}
	\Explain{ 1.2 Then $f(x)$ is also Cauchy as $\{x\}$ is compact for any $x \in X$}
	\Explain{ 1.3 Thus, as $k$ is complete $F = \lim_{n \to \infty} f_{n}$ exists}
	\Explain{ 1.4 On every compact $K$ the convergence of $f_{|K}$ towards $F_{|K}$ is uniform
		so $F_{|K}$ is continuous}
	\Explain{ 1.5 But as $X$ is KRSpace the whole $F$ must be continuous}
	\Explain{ 1.6 So $\kappa_X$ is complete}
	\Explain{ 2 $(\Leftarrow)$: Now assume that $\kappa_X$ is complete}
	\Explain{ 2.1 Take some $f: X \to k$ such that $f_{|K}$ is continuous for any comapct $K$}
	\Explain{ 2.2 Then by Tietze extension theorem  $f_{|K}$ can extended
		to a continuous function $F_K : \beta X \to k$}
	\Explain{ 2.3 By properties of Tietze-Urysohn extension we may assume that $\sup F_K = \sup f_{|K}$}
	\Explain{ 2.4 Define $g_K = F_{K|X}$}
	\Explain{ 2.5 The set $\K(X)$ is directed}
	\Explain{ 2.6 Then $g_K$ is a Cauchy net}
	\Explain{ 2.6.1 Take $K$ be a compact in $X$ and let $\nu_K(f) = \sup_{x \in K} |f|$}
	\Explain{ 2.6.2 Then 
		$\nu_K(g_L - g_H) = 0$ for any $L,H \in \K(X)$ such that $K \subset L$ and $K \subset H$ }
	\Explain{ 
		2.6.3 So $g_L - g_H \in \Cell(\nu_K)$ in this case}
	\Explain{
		2.7 Thus there exists a continuous limit $G$ for $\kappa_X$}
	\Explain{
		2.8 But $G = f$
	}
	\Explain{ 2.8.1
		If $x \in X$ then $g_K(x) = f(x)$ for any $K \in \K(X)$ such that $x \in K$}
	\Explain{ 2.9
		Thus $f$ is continuous}
	\EndProof
	\\
	\DeclareFunc{pointwiseConvergenceTopology}
	{
		\prod X \in \TOP \. \Top\Big(\TOP(X,k)\Big)
	}
	\DefineNamedFunc{pointwiseConvergenceTopology}{}{\pi_X}
	{
		\T \Big( 
			\big\{ \Lambda f \in \TOP(X,k) \.  |f(x)| \big| x \in X \big\} \Big)		
	}
	\\
	\Theorem{SpaceWithPointeisConvergenceTopology}
	{
		\forall X \in \TOP \. V = \Big( \TOP(X,k), \kappa_X \Big) \in \LCHS{k}
	}
	\Explain{ 1 Topology on $V$ is generated by seminorms, so $V$ is locally convex}
	\Explain{
		2 If $f \neq 0$ then there is some $x \in X$ such that $f(x) \neq 0$ 
	}
	\Explain{ 3 So $\epsilon_x(f) \neq 0$  and this means that $V$ is Hausdorff}
	\EndProof	
	\\
	\Theorem{PointwiseConvergence}
	{
		\NewLine ::		
		\forall X \in \TOP \.
		\forall (\Delta,f) : \TYPE{Net}\Big( \TOP(X,k) \Big) \.
		\forall g \in \TOP(X,k) \.
		\lim_{\delta \in \Delta} f_\delta =_{\pi_X} g
		\iff
		\forall x \in X \.
		\lim_{\delta \in \Delta} f_\delta(x) = g(x)
 	}
 	\NoProof
}\Page{
	\DeclareType{Equicontinuous}
	{
		\prod X \in \TOP \.
		\prod G \in \TGRP \.
		??\TOP(X,G)
	}
	\DefineType{\F}{Equicontinuous}
	{
		\forall x \in X \.
		\forall V \in \U_G(e) \.
		\exists U \in \U_X(x) \.
		\forall f \in \F \.
		f(U) \subset f(x) V
	}
	\\
	\DeclareType{Equibounded}
	{
		\prod X \in \TOP \.
		??\TOP(X,k)
	}
	\DefineType{\F}{Equibounded}
	{
		\forall x \in X \.
		\exists \beta \in \Reals_{++} \.
		\forall f \in \F \.
		|f(x)| \le \beta
	}
	\\
	\Theorem{EquicontinuousTopologyEquality}
	{
		\forall X \in \TOP \.
		\forall \F : \TYPE{Equicontinuous}(X,k) \.
		(\F,\kappa_X) = (\F,\pi_X) 
	}
	\Explain{1 Firstly, $\kappa_X \subset $}
	\Explain{1.1 Take $g \in \F$}
	\ExplainFurther{1.2 Assume $U \in \kappa_X(g)$ 
		has form $U = \Big\{ f \in \TOP(X,k) : \sup_{x \in K} |f(x)-g(x)| < \alpha \Big\}$}
	\Explain{ for some compact $K$ and $\alpha \in \Reals_{++}$} 
	\Explain{1.3 Then for each $x \in K$ there is some $W_x \in \U_X(x)$ 
		such that $f(W_x) \subset f(x) + \Cell_k(0,\alpha/4)$ for each $f \in \F$}
	\ExplainFurther{1.4 As $K$ is compact and $W$ is an open cover we can select
		a finite family of points $(x_{i})_{i=1}^n$}
	\Explain{  such that 
		$K \subset \bigcup^{n}_{i=1} W_{x_i}$}
	\Explain{ 1.5 Let $\epsilon_y$ stand for evaluation seminorm 
		$\epsilon_y(f) =  |f(y)|$}
	\Explain{ 1.6  Then $V =\bigcap^n_{i=1} \frac{\alpha}{2} \Cell(\epsilon_{x_i}) + g \in \pi_X$
		and $V \subset U$ in $\F$}
	\Explain{ 1.6.1 Take some $f \in V \cap \F$ and some $y \in K $}
	\Explain{ 1.6.2 Then there is some $i \in \{1,\ldots,n\}$ such that $y \in W_{x_i}$}
	\Explain{ 1.6.3       
		$
			|f(y) - g(y)| \le  
			|f(y) -  f(x_i)|  +
			|f(x_i) - g(x_i)| +
			|g(x_i) - g(y)| < \alpha
 		$
	}
	\Explain{ 1.6.4 So $\sup_{K} |f - g| < \alpha$}
	\Explain{ 1.7 This means that $U$ is open in $\pi_X$}
	\Explain{ 2 This is obvious from definition that $\pi_X \subset \kappa_X$ 
		and $\pi_X = \kappa_X$}
	\EndProof
	\\
	\Theorem{PointwiseClosureEquicontinuous}
	{
		\NewLine ::		
		\forall X \in \TOP \.
		\forall \F : \TYPE{Equicontinuous}(X,k) \.
		\TYPE{Equicontinuous}\Big( X, k ,\cl_{\pi_X} \F\Big)  
	}
	\Explain{ 1 Take $x \in X$ and $V \in \U_k(0)$}
	\Explain{ 2 Then by equicontinuity there is $U \in \U_X(x)$
		such that $f(U) \subset f(x) + V$ for any $f \in \F$}
	\Explain{ 3 Take $g$ to be a limit point in $\F$}
	\Explain{ 4 Then there is sequence $f$ such that $\lim_{n \to \infty} f_n = g$ pointwise}
	\Explain{ 5 Take some $u \in U$}
	\Explain{ 6 Then $g(u) = \lim_{n \to \infty} f_n(u)$}
	\Explain{ 7 Then 
		$|g(u) - g(x)| \le |g(u) - f_n(u)| + |f_n(u)  - f_n(x) | + |f_n(x) - g(x)| \le 3\varepsilon$
		for suitably choosen $n$}
	\Explain{ 8 So $\cl_{\pi_X} \F$ is equicontinuous}
	\EndProof
}\Page{
	\Theorem{ArzeloAscoli1}
	{
		\NewLine ::		
		\forall X \in \TOP \.
		\forall \F  : \TYPE{Equicontinuous}(X,k) \And \TYPE{Equibounded}(X) 
		 \And \Closed\Big(\TOP(X,k),\kappa_X,\F\Big)		
		\. \NewLine \.
		\Compacts\Big( \TOP(X,k), \pi_X, \F\Big)
	}
	\Explain{ 1 Eeach $\F(x)$ is a compact subset of $k$ by Heine-Borel Lemma}
	\Explain{ 2 So by Tychonoff theorem $\prod \F(x)$ is compact in the product topology}
	\Explain{ 3 But $\F$ is a closed subset of $\prod \F(x)$ in $\pi_X$, 
		so $\F$ is also compact in $\pi_X$}
	\Explain{ 4 As $\F$ is equicontinuous $\pi_X$ is equal to $\kappa_X$ on $\F$,
			so $\F$ is also compact in $\kappa_X$}
	\EndProof
	\\
	\Theorem{ArzeloAscoli2}
	{
		\NewLine ::		
		\forall X  : \TYPE{LocallyCompact} \.
		\forall \F  : \Compacts\Big( \TOP(X,k), \kappa_X, \F\Big) \. \NewLine \.
		 \TYPE{Equicontinuous}(X,k,\F) \And \TYPE{Equibounded}(X,\F) 
		 \And \Closed\Big(\TOP(X,k),\pi_X,\F\Big)
	}
	\NoProof
}
\newpage
\subsubsection{Constructions}
\Page{
	\Theorem{SubspaceQuotientSeminorm}
	{
		\NewLine ::		
		\forall V \in \LCS{k} \.
		\forall U \subvec{k} V  \.
		\T\left( \frac{V}{U} \right) = 
		\T\left( \left\{   \Lambda [v] \in \frac{V}{U} \.  \inf_{u \in U} \nu(v + u) \bigg| \nu \in \ssc(V)
		\right\} \right)
	}
	\Explain{ 1 Let $\nu \in \ssc(V)$}
	\Explain{ 2 define $\mu = \Lambda [v] \in \frac{V}{U} \.  \inf_{u \in U} \nu(v + u)$}
	\Explain{ 3 Then $\mu$ is a seminorm}
	\Explain{ 3.1 $[v] = 0$ imply $v \in U$ }
	\Explain{ 3.2 So $\mu=0$ as $\nu(w) \ge 0$ and $\nu=0$}
	\Explain{ 3.3 Take $[v] \in \frac{V}{U}$ and $\alpha \in k$}
	\Explain{ 3.4 Then $\mu[\alpha v] = 
		\inf_{u \in U} \nu(\alpha v + u) = \inf_{u \in U} \nu(\alpha v  + \alpha u ) =
		|\alpha|   \inf_{u \in U} \nu( v + u) = |\alpha|\mu[v]
		$}
	\Explain{ 3.5 Now take $v,w \in V$} 
	\ExplainFurther{ 3.6 Then    
			$			
			\mu[ v +w]	=
			\inf_{u \in U} \nu(v + w + u) =
			\inf_{u,o \in U} \nu(v + w + u + o) \le 
			\inf_{u,o \in U}  \nu(v + u) + \nu(w + o) =$}
	\Explain{
			$\quad  = \inf_{u \in U} \nu(v + u) + \inf_{o \in U} \nu(v + o) 
			\mu[v] + \mu[w]
			$}
	\Explain{ 4 Then $\Cell(\mu) = \pi_U \Cell(\nu)$}
	\ExplainFurther{ 5 As open cells as above form a base of topology on $V$,}
	\Explain{ $\quad$ and quotien topology is an image topology, the result follows}
	\EndProof
	\\
	\Theorem{LocallyConvexQuotient}
	{
		\forall V \in \LCS{k} \.
		\forall U \subvec{k} V \.
		\forall \frac{V}{U} \in \LCS{k}	
	}
	\Explain{
		1 This is True as topology on $\frac{V}{U}$	is generated by seminorms}
	\EndProof
	\\
	\DeclareFunc{kernelOfSeminorm}
	{
		\prod_{V \in \VS{k}} 
		\SMN(V) \to \TYPE{VectorSubspace}(V)
	}
	\DefineNamedFunc{kernelOfSeminorm}{\nu}{\ker \nu}{\nu^{-1}\{0\}}
	\\
	\Theorem{SeminormedCompletion}
	{
		\forall V : \TYPE{SeminormedSpace}(k) \.
		\exists (\hat V,\iota) : \TYPE{TVSCompletion}(V) \.
		\SMS(k,\hat V) 
	}
	\Explain{ 1 Take $[v] \in \hat V$}
	\Explain{ 2 Then $[v]$ can associated with Cauchy sequence  $v$}
	\Explain{ 3 Define $\nu_{\hat V}[v] = \lim_{n \to \infty} \nu_V(v_n)$ }
	\Explain{ 3.1 As $\nu_V$ is uniformly continuous the $\nu_V(v_n)$ must be again Cauchy, 
		and hence convergent as $k$ is complete}
	\Explain{ 3.2 Use completion metric argument to see that $\nu_{\hat V} is Uniquely determined$}
	\Explain{ 3.2.1 Assume $x$ an $y$ are both Cauchy sequences for $[v]$}
	\Explain{ 3.2.2 Then 
		$\lim_{n \to \infty} |\nu_V(x_n) - \nu_V(y_n)|   \le 
		 \lim_{n \to \infty} \nu_V(x_n - y_n)  =
		 \lim_{n \to \infty} \rho_V(x_n,y_n) = 0   		
		$}
	\EndProof
}\Page{
	\Theorem{SeminormedSpaceProductEmbedding}
	{
		\forall V \in \LCS{k} \.
		\exists I \in \SET \.
		\exists W : I \to \TYPE{SeminormedSpace} \. \NewLine \.
		\exists U \subvec{k} \prod_{i \in I} W_i \.
		V \cong_{\TVS{k}} W
	}
	\Explain{ 1 For $\nu \in \ssc(V)$ define $W = (V,\nu)$}
	\Explain{ 2 Then the mapping $x \mapsto (x)_{\nu \in \ssc(V)}$ is an isomorphism}
	\EndProof
	\\
	\Theorem{BanachSpaceProductEmbedding}
	{
		\forall V \in \LCHS{k}\.
		\exists I \in \SET \.
		\exists W : I \to \BAN(k) \. \NewLine \.
		\exists U \subvec{k} \prod_{i \in I} W_i \.
		V \cong_{\TVS{k}} W
	}
	\Explain{ 1 For $\nu \in \ssc(V)$ define $W = \widehat{\left(\frac{V}{\ker \nu}\right)}$}
	\Explain{ 2 Then each $W_\nu$ is an Banach space}
	\Explain{ 3 Then the mapping $\phi:x \mapsto ([x]_{\ker \nu})_{\nu \in \ssc(V)}$ is an isomorphism}
	\Explain{ 3.1 $\phi$ is one-to-one as $V$ is hausdorff}
	\Explain{ 3.1.1 For any $v \in V$ such that $v \neq 0 $
		exists $\nu \in \ssc(V)$ such that $\nu(v) \neq 0$}
	\Explain{ 3.1.2 So $[v]_{\ker \nu} \neq 0$}	
	\EndProof
	\\
	\Theorem{LCSCompletion}{
			\forall V \in \LCS{k} \.
			\exists (\hat V,\iota) : \TYPE{TVSCompletion}(V) \.
			\hat V \in \LCS{k}
	}
	\Explain{ 1 Construct product emedding $\phi : V \hookrightarrow \prod_{\nu \in \ssc(V)} W_\nu$ as in the previous theorem}
	\Explain{ 3 This embedding can be extended to the embedding into a complete 
		vecor space $\prod_{\nu \in \ssc(V)} \hat W_\nu$}
	\Explain{ 3.1 The product of complete spaces is complete}
	\Explain{ 4 Then $\cl_{\hat W} \phi(V)$ is a closed subset of the complete space}
	\Explain{ 5 So $\hat V = \cl_{\hat W} \phi(V)$ is the sought completion}
	\EndProof
	\\
	\Theorem{LCHSCompletion}{
			\forall V \in \LCHS{k} \.
			\exists (\hat V,\iota) : \TYPE{TVSCompletion}(V) \.
			\hat V \in \LCHS{k}
	}
	\Explain{ 1 Same argument as above}
	\EndProof
}
\newpage
\subsubsection{Non-Archimedean Spaces}
\Page{
	& k : \TYPE{UltravaluedField}; \\
	\\
	\DeclareType{Ultraseminorm}
	{
		\prod_{V \in \VS{k} }
		?\SMN(V)
	}
	\DefineType{\nu}{Ultraseminorm}
	{
		\forall v,w \in V \. \nu(v + w) \le \max\Big( \nu(v),\nu(w)\Big)	
	}
	\\
	\Theorem{UltraseminormMaximumPrinciple}
	{
		\NewLine ::		
		\forall V \in \VS{k} \.		
		\forall v,w \in V \. 
		\forall \nu : \TYPE{Ultraseminorm}(V) \.
		\nu(v) < \nu(w) \Imply  \nu(v+w) = \nu(w) 
	}
	\Explain{ 1
		$\nu(w + v) \le \max\Big(\nu(w),\nu(v)\Big) = \nu(w)$
	}   
	\Explain{ 2
		$ \nu(w) = \nu\Big(v  - (w + v) \Big) \le \max\Big( \nu(v), \nu(w+v) \Big) = \nu(w + v)$}
	\Explain{ 2.1
		This must be the case as $\nu(v) < \nu(w)$}
	\Explain{ 3
		$\nu(w) = \nu(w + v)$	
	}
	\EndProof
	\\
	\Theorem{Ultradisc}
	{
		\NewLine ::
		\forall V \in \VS{k} \.
		\forall \nu : \TYPE{Ultraseminorm}(V) \.
		\AKC \And \TYPE{Absorbent} \Big(V,\Cell(\nu)\Big)
	}
	\Explain{1 Assume $v,w \in \Cell(\nu)$ and $\alpha,\beta \in \Disc_k(0,1)$}
	\Explain{2 Then 
		$\nu(\alpha v + \beta w) \le |\alpha|\nu(v) + |\beta|\nu(w) < 1$	
	 }
	\Explain{3 So $\Cell(\nu)$ is K-convex}
	\Explain{4 Take $v \in V$ such that $\nu(v) \neq 0$}
	\Explain{5 Then $\alpha v \in \Cell(\nu)$ for any $\alpha \in k$ such that $|\alpha| < \nu^{-1}(v) $}
	\Explain{6 So $\Cell(\nu)$ is absorbent}
	\EndProof
	\\
	\DeclareFunc{ultragauge}
	{
		\prod_{ V \in \VS{k}}
		\AKC \And \TYPE{Absorbent}(V) \to \TYPE{Ultraseminorm}(V) 
	}
	\DefineNamedFunc{ultragauge}{D}{\upsilon(\bullet| D)}
	{
		\lambda v \in V \.  \inf \Big\{ |\alpha| \Big|\alpha \in k : v \in \alpha D  \Big\}
	}
	\Explain{ 1 It is obvious that the ultragauge is a seminorm}
	\Explain{ 2 Now take $v,w \in V$}
	\Explain{ 3  Then as $D$ is K-convex
		$\upsilon(v + w|D) \le \max\Big( \upsilon(v |D),\upsilon(w|D) \Big) $}
	\Explain{ 3.1 Take a sequence $\alpha,\beta : \Nat \to k_*$
		such that $\alpha_n v \in D, \beta_n w \in D, \lim_{n \to \infty} |\alpha_n|^{-1} = \upsilon(v|D),
		\lim_{n\to\infty}|\beta_n|^{-1}=\upsilon(w|D)$}
	\Explain{ 3.2 Define $\gamma_n = {\arg\max}_{\tau \in \{\alpha_n,\beta_n\}} |\tau$  }
	\Explain{ 3.3 Then $\gamma_n(v + w) \in D$ as $D$ is K-Convex}
	\Explain{ 3.4 Then $\upsilon(v + w | D) \le |\gamma_n| \le \max\Big( |\alpha_n|,|\beta_n| \Big)$  }
	\Explain{ 3.5 Taking limits gives 
		$\upsilon(v + w | D) \le \max\Big(\upsilon(v|D) ,\upsilon(w|D) \Big)$}
	\EndProof
}\Page{
	\Theorem{UltragaugeBound}
	{
		\NewLine ::		
		\forall V \in \VS{k} \.
		\forall D : \AKC \And \TYPE{Absorbent}(V) \.
		\Cell\Big(\upsilon(\bullet|D)\Big) \subset D \subset \Disc\Big(\upsilon(\bullet|D)\Big)
	}
	\Explain{ Pretty obvious}
	\EndProof
	\\
	\Theorem{UltragaugeContinuity}
	{
		\NewLine ::		
		\forall V \in \TVS{k} \.
		\forall D : \AKC \And \TYPE{Absorbent}(V) \.
		D \in \N_V \iff
		\upsilon(\bullet|D) \in C(V)
	}
	\Explain{ 1 $(\Rightarrow)$ Assume $D$ has non-empty interior} 
	\Explain{ 1.1 By previous result this implies that $D$ is open}
	\Explain{ 1.2 Then $\upsilon^{-1}\Big([0,\rho),D\Big)= \bigcup_{\alpha \in \Disc(0,\rho)} \alpha D$}
	\Explain{ 1.3 But $\alpha D$ is also open as multiplication by $\alpha$ is a homeomorphism}
	\Explain{ 1.4 So the ultraguage must be continuous}
	\Explain{ 2 $(\Leftarrow)$ Assume that ultragauge is continuous}
	\Explain{ 2.1 Then $\upsilon^{-1}\Big([0,\rho),D\Big) \subset D$}   
	\Explain{ 2.2 So $D$ has non-empty interior}	
	\EndProof
	\\
	\DeclareFunc{topologyOfUltraseminorms}
	{
		\prod_{V \in \VS{k}} ?\TYPE{Ultraseminorm}(V) \to \Vect\Top(V)
	}
	\DefineNamedFunc{topologyOfUltraseminorms}{\Upsilon}{\T(\Upsilon)}
	{
		\W_V(\Upsilon,\Reals,\id)
	}
	\\
	\Theorem{UltraseminormsDefineLocallyKConvexTopology}
	{
		\NewLine ::		
		\forall V \in \VS{k} \.
		\forall \Upsilon : ?\TYPE{Ultraseminorm}(V)  \.
		\LKConv(k,V,\T(\Upsilon))
	}
	\Explain{1 Take $\upsilon \in \Upsilon$}
	\Explain{2 Then $\Cell(\upsilon)$ is absolutely K-convex}
	\Explain{2.1 See ultradisc theorem}
	\EndProof	
	\\
	\Theorem{LocallyKConvexTopologyIsGeneratedByUltraseminorms}
	{
		\NewLine ::		
		\forall V : \LKConv(k) \.
		\exists \Upsilon : ?\TYPE{Ultraseminorm}(V) \.
		\T_V = \T(\Upsilon)
	}
	\Explain{ Take ultragauges for the K-discs generating the locally K-convex topology}
	\EndProof	
	\\
	\DeclareFunc{definingUltraseminorms}
	{
		\prod V : \LKConv(k) \.
		?\TYPE{Ultraseminorm}(V)
	}
	\DefineNamedFunc{definingUltraseminorms}{V}{\suc}
	{
		C(V) \cap \TYPE{Ultraseminorm}(V)
	}
}\Page{
	\Theorem{Ultrasemimetrization}
	{
		\NewLine ::		
		\forall V \in \LKConv(k) \.
		\TYPE{Ultrasemimetrizable}(V)
		\iff \NewLine \iff
		\exists : \upsilon : \Nat \uparrow \TYPE{Ultraseminorm}(V) \.
		\T_V = \T(\im \upsilon)
	}
	\Explain{ 1 This is simmilar to normal semimetrization theorem }
	\Explain{ 2 Define an F-seminorm 
		$\mu(v) = \sum^\infty_{n=1} \frac{1}{2^n} \frac{\upsilon_n(v)}{1 + \upsilon_n(v)}$}
	\Explain{ 3 The only difference is in the proving the ulrametric property}
	\Explain{ 3.1 Take some $v,w \in V$}
	\Explain{ 3.2 Then $\upsilon_n(v + w) \le \max\Big(\upsilon_n(v),\upsilon_n(w)\Big)$}
	\Explain{ 3.3 But as th function $\frac{x}{x + 1}$ is increasing   
		$ \frac{\upsilon_n(v + w)}{1 + \upsilon_n(v + w)} \le 
			\max\left(\frac{\upsilon_n(w)}{1 + \upsilon_n(v)},\frac{\upsilon_n(w)}{1 + \upsilon_n(w)}  
			\right)$}
	\Explain{ 4 Thus $\mu(v + w) \le  \max\Big(\mu(v),\mu(w)\Big)$  for any $v,w \in V$}
	\Explain{ 5 So $\mu$ defines an ultrasemimetric}
	\EndProof
	\\
	\DeclareType{\LCCompact}
	{
		?\TVS{k}
	}
	\DefineType{V}{\LCCompact}{
	\exists \F : \Filterbase(\N_0(V)) \.
	\forall F \in \F \. \CCompact \And \AKC(V,F)}
	\\
	\DeclareType{Ultranorm}
	{
		\prod_{V \in \VS{k}}	 ?\TYPE{Ultraseminorm}(V)
	}
	\DefineType{\upsilon}{Ultranorm}
	{
		\forall v \in V \. \upsilon(v) = 0 \iff v = 0	
	}
	\\
	\DeclareType{UltranormedSpace}
	{
		? \sum_{V \in \TVS{k}} \TYPE{Ultraseminorm}(V)
	}
	\DefineType{(V,\upsilon)}{UltranormedSpace}
	{
		\T_V = \T\{\upsilon\}	
	}
	\\
	& |\cdot|_k  \neq \Lambda \alpha \in k \. [k \neq 0]  \\
	\\
	\Theorem{LocallyCCompactHasLocllyCCompactField}
	{
		\forall V : \LCCompact(k) \.
		\dim V > 0 \Imply
		\LCCompact(k,k)
	}
	\Explain{ 1 As $k$ has non-trivial valuation
		Every one-dimensional subspace of $V$ is
		isomorphic to  $k$}
	\Explain{ 2 Let $L$ be such one-dimensional subspace}
	\Explain{ 3 And let $C$ be a C-compact neighborhood of $0$ in $V$}
	\Explain{ 4  The $C \cap L$ is C-compact and and reltively open in $L$}
	\Explain{ 5 So $L$ is  locally compact}
	\Explain{ 6 And so is $k$ as it is isomorphic to $L$}
	\EndProof
}\Page{
	\Theorem{LocallyCCompactIsFinDim}
	{
		\forall V : \TYPE{Ultranormed} \And \LCCompact(k) \. \dim  V < \infty 
	}
	\Explain{1 Assume that $\dim V = \infty$}
	\Explain{2 As $V$ is Locally C-compact there is a C-compact neighborhood
		$C$ of $0$ in $V$}
	\Explain{3 Then there is a ball $D \subset C$ if radius $\rho$}
	\Explain{4 Select a topologically linearly independent seqyence $(e_i)_{i=1}^\infty$
		such that $\|e_i\| = \rho$}
	\Explain{5 Define $F_i =  \cl_V \kconv (e_j)_{j=i}^\infty$}
	\Explain{6 Then $(F_i)^\infty_{i=1}$ is a closed k-convex filterbase on $C$}
	\Explain{6.1  The K-convex filterbase property is obvious}
	\Explain{6.2 As all points $e_i,e_j$ are separated, sets $ (e_j)_{j=i}^\infty$ are closed}
	\Explain{6.3 And k-convex hull of closed sets must be closed}
	\Explain{7 This mean that $\bigcap^\infty_{i=1} F_i \neq \emptyset $ as $C$ is C-convex} 
	\Exclaim{8 On the other hand, clearly $\bigcap^\infty_{i=1} F_i = \emptyset$, a contradiction} 
	\Explain{ 8.1 Assume $v \in \bigcap^\infty_{i=1} F_i = \emptyset$}
	\Explain{ 8.2 Then $v \in \Span (e_i)^\infty_{i=1}$ by construction}
	\Explain{ 8.3 But as $v \in F_{i=1}$ it means that its $e_i$ coefficient must be $0$}
	\Explain{ 8.4 So it must be the case that $v = 0$}
	\Explain{ 8.5 But $0$ do not belong to any $F_i$}
	\EndProof
	\\
	\Theorem{LocallyCCompactIsCCompact}
	{
		\forall V : \LCCompact \And \LKConv(k) \.
		 \CCompact(V)
	}
	\Explain{1 $k$ is C-compact}
	\Explain{1.1 Let $\F$ be a K-convex Filter on $k$ }
	\Explain{1.2 Then $\F$ can be structured as a monotonic sequence of balls}
	\Explain{1.3 If $\F$ there is a ball $D$ such tha all  small enough elements $F \in \F$ 
		are in $D$}
	\Explain{1.4 but all closed discs are isomorphic in $k$}
	\Explain{1.5 Thus $D$ is C-compact}
	\Explain{1.6 So $\F$ must have an adherence point in $D$}
	\Explain{1.7 So it also has an adherence point in $k$, and $k$ is C-compact}
	\Explain{2 Then $V \cong k^n$ as $V$ must be finite-dimensional}
	\Explain{3 And $k^n$ is C-compact as a product of C-compact sets}
	\EndProof
}
\newpage
\subsection{Towards Bornology}
\subsubsection{Bounded Sets}
\Page{
	& k : \AVF(\Reals) \Big| \TYPE{UltravaluedField} ; \\
	\\
	\DeclareType{\Bounded}
	{
		\prod V \in \TVS{k} \.  ??V
	}
	\DefineType{B}{\Bounded}
	{
		\forall U \in \U_V(0) \. 
		\exists \lambda \in \Reals \.
		\forall \alpha \in k \.
		|\alpha| \ge \lambda 
		\Imply
		B \subset \alpha U
	}
	\\
	\Theorem{BoundedByBase}
	{
		\NewLine::		
		\forall V \in \TVS{k} \.
		\forall B \subset V \.
		\forall \beta : \TYPE{BalancedBase}\TYPE{Base}(V) \.
		\TYPE{Bounded}(V)  
		\iff
		\forall U \in \B \.
		\exists \alpha \in k \.
		\alpha B \subset U
	}
	\Explain{ Obvious}
	\EndProof
	\\
	\Theorem{BoundedBySeminirms}
	{
		\NewLine::		
		\forall V \in \LCS{k} \.
		\forall B \subset V \.
		\forall \beta : \TYPE{BalancedBase}\TYPE{Base}(V) \.
		\TYPE{Bounded}(V)  
		\iff
		\forall \nu \in \ssc \.
		\Bounded(B,\nu_{|B})
	}
	\Explain{ Obvious}
	\EndProof
	\\
	\Theorem{TotallyBoundedIsBounded}
	{
		\forall V \in \TVS{k} \. 
		\forall B : \TB(V) \.
		\Bounded(V,B) 
	}
	\Explain{ 1 Assume $U \in \U_V(0)$}
	\Explain{ 2 Then where exists a balanced  and absorbing $W \in \U_V(0)$ 
		such that  $W + W \subset V$}
	\Explain{ 
		3 As $B$ is
		totally bounded there is a finite subset $F \subset V$ 
		such that $B \subset W + F$}
	\Explain{
		4 As $W$ is absorbing there exists $\alpha\in k$ such that 
		$F \subset \alpha W$}
	\Explain{
		5 Without loss of generality we may assume that
		$|\alpha| > 1$}
	\Explain{
		5 So, as $W$ is balanced $W \subset \alpha W$}
	\Explain{
		6 Thus, $B \subset \alpha W + \alpha W = \alpha ( W + W) \subset \alpha U$	
	}
	\EndProof
	\\
	\Theorem{KolomogorovsBoundednessCriterion}
	{
		\NewLine ::		
		\forall V \in \TVS{k} \.
		\forall B \subset V \.\
		\Bounded(V,B)
		\iff
		\forall \alpha : \Nat \to k \. 
		\forall b : \Nat \to B \. \Big(
		\lim_{n \to \infty}  \alpha_n = 0
		\Imply
		\lim_{n \to \infty} \alpha_n b_n = 0 \Big)
	}
	\Explain{ 1 $(\Rightarrow)$ This direction is obvious}
	\Explain{ 2 $(\Leftarrow)$ Assume $B$ is not bounded}
	\Explain{ 2.1
		Then there is an $U \in \U_V(0)$ such that for any
		$\rho \in \Reals_{++}$ there is $\alpha \in k$ such
		that $|\alpha| \ge \rho$ an $U \not \subset \alpha B$}
	\Explain{  2.2 
		So there exists sequences $\alpha$ with 
		$|\alpha_n| \le \frac{1}{n}$ and $b:\Nat \to B$
		such that $\alpha_n b_n \not\in U$}
	\Explain{ 2.3
		$|\alpha_n| \le \frac{1}{n}$ imply that
		$\lim_{n \to \infty} \alpha_n = 0$}
	\Explain{ 2.4
		On the other hand
		$ \alpha_n b_n \not\in U$ imply that
		$\lim_{n \to \infty} \alpha_n bbb_n\neq 0 $}
	\Explain{ 2.5
		This conradicts an initial assumption}
	\EndProof
}\Page{
	\Theorem{BoundednesByCountableSubsets}
	{
		\forall V \in \TVS{k} \.
		\forall B \subset V \. \NewLine \.
		\Bounded(V,B)
		\iff
		\forall C: \Countables(V,B) \.
		\Bounded(V,C)
	}
	\Explain{ This follows from Kolmogorov's ctiterion}
	\EndProof
	\\
	\Theorem{BoundedMetrizationTHM}
	{
		\forall V \in \TVS{k} \.
		\forall N \in \N_V(0) \.
		\Bounded(V,N)
		\Imply
		\TYPE{Semimetrizable}(V)
	}
	\Explain{
		$\left( \frac{1}{n} N \right)^\infty_{n=1}$ 
		is a countable base of vector topology for $V$}
	\EndProof
	\\
	\Theorem{BoundedNormizationTHM}
	{
		\forall V \in \TVS{k} \.
		\forall N \in \N_V(0) \.
		\Bounded \And \TYPE{Disc}(V,N)
		\Imply
		\TYPE{Seminormable}(V)
	}
	\Explain{
		Topology may be determined by $\gamma(\bullet|N)$}
	\EndProof
}
\newpage
\subsubsection{Stability under Operations}
\Page{
	\Theorem{SubsetOfBounded}
	{
		\forall V \in \TVS{k} \.
		\forall B : \Bounded(V) \.
		\forall C \subset B \.
		\Bounded(V,B)
	}
	\Explain{ Obvious}
	\EndProof
	\\
	\Theorem{BoundedUnion}
	{
		\forall V \in \TVS{k} \.
		\forall B,C : \Bounded(V) \.
		\Bounded(V,B \cap C)
	}
	\Explain{ Select max}
	\EndProof
	\\
	\Theorem{BoundedScale}
	{
		\forall V \in \TVS{k} \.
		\forall B : \Bounded(V) \.
		\forall \alpha \in k \.		
		\Bounded(V, \alpha B)
	}
	\Explain{ Rescale}
	\EndProof
	\\
	\Theorem{BoundedSum}
	{
		\forall V \in \TVS{k} \.
		\forall B,C : \Bounded(V) \.
		\forall \alpha \in k \.		
		\Bounded(V, B + C)
	}
	\Explain{ Assume $U \in \U_V(0)$}
	\Explain{ Select $V \in \U_V(0)$ such that $V + V \subset U$}
	\Explain{ Then there are two $V$-absorbtion factors $\rho$ and $\sigma$ for $B$ and $C$  
		respectively}
	\Explain{
		If $\alpha \in k$ is such that $|\alpha| \ge \max(\rho,\sigma)$, then
		$  B + C \subset \alpha V + \alpha V = \alpha(V + V) \subset \alpha U$ 
	}
	\EndProof
	\\
	\Theorem{BoundedQuotient}
	{
		\forall V \in \TVS{k} \.
		\forall W\subvec{k} \.
		\forall B : \Bounded(V)\.
		\forall \Bounded\left( \frac{V}{W}, \pi_W(B) \right)
	}
	\Explain{ Use the preimage to determine the absorbtion factor}
	\EndProof
	\\
	\Theorem{BoundedProducts}
	{
		\forall I \in \SET \.		
		\forall V : I \to \TVS{k} \.
		\forall B : \prod_{i \in \I} \Bounded(V_i) \.
		\Bounded\left(\prod_{i\in I} V_i, \prod_{i \in I} B_i \right)
	}
	\Explain{ Assume $U \in \U_{\prod_{i \in I} V_i}(0)$}
	\Explain{ Then there exists $W \in \prod_{i \in I} \T(V_i)$  
		such that that $W_i \neq V_i$ only for a finite set of indices $J \subset I$ 
		and $\prod_{i \in I} W_i \subset U$}
	\Explain{
		Then find a $W_i$-absorbtion factor $\rho_i$ for each $i \in J$ 
	}
	\Explain{ Then $\prod_{i \in I} B_i \subset \alpha \prod_{i \in I} W_i \subset \alpha U$ 
		for any $\alpha \in k$ with $|\alpha| \ge \max_{i \in J} \rho_i$}
	\EndProof
}\Page{
	\Theorem{BoundedClosure}
	{
		\forall V \in \TVS{k} \.
		\forall B : \Bounded(V) \.
		\Bounded(V,\overline B)
	}
	\Explain{ $\overline B$ is bounded for the base of closed neighborhoods of unity}
	\Explain{ Thus,$ \overline B$ is bounded in a general sence}
	\EndProof	
	\\
	\Theorem{BoundedBalancedHull}
	{
		\forall V \in \TVS{k} \.
		\forall B : \Bounded(V) \.
		\Bounded(V,\bal B)
	}
	\Explain{ $\bal B$ is bounded for the base of balanced neighborhoods of unity}
	\Explain{ Thus,$ \overline B$ is bounded in a general sence}
	\EndProof	
	\\
	\Theorem{BoundedConvexHull}
	{
		\forall V \in \LCS{k} \.
		\forall B : \Bounded(V) \.
		\Bounded(V,\conv B)
	}
	\Explain{ $\conv B$ is bounded for the base of disced neighborhoods of unity}
	\Explain{ Thus,$ \overline B$ is bounded in a general sence}
	\EndProof
	\\
	\DeclareType{BoundedBase}
	{
		\prod_{V \in \TVS{k}} ??\Bounded(V)
	}
	\DefineType{\beta}{BoundedBase}
	{
		\forall B : \Bounded(V) \. \exists B' \in \beta \. B \subset B'
	}
	\\
	\Theorem{ClosedDiscsAsBoundedBase}
	{
		\forall V \in \LCS{k} \.
		\TYPE{BoundedBase}\Big(V, \Closed \And \TYPE{Disc}(V) \Big)
	}
	\Explain{ Assume $B$ is bounded in $V$}
	\Explain{ Then the disced hull of $B$ is also bounded}
	\EndProof
}
\newpage
\subsubsection{Locally Bounded Maps}
\Page{
	& k : \AVF(\Reals); \\
	\\
	\DeclareType{\LO}{\prod_{V,W: \TVS{k}} ?(V \to W)}
	\DefineType{f}{\LO}
	{
		\forall B : \Bounded(V) \. \Bounded\Big(W, f(B) \Big)
	}
	\\
	\DeclareType{Homogeneous}{ \prod_{V,W: \VS{k}} ?(V \to W)}
	\DefineType{f}{Homogeneous}{
		\exists \delta \in \Reals_{++} \.
		\forall v \in V \.
		\forall \rho \in \Reals_{++} \.
		f(\rho v) = \rho^\delta f(v)
	}
	\\
	\Theorem{ContunuousHomogenuousIsLocallyBounded}
	{
		\NewLine ::		
		\forall V,W\in \TVS{k} \. 
		\forall f : \TOP \And \Homog(V,W) \.
		\LO(V,W,f)
	}
	\Explain{Pretty obvious if you use basic properties}
	\EndProof
	\\
	\Theorem{BoundedProductsConverse}
	{
		\forall I \in \SET \.		
		\forall V : I \to \TVS{k} \.
		\forall B \subset \prod_{i \in \I} V_i \. \NewLine \.
		\Big(\forall i \in I \. \Bounded(V_i,\pi_i(B)) \Big)
		\iff
		\Bounded\left(\prod_{i\in I} V_i, \prod_{i \in I} B_i \right)
	}
	\Explain{ 1 ($\Imply$) } 
	\Explain{ 1.1 As $\pi_i(B)$ is bounde, so is $\prod_{i \in I} \pi_i(B)$}
	\Explain{ 1.2 Then $B$ is bounded as $B \subset \prod_{i \in I} \pi_i(B)$}
	\Explain{ 2 ($\Leftarrow$)}
	\Explain{ 2.1 In product topology each $\pi_i$ is continuous linear and so locally bounded}
	\EndProof
	\\
	\Theorem{MultilinearIsLocallyBounded}
	{
		\NewLine::		
		 \forall n \in \Nat \.  
		\forall V : \{1,\ldots,n \} \to \TVS{k} \.
		\forall W \in \TVS{k} \. \NewLine \.
		\forall T \in \L(V;W) \TOP\left( \prod^n_{i=1} V_i, W\right) \.
		\LO\left( \prod^n_{i=1} V_i,W,T\right)
	}
	\Explain{Multilinear maps are homogeneous of degree $n$}
	\EndProof
}\Page{
	\Theorem{BoundedSetsInWeakTopology}
	{
		\forall V \in \VS{k} \.
		\forall I \in \SET \.
		\forall W : I \to \TVS{k} \. \NewLine \.
		\forall T : \prod_{i \in I} \VS{k}(V,W_i) \.
		\forall  B \subset V \.
		\Bounded\Big( \big(V,\W(I,W,T)\big),B\Big)
		\iff
		\forall i \in I \. \Bounded\Big( W_i, T_i(B) \Big)
	}
	\Explain{
		1 This is simmilar to the case with products}
	\Explain{
		2 We may assume that topology is determined by one map
		$T : V \to \prod_{i \in I} W_i$
	}
	\Explain{
		3 Then $\prod_{i \in I} T_i(B)$ is bounded in $\prod_{i \in I} W_i$
	}
	\Explain{ 
		4 Assume $U$ is a neighborhood in the weak topology
	}
	\Explain{ 5 Then it must be a preimage of some open $O \in \prod_{i \in I} W_i$}
	\Explain{ 6 So find an $O$-absorbing scale $\rho$ for $\prod_{i \in I} T_i(B)$ 
		and use it as $U$-absorbing scale for $B$}
	\Explain{ 6.1 Take some $\alpha \in k$ such that $|\alpha| \ge \rho$}	
	\Explain{ 6.2 Then $T(b) \in \alpha O$ for any $b \in B$  }
	\Explain{ 6.3 By thaking inverse image 
		$b \in T^{-1}(\alpha O) = \alpha T^{-1}(O) = \alpha U$}
	\EndProof
	\\
	\Theorem{ContinuityByBoundedImage}
	{
		\NewLine::		
		\forall V,W \in \TVS{k} \.
		\forall T \in \VS{k}(V,W) \.
		\forall U \in \U_V(0) \.
		\Bounded\Big(W, T(U)\Big)
		\Imply
		T \in \TVS{k}(V,W)
	}
	\Explain{ Assume $O \in \U_W(0)$}
	\Explain{ Then there exists an $\rho \in \Reals_{++}$ such that $T(U) \subset rO$}
	\Explain{ But this means that $T(r^{-1}U) \subset O$}
	\Explain{ Then by topological group theory $T$ is continuous}
	\EndProof
	\\
	\Theorem{LocallyBoundedWithSemimetrizableDomainIsContinuous}
	{
		\NewLine ::
		\forall V,W \in \TVS{k} \.
		\forall T \in \VS{k} \And \LO(V,W) \.
		\TYPE{Semimetrizable}(V)
		\Imply
		T \in \TVS{k} \. 
	}
	\Explain{ 1 Let $U$ be a decreasing countable base of neighborhoods of $0$ in $V$}
	\Explain{ 2 Assume that $T$ is discontinuous}
	\Explain{ 2.1 By group topology $T$ must be discontinuous at $0$}
	\Explain{ 2.2 Then there is a $O \in \U_W(0)$ such that $T^{-1}(O)$
		is not a neighborhood of $0$ in $V$}
	\Explain{2.3 So $\frac{1}{n}U_n \not \subset T^{-1}(O)$}
	\Explain{2.4 It must be possible select a sequence 
		$u$ such that $u_n \in U_n$ and $Tu_n \not \in O$}
	\Explain{2.5 As $U$ is a neighborhood baseit follows that 
		$\lim_{n\to \infty} nu_n = 0$	
	}
	\Explain{ 2.6 This means that $\{ nu_n | n \in \Nat \}$ is bounded}
	\Explain{ 2.6.1 Given $E \in \U_V(0)$ there is only finite amount of numbers
		$n$ such that $nu_n \not \in E$}
	\Explain{ 2.6.2 So it is posible to find $E$-absorbtion scales for this finite number  
		and take max}
	\Explain{
		2.7 So $nTu_n$ can be also be viewed as a sequence in a bounded
		subset of $W$}
	\Explain{
		2.8 So there exist an $O$-absorbtion scale $\alpha$ for $n Tu_n$}
	\Explain{
		2.9 That is $n Tu_n \in \alpha O$ for all $n \in \Nat$
	}
	\Exclaim{
		2.10 By archemedian property there exists $n \in \Nat$ such that
			$n \ge \alpha$, so $Tu_n \in O$, a contradiction}
	\EndProof
}
\newpage
\subsubsection{Liouville's Theorem}
\Page{
	\DeclareType{Bounded}
	{
		\prod_{X \in \Set} 
		\prod_{V \in \TVS{k}} 
		?(X \to V)
	}
	\DefineType{f}{Bounded}{\Bounded\Big(V,f(X)\Big)}
	\\
	\DeclareType{Analytic}
	{
		\prod_{U \in \T(\Complex)} 
		\prod_{V \in \TVS{\Complex}} 
		?(X \to V)
	}
	\DefineType{f}{Analytic}{
		\forall u \in U \. \exists v \in V \. 
		\lim_{z \to u} \frac{f(z) - f(u)}{z - u} = v	
	}
	\\
	\Conclude{\TYPE{Entire}}{\Lambda V \in \TVS{\Complex} \. \TYPE{Analytic}(\Complex,V) }
	{
		\TVS{\Complex} \to \Type
	}
	\\
	\Theorem{ContinuousComposition}
	{
		\NewLine ::		
		\forall U \in \T(\Complex) \.
		\forall V \in \TVS{\Complex} \.
		\forall v : \TYPE{Analytic}(U,V) \.
		\forall f \in V' \.
		\TYPE{Analytic}\Big(U,\Complex, f(v)\Big)
	}
	\Explain{Use the continuity of $f$ on the limit, which defines derivative}
	\EndProof
	\\
	\DeclareType{Total}
	{
		\prod_{V \in \VS{k}} ??V
	}
	\DefineType{A}{Total}{\forall v\in V \. \Big( \forall f \in A \. f(v) = 0\Big) \Imply v = 0}
	\\
	\Theorem{LiouvillesTheorem}
	{
		\NewLine ::		
		\forall V \in \TVS{\Complex} \.
		\forall v : \Bounded(\Complex,V) \And \TYPE{Entire}(V) \.
		\forall \aleph : \TYPE{Total}(V,V') \.
		\Type{Constant}(\Complex,V,v)
	}
	\Explain{ $f(v)$ is an entire bounded function for every $f \in V'$}
	\Explain{ So $f(v)$ must be constant by classical Liouville theorem}
	\Explain{ But this means that 
		$f\Big( v(\alpha) - v(\beta)\Big) = f\Big(v(\alpha)\Big) - f\Big(f(\beta)\Big) = 0$
		for every $\alpha,\beta \in \Complex$}
	\Explain{
		But as $V'$ is total this means that $v$ is constant}
	\EndProof
}
\newpage
\subsubsection{p-convexity}
\Page{
	\DeclareType{PConvex}
	{
		\prod_{V \in \VS{\Reals}} \Reals_{++} \to ??V
	}
	\DefineType{A}{PConvex}
	{
		\Lambda p \in \Reals_{++} \. 		
		\forall \alpha,\beta \in \Reals_{++} \.
		\forall v,w \in A \.
		\alpha^p + \beta^p = 1
		\Imply
		\alpha v + \beta w \in A
	}	
	\\
	\DeclareType{AbsolutelyPConvex}
	{
		\prod_{V \in \VS{k}} \Reals_{++} \to ??V
	}
	\DefineType{A}{AbsolutelyPConvex}
	{
		\Lambda p \in \Reals_{++} \. 		
		\forall \alpha,\beta \in k \.
		\forall v,w \in A \.
		|\alpha|^p + |\beta|^p \le 1
		\Imply
		\alpha v + \beta w \in A
	}
	\\	
	\DeclareType{PSeminorm}
	{
		\prod_{V \in \VS{k}} \Reals_{++} \to ?\TYPE{Sublinear}(V,\Reals)
	}
	\DefineType{\nu}{PSeminorm}
	{
		\Lambda p \in \Reals_{++} \. 		
		\forall \alpha \in k \.
		\forall v \in A \.
		\| \alpha v  \| = |\alpha|^p\|v\|
	}
	\\
	\DeclareType{PSeminorm}
	{
		\prod_{V \in \VS{k}} \Reals_{++} \to ?\TYPE{Sublinear}(V,\Reals)
	}
	\DefineType{\nu}{PSeminorm}
	{
		\Lambda p \in \Reals_{++} \. 		
		\forall \alpha \in k \.
		\forall v \in A \.
		\| \alpha v  \| = |\alpha|^p\|v\|
	}
	\\
	\DeclareFunc{pSeminormedTopology}
	{
		\prod_{V \in \VS{k}} \TYPE{PSeminorm}(V,k,p) \to \Vec\Top(V)
	}
	\DefineNamedFunc{pSeminormedTopology}{\nu}{\T(\nu)}
	{
		\Big\langle \Big\{ 
			\{ w \in W: \nu(v - w) < \rho  \} 
			\Big| v \in V,\rho \in \Reals_{++}  
		 \Big\} \Big\rangle
	}
	\\
	\DeclareType{PSeminormable}{\Reals_{++} \to ?\TVS{k}}
	\DefineType{V}{PSeminormable}{
		\Lambda p \in \Reals_{++} \. 
		\exists \nu : \TYPE{PSeminorm}(V) \. \T(V) = \T(\nu) }
	\\
	\Theorem{PSeminormableSpace}
	{
		\NewLine ::		
		\forall V \in \TVS{k} \.
		\forall p \in \Reals_{++}
		\TYPE{PSeminormable}(V,p) 
		\iff
		\exists U \in \U_V(0) \. 
		\Bounded(V,U) \And \TYPE{PConvex}(V,p,U)
	}
	\Explain{
		$\left( \frac{1}{n} U \right)^\infty_{n=1}$ 
		is a countable base of vector topology for $V$}
	\Explain{
		The gauges defined by $U$ are p-seminorms}
	\EndProof
}
\newpage
\subsubsection{Bornology}
\Page{
	& k : \AVF(\Reals) \Big| \TYPE{UltravaluedField} ; \\
	\\
	\Conclude{\TYPE{Bornology}}{
		\Lambda X \in \SET \. 
		\Ideal(2^X)
	}{\SET \to \Type}
	\\
	\Conclude{\TYPE{BoundedStructrure}}{
		\sum_{X \in \SET} \TYPE{Bornology}(X)
	}{\Type}
	\\
	\DeclareFunc{asSet}{\BS \to \Set}
	\DefineNamedFunc{asSet}{X,\beta}{(X,\beta)}{X}
	\\
	\DeclareFunc{bornology}{\prod (X,\beta) : \BS \. \TYPE{Bornology}(X)}
	\DefineNamedFunc{bornology}{}{\B(X,\beta)}{\beta}
	\\
	\DeclareType{Bounded}{\prod X : \BS \. ??X}
	\DefineType{B}{Bounded}{B \in \B(X)}
	\\
	\Theorem{CompactsAreBornology}
	{
		\forall X \in \TOP \. \Born\Big(X,\TYPE{RelativeCompcts}(X)\Big)
	}  	
	\Explain{This is obvious}
	\EndProof
	\\
	\DeclareFunc{standardBornology}
	{
		 \TVS{k} \to \BS 
	}
	\DefineNamedFunc{standardBornology}{V}{V}{\Big(V,\Bounded(V)\Big)}
	\\
	\DeclareType{BornologyBase}
	{
		\prod X : \BS \. ??\B(X)
	}
	\DefineType{\C}{\BB}{\forall B \in \B(X) \. \exists C \in \C \. B \subset C}
	\\
	\DeclareFunc{generateBornology}
	{
		\prod_{X \in \SET} ??X \to \Born(X)
	}
	\DefineNamedFunc{generateBornology}{\alpha}{\langle \alpha \rangle_{\mathsf{BORN}}}
	{
		\left\{ A \subset X : 
			\exists n \in \Nat \.  
			\exists C : \{1,\ldots,n\} \to \alpha \.
			 A \subset \bigcup^n_{i=1} C_i   \right\}
	}
	\\
	\DeclareFunc{bornologicalCategory}
	{
		\CAT
	}
	\DefineNamedFunc{bornologicalCategory}{}{\BORN}
	{
		\NewLine \de		
		\Big( \BS , \Lambda X,Y : \BS \. \{ f : X \to Y \. \forall B \in \B(X) \. f(B) \in \B(Y)   \},
			\circ, \id \Big)
	}
}\Page{
	\DeclareFunc{strongBornology}
	{
		\prod_{X \in \SET} \prod Y : \BS \. (X \to Y) \to \Born(X)
	}
	\DefineNamedFunc{strongBornology}{f}{\S(Y,f)}
	{
		\langle  f^{-1} \B(Y) \rangle_{\mathsf{BORN}}
	}
	\\
	\DeclareFunc{weekBornology}
	{
		\prod_{Y \in \SET} \prod X : \BS \. (X \to Y) \to \Born(Y)
	}
	\DefineNamedFunc{weakBornology}{f}{\W(X,f)}
	{
		\langle  f \B(X) \rangle_{\BORN} 
	}
	\\
	\ExplainFurther{
		By use of week and strong notions,  
		we may define subset bornology,}
	\Explain{ 
		quotient bornology or any kind of limit bornologies}
	\\
	\DeclareFunc{supBornology}
	{
		\prod_{X,I \in \SET} \Big(I \to \Born(X)\Big) \to \Born(X)
	}
	\DefineNamedFunc{supBornology}{\beta}{\bigvee_{i \in I} \beta_i}
	{
		\left\langle \bigcup_{i \in I} \beta_i \right\rangle_{\BORN}
	}
	\\
	\DeclareFunc{infBornology}
	{
		\prod_{X,I \in \SET} \Big(I \to \Born(X)\Big) \to \Born(X)
	}
	\DefineNamedFunc{infBornology}{\beta}{\bigwedge_{i \in I} \beta_i}
	{
		\left\langle \bigcap_{i \in I} \beta_i \right\rangle_{\BORN}
	}
	\\
	\Explain{This shows that a set of bornologies forms acomplete lattice}
	\\
	\DeclareType{VectorBornology}
	{
		\prod V \in \VS{k}  \. ?\Born(V)
	}
	\DefineType{\beta}{VectorBornology}
	{
		+_V \in \BORN\Big( (V,\beta) \times (V,\beta), (V,\beta)\Big)
		\And
		\cdot_V \in \BORN\Big( k \times (V,\beta), (V,\beta)\Big)
	}
	\\
	\DeclareType{ConvexBornology}
	{
		\prod V \in \VS{k}  \. ?\Vect\Born(V)
	}
	\DefineType{\beta}{ConvexBornology}
	{
		\exists \gamma : \BB(V,\beta) \.
		\forall B \in \gamma \. \Convex(V,B)
	}
	\\
	\Theorem{VectorBornologyCharacterisation}
	{
		\NewLine ::		
		\forall V \in \VS{k} \.
		\forall \beta : \Born(V) \.  \NewLine \.
		\Vect\Born(V,\beta)
		\iff
		\forall A,B \in \beta \. A + B \in \beta \And
		\forall A \in \beta \. \bal A \in \beta
	}
	\Explain{ 1 $(\Rightarrow)$}
	\Explain{ 1.1 $A + B \in \beta$ as addition is locally bounded}
	\Explain{ 1.2 $\bal A = \Disc_k(0,1) A$ and scalar multiplication is uniformly bounded}
	\Explain{ 2 $(\Leftarrow)$  }
	\Explain{ 2.1  $A + B \in \beta$ implies that addition is locally bounded }
	\Explain{ 2.2  $\Disc_k(0,r) A  \in \beta$}
	\Explain{ 2.2.1 By archimedean property of $\Reals$ there is $n \in \Nat$ such that 
		$n \ge r$}
	\Explain{ 2.2.2 But
		$
			\Disc_k(0,r) A \subset \Disc_k(0,n) A \subset \sum^n_{i=1} \Disc(0,1) A =
			\sum^n_{i=1} \bal A \in \beta   
		$
	}
	\Explain{ 2.2.3 As $\beta$ is ideal $\Disc_k(0,r) A $}
	\Explain{ 2.3 As $k$ has bornology base of discs the scalar multiplication must be continuous}
	\EndProof
}\Page{
	\Theorem{EquicontinuousBornology}
	{
		\forall X \in \TOP \. 
		\Vect\Born\Big(\TOP(X,k),\TYPE{Equicontinuous}(X,k) \Big)
	}
	\Explain{ 1 Denote by $\eta$ 
		the set of equicontinuous subsets of $\TOP(X,k)$}
	\Explain{	 2 It is obvious that $\eta$ is downwards closed}
	\Explain{ 3 $\eta$ is also closed under finite unions}
	\Explain{ 3.1 Assume $A,B \in \eta$, also assume $U \in \U_k(0)$ and $x \in X$}
	\Explain{ 3.2 Then there exists $V \in \U_X(x)$ such that 
			$f(V) \subset U + f(x)$ for all $f \in A$}
	\Explain{ 3.3 Also there is $W \in \U_X(x)$ such that 
			$f(W) \subset U + f(x)$ for all $f \in B$}
	\Explain{ 3.4 Then taking $V \cap W$ should for $A \cup B$}
	\Explain{ 4 Also $\eta$ is closed under addition}
	\Explain{ 4.1 Assume $A,B \in \eta$, also assume $U \in \U_k(0)$ and $x \in X$}
	\Explain{ 4.2 Then there exists $O \in \U_k(0)$ such that $O + O \subset U$}
	\Explain{ 4.3 Then there exists $V \in \U_X(x)$ such that 
			$f(V) \subset O + f(x)$ for all $f \in A$}
	\Explain{ 4.4 Also there is $W \in \U_X(x)$ such that 
			$f(W) \subset O + f(x)$ for all $f \in B$}
	\Explain{ 4.5 A function $h \in A + B$  can be expressed as $h = f +g $ for
		$f \in A$ and  $g \in B$}
	\Explain{ 4.6
		So $
			h(V \cap W) = 
			f(V \cap W) + g(V \cap W)  \subset
			O + O + f(x) + g(x) \subset  U + h(x)			 
		$}
	\Explain{ 5 Scalar multiplication is locally bounded}
	\Explain{ 5.1 Assume $A \in \eta$, also assume $U \in \U_k(0)$ and $x \in X$}
	\Explain{ 5.2 Then there exist a balanced $W \in \U_k(0)$ such that $W \subset U$}
	\Explain{ 5.3 Then there exists $V \in \U_X(x)$ such that 
			$f(V) \subset W + f(x)$ for all $f \in A$}
	\Explain{ 5.4 Then for any $f \in \bal A = \Disc_k(0,1) A$ 
		there is $g \in A$ and $\alpha \in \Disc_k(0,1)$ such that $f = \alpha g$ }
	\Explain{ 5.5 Then
		$f(V) =\alpha g(V) \subset \alpha W + \alpha g(x) = W + f(x) \subset U + f(x)$}
	\EndProof
	\\
	\DeclareFunc{closure}
	{
		\prod_{X \in \TOP} \Born(X) \to \Born(X) 
	}
	\DefineNamedFunc{closure}{\beta}{\cl \beta}
	{\Big\langle \{ \cl B | B \in \beta \}  \Big\rangle_\BORN}
	\\
	\DeclareFunc{interior}
	{
		\prod_{X \in \TOP} \Born(X) \to \Born(X) 
	}
	\DefineNamedFunc{interior}{\beta}{\intx \beta}
	{\Big\langle \{ \intx B | B \in \beta \}  \Big\rangle_\BORN}
	\\
	\Theorem{InteriorClosureOrder}
	{
		\forall X \in \TOP \.
		\forall \beta  : \Born(X) \.
		\intx \beta \subset \beta \subset \cl \beta
	}
	\Explain{ This follows from the fact that $\beta$ is closed under taking susets}
	\Explain{ And $\intx A \subset A \subset \cl A$ for any $A \subset X$}
	\EndProof
	\\
	\Theorem{MonotonicInterior}
	{
		\forall X \in \TOP \.
		\forall \alpha, \beta  : \Born(X) \.
		\alpha \subset \beta \Imply
		\intx \alpha \subset \intx \beta
	}
	\Explain{ Obvious}
	\EndProof
}\Page{
	\Theorem{MonotonicClosure}
	{
		\forall X \in \TOP \.
		\forall \alpha, \beta  : \Born(X) \.
		\alpha \subset \beta \Imply
		\cl \alpha \subset \cl \beta
	}
	\Explain{ Obvious}
	\EndProof
	\\
	\DeclareType{Open}
	{
		\forall X \in \TOP \.
		?\Born(X)
	}
	\DefineType{\beta}{\Open}{\intx \beta = \beta}
	\\
	\DeclareType{Closed}
	{
		\forall X \in \TOP \.
		?\Born(X)
	}
	\DefineType{\beta}{\Closed}{\cl \beta = \beta}
	\\
	\Conclude{\TYPE{Proper}}{\TYPE{Closed} \And \TYPE{Open}}
	{
		\prod_{X \in \TOP} ?\Born(X)
	}
	\\
	\Theorem{ClodednessAltDef}
	{
		\NewLine \.		
		\forall X \in \TOP \.
		\forall \beta : \Born(X) \.
		\Closed(X,\beta) \iff
		\BB\Big( X, \beta,  \beta \cap \TYPE{Closed}(X) \Big)
	}
	\Explain{1 $(\Rightarrow)$}
	\Explain{ 1.1 If $A \in \beta$, then $A \subset \cl A$}
	\Explain{ 1.2 Also $\cl A \in \beta$}
	\Explain{2 $(\Leftarrow)$}
	\Explain{ 2.1 Assume $A \in \beta$}
	\Explain{ 2.2 Then there is a closed set $F \in \beta$ such that $A \subset F$}
	\Explain{ 2.3 But $A \subset \cl A \subset F$}
	\Explain{ 2.4 So $\cl A \in \beta$ as $\beta$ is closed under taking subsets}
	\EndProof
	\\
	\DeclareType{LocallyBounded}
	{
		?\TOP \And \BORN
	}
	\DefineType{X}{LocallyBounded}
	{
		\forall x \in X \.\N_V(x) \cap \beta \neq \emptyset
	}
	\\
	\Theorem{CompactsAreBoundedInLocallyBoundedSpace}
	{
		\forall X : \TYPE{LocallyBounded} \.
		\K(X) \subset \B(X)
	}
	\Explain{1 Take $K$ to be compact in $X$}
	\Explain{2 Select a bounded Neighborhood $U_x$ for each point $x \in K$}
	\Explain{3 As $K$ is compact there is a finite subcover $(x_i)_{i=1}^n$}
	\Explain{4 Then $\bigcup^n_{i=1} U_{x_i} \in \B(X)$ as $\B(X)$ is an ideal}
	\Explain{5 But $K \subset \bigcup^n_{i=1} U_{x_i} \in \B(X)$, so $K \in \B(X)$,
		as $\B(X)$ is an ideal}
	\EndProof
}\Page{
	\DeclareFunc{semimetricBornology}
	{
		\prod_{X \in \SET} \TYPE{Semimetric}(X) \to \Born(X)
	}
	\DefineNamedFunc{semimetricBornology}{\rho}{\B(\rho)}
	{
		\langle \Cell_{X}(X,\Reals_{++}) \rangle_\BORN
	}
	\\
	\DeclareType{Semimetrizable}{?\TOP \And \BORN}
	\DefineType{X}{Semimetrizable}
	{
		\exists \rho : \TYPE{Semimetric}(X) \.
		\T(X) = \T(\rho) \And \B(X) = \B(\rho)
	}
	\\
	\Theorem{SemimetrizationTHM}
	{
		\NewLine ::		
		\forall (X,\tau,\beta) \in \TOP \And \BORN \.  \NewLine \.
		\TYPE{Semimetrizable}(X,\tau,\beta)
		\iff \NewLine\iff
		\TYPE{Semimetrizable}(X,\tau)
		\And
		\TYPE{LocallyBounded}\And \TYPE{Proper}(X,\beta)
		\And
		\exists \beta' : \BB(X)  \.
		|\beta'| \le \aleph_0
	}
	\NoProof
}
\newpage
\subsubsection{Interesting Examples and Facts}
\newpage
\subsection{Infinite Dimensional Geometry}
\subsubsection{Hahn-Banach theorems}
\Page{
	\Theorem{OneDimensionalExtension}
	{
		\NewLine ::		
		\forall V \in \VS{\Reals} \.
		\forall U \subvec{\Reals} V \.
		\forall \sigma : \TYPE{Sublinear}(V) \,
		\forall f \in U^* \.
		\forall v \in U^\c \. \NewLine \.
		\forall \aleph :  f \le \sigma_{|U} \.
		\exists F \in (U \oplus v)^* \.
		F_{|U} = f \And F \le \sigma_{|U \oplus v}
	}
	\Explain{ 1   
		$
			\alpha = \sup_{u \in U}  -\sigma(-u-v) - f(u) \le 
		 	\inf_{u \in U} \sigma(u  +  v) - f(u) = \beta		
		$}
	\Explain{ 1.1 Assume $u,w \in U$}
	\Explain{ 1.2 Then $f(u) - f(w) = f(u - w) \le \sigma(u -w)  =
		\sigma( u + v - v - w) = \sigma(u + v) + \sigma(-v - w)$}
	\Explain{ 1.3 By rearenging one gets
		$
			- \sigma(-v- w) - f(w) \le  \sigma(u + v) - f(u)
		$}
	\Explain{ 1.4 Not, that both $\alpha$ and $\beta$ must be finite by
		inf and sup definition }
	\Explain{ 2 So  $-\sigma(-v-u) \le \gamma \le \sigma(v+u)$
			for any $\gamma \in [\alpha,\beta]$ and $u \in U$}
	\Explain{ 3 Select $\gamma \in [\alpha,\beta]$}
	\Explain{ 4 Define $F(u + \delta v) \de f(u) + \delta \gamma$ on $U \oplus v$, which is linear}
	\Explain{ 5 $F \le \sigma$  on $U \oplus v$}
	\Explain{ 5.1 Assume $\delta > 0$}
	\Explain{ 5.1.1 Then 
			$F(u + \delta v) \le f(u) + \delta\sigma\left( \frac{u}{\delta} + v \right) - f(u) = 
			  \sigma(u + \delta v)$ by construction of $\gamma$}
	\Explain{ 5.1.2 Here we used thed fact that $\sigma$ is conic}
	\Explain{ 5.2 Assume $\delta < 0$  }
	\Explain{ 5.2.1 Then
		$F(u + \delta v) \le f(u)  - \delta\sigma\left( -\frac{u}{\delta} - v \right) - f(u) = 
			  \sigma(u + \delta v)$  by construction of $\gamma$}
	\Explain{ 5.3 The case $\delta = 0$ is evident}
	\EndProof
	\\
	\Theorem{HahnBanachTheorem1}
	{
		\NewLine ::		
		\forall V \in \VS{\Reals} \.
		\forall U \subvec{\Reals} V \.
		\forall \sigma : \TYPE{Sublinear}(V) \,
		\forall f \in U^* \.
		\forall \aleph :  f \le \sigma_{|U} \.
		\exists F \in V^* \.
		F_{|U} = f \And F \le \sigma
	}
	\Explain{ 1 Define $\phi \subset \sum W : \TYPE{VectorSubspace}(V) \. W^*$ 
		to be the set of all extensions of $f$ bounded by $\sigma$}
	\Explain{ 2 Order $\phi$ by saying $(W,g) \le (O,h)$ iff $W \subvec{k} O$ 
	 and $h_{|W} = g$}
	 \Explain{ 3 By Zorn Lemma extract an upper bound $(W,F)$ of $\phi$} 
	 \Explain{ 3.1 Clearly $(U,f) \in \phi$, so $\phi \neq \emptyset$} 
	 \Explain{ 3.2 If $\C$ is a chain in $\phi$, then $\bigcup \C \in \phi$ is an upper bound of $\C$}
	 \Explain{ 4 If $W \neq V$ then the extension 
	 	$F$ can be extended furtherly, but this contradicts the maximality}
	 \EndProof
	 \\
	 & k :: \AVF(\Reals) ;\\
	 \\
	 \Theorem{HahnBanachExtension}
	{
		\NewLine ::		
		\forall V \in \TVS{k} \.
		\forall U \subvec{k} V \.
		\forall \sigma \in \SMN(V) \.
		\forall f \in U^* \.
		\forall \aleph :  f \le \sigma_{|U} \.
		\exists F \in V^* \.
		F_{|U} = f \And |F| \le \sigma
	}
	\Explain{ This is a modification of Hahn-Banach}
	\EndProof
}\Page{
	\Theorem{ContinuousExtension}{
		\NewLine ::		
		\forall V \in \LCS{k} \.
		\forall U \subvec{k} V \.
		\forall f \in U' \.
		\forall \aleph :  f \le \sigma_{|U} \.
		\exists F \in V' \.
		F_{|U} = f
	}
	\Explain{ 1 The family of seminorms $\ssc(V)$ generates the topology of $V$}
	\Explain{ 2 The restrictions $\sigma_{|U}$ for $\sigma \in \ssc(V)$ 
		generate the locally convex topology of $U$}
	\Explain{ 3 So there exists $\sigma \in \ssc(V)$ such that $|f| \le \sigma_{|U}$}
	\Explain{ 3.1 This is a continiuity ctiterion for locally convex spaces}
	\Explain{ 4  By Hahn-Banach there is an extension $F$ of $f$ 
		such that $|F| \le \sigma$}
	\Explain{ 5 So by same continuity criterion $F \in V'$}
	\EndProof
	\\
	\Theorem{SublinearFunctionalSupport}
	{
		\forall V \in \TVS{k} \.
		\forall  \sigma : \TYPE{Sublinear}(V) \.
		\forall v \in V \.
		\exists f \in V^* \. \NewLine \.
		f(v) = \sigma(v) \And
		\forall w \in V \.
		-\sigma(-w) \le f(w) \le \sigma(w)	
	}
	\Explain{ 1 define $g$ on $kv$ by setting $g(\alpha v) = \alpha \sigma(v)$  }
	\Explain{ 2 Obviously $g$ is linear}
	\Explain{ 3 $g \le \sigma_{kv}$}
	\Explain{ 3.1 Assume $\alpha \ge 0$}
	\Explain{ 3.1.1 Then by defineition $g(\alpha v) = \alpha \sigma(v) = \sigma(\alpha v)$}
	\Explain{ 3.1.2 So $g(\alpha v) \le \sigma(\alpha v)$}
	\Explain{ 3.2 Assume $\alpha < 0$ }
	\Explain{ 3.2.1 Then $f(\alpha v) = \alpha = -(-\alpha) \sigma( v) = -\sigma(-\alpha v) 
		\le \sigma(\alpha v)$}
	\Explain{ 3.2.2 Last Inequelity follow from the fact that 
		$0 = \sigma(0) = \sigma(u - u) \le \sigma(u) + \sigma(-u)$ for any $u \in V$}
	\Explain{ 3.2.3 So $-\sigma(-u) \le \sigma(u)$ }
	\Explain{ 4 By Hahn Banach there is a dominated extendion $f \in V^*$  of $g$}
	\Explain{ 5 By  one-dimensional extension proof's 
		construction it must be the case that    
		$-\sigma(w) \le f(w) \le \sigma(w)$}
	\Explain{ 5.1 Apply statement (1) to the construction with $u=0$}
	\EndProof
	\\
	\Theorem{SeminormFunctionalSupport}
	{
		\forall V \in \VS{\Reals} \.
		\forall  \sigma \in \SMN(V) \.
		\forall v \in V \.
		\exists f \in V^* \. \NewLine \.
		f(v) = \sigma(v) \And
		|f| \le \sigma
	}
	\Explain{ This is an obvious modification of the previous result}
	\EndProof
}\Page{
	\Theorem{ContinuousFunctionalSupport}
	{
		\forall V \in \TVS{\Reals} \.
		\forall  \sigma : \TYPE{Sublinear}(V) \cap \TOP(V,\Reals) \.
		\forall v \in V \.
		\exists f \in V' \. \NewLine \.
		f(v) = \sigma(v) \And
		-\sigma(-w) \le f(w) \le \sigma(w)
	}
	\Explain{ 1 Assume $U \in \U_\Reals(0)$}
	\Explain{ 2 Then there is a balanced $W \in \U_k(0)$ such that $W \subset U$ }
	\Explain{ 3 By continuity there is $O \in \U_V(0)$ such that $\sigma(O) \subset W$}
	\Explain{ 4 Let $E \in \U_V(0)$ be a balanced subset of $O$   }	
	\Explain{ 5 Then $f(E) \subset U$}
	\Explain{ 5.1 Select $w \in E$}
	\Explain{ 5.2 Then $w,-w \in O$, so $-\sigma(-w),\sigma(w) \in W$}
	\Explain{ 5.3 But $-\sigma(-w) \le f(w) \le \sigma(w)$}
	\Explain{ 5.4 As $W$ is balanced $f(w) \in E$ }
	\Explain{ 5.4.1 Think about $W$ as open interval $(-\alpha,\alpha)$}
	\Explain{ 6 By continuity at zero, the general continiuity follows}	
	\EndProof
	\\
	\Theorem{FiniteDimIsComplemented}
	{
		\forall V \in \LCHS{k} \.
		\forall U \subvec{k} V \.
		\dim U < \infty \Imply 
		\exists W \subvec{k} \.
		V =_{\TVS{k}} U \oplus W
	}
	\Explain{ Let $(e_i)^n_{i=1}$ be a finite base of $U$}
	\Explain{ Then functionals $f_i\left( \alpha e \right) = \alpha_i$ are continuous }
	\Explain{ So there exist a continuous extensions $F_i \in V'$ of each $f_i$}
	\Explain{ Define continuous operator $P(v) =  F_i(v) e_i $}
	\Explain{ Obviously, $P^2 = P$, so $P$ is a continuous projector}
	\Explain{ This means that $P$ must be complemented}
	\EndProof
	\\
	\Theorem{NormPreservingFunctionalExtension}
	{
		\forall V  : \NS(k) \.
		\forall  U \subvec{k} V \.
		\forall f \in U' \.
		\exists F \in V' \.
		\|f\| = \|F\|
		\And
		F_{|U} = f 
	}
	\Explain{ 1 Define a sublinear function $\sigma(v) = \|f\|\|v\|$  on V}
	\Explain{ 2 Then, by the definition of dual normed space $|f| \le \sigma_{|U}$}
	\Explain{ 3 Construct $F$ as Hahn-Banach dominated extension of $f$ dominated by $\sigma$}
	\Explain{ 4 Then $F$ is continuous}
	\Explain{ 5 As $|F| \le \sigma$ it must be the case that $\|F\| \le \|f\|$}
	\Explain{ 6 On the other hand there must exist a sequence $u : \Nat \to U$
		such that $|f(u_n)| \to \|f\|$}
	\Explain{ 7 But this means that $|F(u_n)| = |f(u_n)| \to \|f\|$, so $\|F\| = \|f\|$}
	\EndProof
	\\
	\Theorem{FunctionalAbundence}
	{
		\forall V  : \NS(k) \.
		\forall  v \in V
		\exists f \in \Sphere(V') \.
		f(v) = \|v\|
	}
	\Explain{ 1 Define a a function $g : kv \to k$ by $g(\alpha v) = \alpha \|v\|$}
	\Explain{ 2 Then $g$ is linear and has norm $\|g\| = 1$}
	\Explain{ 3 By the previous result there exists an extension $f$ of $g$ on $V$}
	\EndProof
}\Page{
	\Theorem{DualZeroCritetion}
	{
		\forall V : \NS(k) \.
		\forall v \in V \.
		v = 0
		\iff
		\forall f \in  \Sphere(V') \.
		f(v) = 0
	}
	\Explain{ Obvious}
	\EndProof
	\\
	\Theorem{DualNormConstruction}
	{
		\forall V : \NS(k) \.
		\forall v \in V \.
		\|v\| = \sup \Big\{ |f(v)| \Big| f \in \Sphere(V') \Big\}
	}
	\Explain{ There must be $f \in \Sphere(V')$ such that $f(v) = \|v\|$}
	\Explain{ On the other hand by definition of the dual norm $|f(v)| \le \|f\|\|v\| = \|v\|$ }
	\EndProof
	\\
	\Theorem{SubspaceSeparatingFunctionalExists}
	{
		\NewLine ::		
		\forall V : \NS(k) \.
		\forall U \subvec{k} V \.
		\forall v \in (\cl U)^\c \.
		\forall \delta \in \Reals_{++} \.
		\forall \aleph : d_V(v,U) = \delta \. \NewLine \.
		\exists f \in \Sphere(V') \.
		f(U) = \{0\} \And f(v) = \delta
	}
	\Explain{ 1  Define $g(u + \alpha v) = \alpha \delta$ over $U \oplus kv$}
	\Explain{ 2  Then $g$ is linear}
	\Explain{ 3 $g$ is continuous and has $\|g\| \le 1$}
	\Explain{ 3.1 Assume $u + \alpha v$ is sach that $\|u + \alpha v \| = 1$}
	\Explain{ 3.2 Then $f(u + \alpha v) = \alpha \delta$}
	\Explain{ 3.3 If $\alpha = 0$, then $|f(u + \alpha v)| = |0| =  0 \le 1$}
	\Explain{ 3.4 So assume $\alpha \neq 0$ }
	\Explain{ 3.5 write $1 = \|u + \alpha v\| = \left\| - \alpha\frac{-u}{\alpha} + \alpha v\right\|
		= |\alpha| \left\| v - \frac{ -u  }{\alpha} \right\| \ge |\alpha|\delta	
	$ }
	\Explain{ 3.5.1 Here the last inequality holds by the definition of a distance to a set}
	\Explain{ 3.6 Also $|f(u + \alpha v)| = |\alpha \delta | = |\alpha| \delta \le 1$}
	\Explain{ 4 Actually $\|g\| = 1$}
	\Explain{ 4.1 Select a sequence $u : U \to \Nat$ such that $\lim_{n \to \infty} \|v - u_n\| = \delta$  }
	\Explain{ 4.2 But $g(v-u_n) = \delta$, so $\|g\| \ge 1$}
	\Explain{ 5 Define $f$ to be a Hahn-Banach extension of $g$}
	\EndProof 
	\\
	\Theorem{LinearlyIndependendFunctionSeparation}
	{
		\NewLine ::		
		\forall V : \NS(k) \.
		\forall n \in \Int_+ \.
		\forall v : \LI\Big(\{1,\ldots,n\},V\Big) \NewLine \.
		\exists f : \{1,\ldots,n\} \to V' \.
		\forall i,j \in \{1,\ldots,n\} \.
		f_i(v_j) = \delta_{i,j}
	}
	\Explain{ Define functionals on $\Span\{v_1,\ldots,v_n\}$ and then extend the to the whole space}
	\EndProof
}\Page{
	\Theorem{GreaterNormExtension}
	{
		\NewLine ::		
		\forall V : \NS(k) \.
		\forall U \subvec{k} V \.
		\forall f \in U' \.
		\exists F \in V' \.
		F_{|U} = f \And \|F\| \ge \|f\|
	}
	\Explain{ 1 If $V = \cl U$ the result holds trivially}
	\Explain{ 2 So take $v \in (\cl U)^\c$ }
	\Explain{ 3 Let $\delta = d_V(U,v)$}
	\Explain{ 4 define $g(u + \alpha v) = f(u) + \alpha \beta$ with $\beta \ge \|v\|\|f\|$  on $U \oplus kv$}
	\ExplainFurther{ 5 This functional is continuous as $g$ is sum of $f$} 
	\Explain{ $\quad$ and the fucntional  of the theorem  $\THM{SubspaceSeparatingFunctionalExists}$}
	\Explain{ 6 $\|g\| \ge \|f\|$}
	\Explain{ 6.1  See that $g\left( \frac{u}{\|u\|} \right) = \frac{\beta}{\|u\|} \ge \|f\|$}
	\Explain{ 7 Extend $g$ By Hahn-Banach to get the result}	
	\EndProof
} 
\newpage
\subsubsection{Mazur-Orlich Theorem}
\Page{
	\Theorem{MazurOrlichTHM}
	{
		\NewLine ::		
		\forall V \in \VS{\Reals} \.
		\forall \sigma : \TYPE{Sublinear}(V) \.
		\forall X \in \SET \.
		\forall v : X \to V \.
		\forall \rho : X \to \Reals \. \NewLine \.
		\Big( \exists f \in V^* \. f \le \sigma \And  \rho \le vf \Big)
		\iff \NewLine \iff
		\forall n \in \Nat \.
		\forall \alpha : \{1,\ldots,n\} \to \Reals_{+} \.
		\forall x : \{1,\ldots,n\} \to X \. 
		\sum^n_{i=1} \alpha_i \rho(x_i) \le  \sigma\left( \sum^n_{i=1} \alpha_i v(x_i) \right)
	}
	\Explain{ 1 $(\Rightarrow)$}
	\Explain{ 1.1 
		$\sum^n_{i=1} \alpha_i \rho(x_i) \le  
		\sum^n_{i=1} \alpha_i f( v(x_i) )  =
		f\left( \sum^n_{i=1} \alpha_i v(x_i) \right)  \le 
		\sigma\left( \sum^n_{i=1} \alpha_i v(x_i) \right)$}
	\Explain{ 2 $(\Leftarrow)$}
	\Explain{ 2.1 Take some $n \in \Nat$ and $u \in V$}
	\Explain{ 2.2 Define $\Gamma_n(u) = \left\{ \sigma\left( u + \sum^n_{i=1} \alpha_i v(x_i) 
		\right) - \sum^n_{i=1} \alpha_i \rho(x_i) \bigg|\alpha : \{1,\ldots,n\} \to \Reals_{+},
		x : \{1,\ldots,n\} \to X  \right\}$}
	\Explain{ 2.3 Also Define $\gamma(u) = \inf_{n \in \Nat} \inf \Gamma_n(u)$}
	\Explain{ 2.3.1 $\gamma(u)$ is well defined and bounded below by $-\sigma(-u)$}
	\Explain{ 2.3.1.1 $\sum^n_{i=1} \alpha_i \rho(x_i) \le  
	\sigma\left( \sum^n_{i=1} \alpha_i v(x_i) \right) \le 
	\sigma\left( u + \sum^n_{i=1} \alpha_i v(x_i) \right) + \sigma(-u)$ for any $\alpha$ and $x$}
	\Explain{ 2.3.1.2 By rearanging inequality one gets the bound}
	\Explain{ 2.3.2 $\gamma$ is subadditive} 
	\Explain{ 2.3.2.1 Take some $u,w \in V$}
	\ExplainFurther{ 
		2.3.2.2 Then
		$\gamma(u + w) = \inf_{n,\alpha,x} 
			\sigma\left( u + w +  \sum^n_{i=1} \alpha_i v(x_i) 
		\right) - \sum^n_{i=1} \alpha_i \rho(x_i) =$}
		\ExplainFurther{ $=\inf_{n,\alpha,\beta,x,y} 
			\sigma\left( u + w + \sum^n_{i=1} \alpha_i v(x_i) +   \sum^n_{i=1} \beta_i v(y_i)
		\right)  - \sum^n_{i=1} \alpha_i \rho(x_i) - \sum^n_{i=1} \beta_i \rho(y_i) \le$ } 
		\ExplainFurther{ $\le 
		 \inf_{n,\alpha,\beta,x,y}   \sigma\left( u +  \sum^n_{i=1} \alpha_i v(x_i) 
		\right) - \sum^n_{i=1} \alpha_i \rho(x_i) +
		\sigma\left( w +  \sum^n_{i=1} \beta_i v(y_i) 
		\right) - \sum^n_{i=1} \beta_i \rho(y_i)  =$}
		\Explain{ $=
		\inf_{n,\alpha,x}   \sigma\left( u +  \sum^n_{i=1} \alpha_i v(x_i) 
		\right) - \sum^n_{i=1} \alpha_i \rho(x_i) +
		\inf_{n,\beta,y} \sigma\left( w +  \sum^n_{i=1} \beta_i v(y_i) 
		\right) - \sum^n_{i=1} \beta_i \rho(y_i) = \gamma(u) + \gamma(v)$	
	}
	\Explain{ 2.3.3 $\gamma$ is positively homogeneous}
	\Explain{ 2.3.3.1 Take some $u \in V$ and $\lambda \in \Reals_{++}$}
	\ExplainFurther{ 
		2.3.3.2Then
		$\gamma(\lambda u) = \inf_{n,\alpha,x} 
			\sigma\left( \lambda u +  \sum^n_{i=1} \alpha_i v(x_i) 
		\right) - \sum^n_{i=1} \alpha_i \rho(x_i) =$}
	\Explain{
		$ =\inf_{n,\alpha,x} 
			\sigma\left( \lambda u +  \sum^n_{i=1} \lambda \alpha_i v(x_i) 
		\right) - \sum^n_{i=1} \lambda \alpha_i \rho(x_i) = 
		\lambda \inf_{n,\alpha,x} 
			\sigma\left(u +  \sum^n_{i=1} \alpha_i v(x_i) 
		\right) - \sum^n_{i=1} \alpha_i \rho(x_i) = \lambda \gamma(u) 
		$}
	\Explain{ 2.4 Define $f$ as Hahn-Banach extension of $0$ dominated by $\gamma$}
	\Explain{ 2.5 Clearly $f \le \gamma \le \sigma$}
	\Explain{ 2.6 $\rho  \le  f v$}
	\Explain{ 2.6.1 Select $x \in X$}
	\Explain{ 2.6.2 Then by construction $\gamma(-v(x)) \le \sigma( -v(x) + v(x) ) - \rho(x) = -\rho(x)$}
}\Page{
	\Explain{ 2.6.3 But  $f(v(x)) \ge -\gamma(-v(x)) \ge \rho(x)$}
	\EndProof
}
\newpage
\subsubsection{Subliniar Functionals}
\Page{
	\Conclude{\FUNC{sublinear} = \Lambda V \in \VS{k} \. V^\# }
	{
		 \Lambda V \in \VS{k} \. \TYPE{Sublinear}(V)
	}{\VS{k} \to \Type}
	\\
	\Theorem{LinearityCriterion}
	{
		\forall V \in \VS{\Reals} \.
		\forall \sigma \in V^\# \.
		\sigma \in V^*
		\iff
		\forall v \in V \.
		\sigma(v) + \sigma(-v) = 0
	}
	\Explain{1 $(\Rightarrow)$ is obvious}
	\Explain{2 $(\Leftarrow)$}
	\Explain{2.1 Assume $\sigma(v) + \sigma(-v) = 0$ holds}
	\Explain{2.2 Then $\sigma(v) = -\sigma(-v)$}
	\Explain{2.3 So $\sigma$ is homogeneous}
	\Explain{2.4 $\sigma$ is additive}
	\Explain{2.4.1 Assume $v,w \in V$}
	\Explain{2.4.2 Then $\sigma(v) = \sigma(v + w - w) 
		\le \sigma(v + w) + \sigma(-w) = \sigma(v + w) - \sigma(w) $}
	\Explain{2.4.3 By rearanging inequalities $\sigma(v) + \sigma(w) \le \sigma(v + w)$}
	\Explain{2.4.4 But this is an inverse of Minkowski's inequality, so 
		$\sigma(v+w) = \sigma(v) + \sigma(w) $}
	\EndProof
	\\
	\DeclareFunc{auxiliaryConjugate}
	{
		\prod_{V \in \VS{\Reals}} \. V^\# \to V^\# 
	}
	\DefineNamedFunc{auxiliaryConjugate}{\sigma}{\sigma^\#}
	{
		\Lambda v \in V \. \inf \{  \sigma(v + w) - \sigma(w) | w \in V  \}
	}
	\\
	\Theorem{LinearIfMinimal}
	{
		\forall V \in \VS{\Reals} \.  V^*  = \min V^\#
	}
	\Explain{1 Take $f \in V^*$}
	\Explain{1.1 Assume $\sigma \in V^\#$ is such that $\sigma \le f$}
	\Explain{1.2 Then $f(v) \ge \sigma(v) \ge -\sigma(-v) \ge - f(-v) = f(v)$ for every $v \in V$}
	\Explain{1.3 So $f = \sigma$}
	\Explain{1.4 As $\sigma$ was arbitrary, this proves that $f$ is minimal}
	\Explain{2 Take $\sigma \in \min V^\#$}
	\Explain{2.1 Then $\sigma^\# = \sigma$ }
	\Explain{2.1.1 This holds as $\sigma^\# \le \sigma$ and $\sigma$ is minimal}
	\Explain{2.2 Note, that this implies that $\sigma(v) \le  
		\sigma\left(\frac{1}{2}v\right) - \sigma\left( -\frac{1}{2}v\right) $ for any $v \in V $}
	\Explain{ 2.3 which can be rewritten as   
		$
			\sigma\left(\frac{1}{2}v\right) \le \sigma\left( -\frac{1}{2}v\right)
		$
	}
	\Explain{ 2.4 Or as $v$ was arbitrary $\sigma(v) \le - \sigma(-v)$ which proves that $\sigma \in V^*$}
	\EndProof
	\\
	\Theorem{MinimalSublinearAlwaysExists}
	{
		\forall V \in \VS{\Reals} \.
		\forall \sigma \in V^\# \.
		\exists \tau \in \min V \.
		\tau \le \sigma
	}
	\Explain{This is Equivalent to Hahn-Banach Theorem}
	\EndProof
}\Page{
	\DeclareFunc{sublinearCell}
	{
		\prod V \in \VS{k} \.
		V^\# \to \Convex(V)
	}
	\DefineNamedFunc{sublinearCell}{\sigma}{\Cell(\sigma)}
	{
		\{ v \in V : \sigma(v) < 1 \}
	}
	\\
	\Theorem{SeparationAndDomination}
	{
		\forall V \in \VS{\Reals} \.
		\forall f \in V^* \setminus \{0\} \.
		\forall \sigma \in V^\#_+ \.
		f \le \sigma  \iff   \Cell(\sigma) f^{-1}\{1\} = 1
	}
	\Explain{1 $(\Rightarrow)$}
	\Explain{1.1 This is straightforward by inequality $f(v) \le \sigma(v) < 1$}
	\Explain{2 $(\Leftarrow)$}
	\Explain{2.1 Assume $v \in V$ such that $f(v) > \sigma(v) \ge 0$}
	\Explain{2.2 Then there is a scale $\lambda$ such that $f(\lambda v) = 1$}
	\Explain{2.3 But this means that 
		 $ \lambda \sigma(v) < \lambda f(v) = f(\lambda v) \le \sigma(\lambda v) = \lambda \sigma(v)$}
	\Exclaim{2.4 But this is impossible}
	\EndProof
	\\
	\Theorem{ConrinuityAndDomination}
	{
		\forall V \in \TVS{\Reals} \.
		\forall f \in V^* \setminus \{0\} \.
		\forall \sigma \in V^\#_+ \cap \TOP(V,\Reals) \.
		f \le \sigma  \Imply f \in V'
	}
	\Explain{1 Take $U \in \U_\Reals(0)$}
	\Explain{2 Then there is a balanced $W \in \U_\Reals(0)$ such that $W \subset U$}
	\Explain{3 By continuity there is $O \in \U_V(0)$ such that $\sigma(O) \subset W$}
	\Explain{4 Select Balanced $E \in \U_V(0)$ such that $E \subset O$}
	\Explain{5 Then $f(E) \subset W \subset U$}
	\Explain{5.1 Assume $v \in E$}
	\Explain{5.2 If $f(v) = 0$ then $f(v) \in W$, so assume that $f(v) \neq 0$}
	\Explain{5.3 Then either $f(v) > 0$ or $f(-v) > 0$}
	\Explain{5.4 So either $ 0 \le f(v)  \le \sigma(v)$ or $0 \le f(-v) \le \sigma(-v)$}
	\Explain{5.5 And as $E$ is balanced this means that either $f(v) \in W$ or $f(-v) \in W$}
	\Explain{5.6 But as $W$ is also balanced and $-f(v) = f(-v)$ it always must be thes case 
		that $f(v) \in W$ }
	\Explain{6 Continuity at $0$ of $f$ proves global continuity}
	\EndProof
	\\
	\Theorem{InverseMinkowskiIneq}
	{
		\forall V \in \VS{k} \.
		\forall \sigma \in V^\# \.
		\forall v,w \in V \.
		\sigma(v) - \sigma(w) \le \sigma(v - w)
	}
	\Explain{1 write $\sigma(v) = \sigma(v -w + w) \le \sigma(v - w) + \sigma(w)$}
	\Explain{2 By rearanging the inequlity $\sigma(v) - \sigma(w) \le \sigma(v - w)$}
	\EndProof
	\\
	\Theorem{SublinearUniformContinuityCriterion}
	{
		\NewLine ::		
		\forall V \in \TVS{k} \.
		\forall \sigma \in V^\# \.
		\sigma \in C_0(V) \Imply \sigma \in \UNI(V,\Reals)
	}
	\Explain{ Obvious}
	\EndProof
}\Page{
	\Theorem{PositiveSublinearContinuity}
	{
		\NewLine ::
		\forall V \in \TVS{k} \.
		\forall \sigma \in V^\#_+ \.
		\sigma \in \UNI(V,\Reals) \iff 
		\Cell(\sigma) \in \T(V)
	}
	\Explain{1 $(\Rightarrow)$}
	\Explain{1.1 This follows directly from topological definition of continuity}
	\Explain{2 $(\Leftarrow)$}
	\Explain{2.1 Assume $(\Delta,v)$ is a net in $V$ such that $\lim_{\delta \in \Delta} v_\delta = 0$}
	\Explain{2.2 Then $v_\delta \in  \lambda \Cell_V$ for all sufficiently large $\delta$ 
		and any $\delta \in \Reals_{++}$}
	\Explain{2.3 But this means that $\sigma(v_\delta) < \lambda$, so  
		$\lim_{\delta \in \Delta} \sigma(v_\delta) = 0$}
	\Explain{2.4 This proves uniform continuity }
	\EndProof
	\\
	\Theorem{ContinuousGauge}{
		\forall V \in \TVS{k} \.
		\forall C : \Convex(V) \cap \U_0(V) \.
		\gamma(\bullet|C) \in \UNI(V,\Reals) 
	}
	\Explain{This follows by the previous theorem}
	\EndProof
	\\
	\Theorem{OpenConvexRepresentation}
	{
		\NewLine ::		
		\forall V \in \TVS{k} \.
		\forall C : \Convex \And \TYPE{NonEmpty} \And \T(V) \.
		\exists \sigma \in V^\#_+ \And \UNI(V,\Reals) \.
		\exists v \in V \.
		C = v + \Cell(\sigma)
	}
	\Explain{This follows by the previous theorem}
	\EndProof
}
\newpage
\subsubsection{Geometric Interpretation}
\Page{
	\Theorem{GeometricRealHahnBanachTheorem}
	{
		\NewLine :: 		
		\forall V \in \TVS{\Reals} \.
		\forall C : \Convex \And \T(V) \.
		\forall A \subset_{k\hyph\mathsf{AFF}} V \.
		\forall \aleph : CA = \emptyset \. \NewLine \.
		\exists H : \TYPE{Hyperplane}(V) \.
		A \subset H \And CH = \emptyset
	}
	\Explain{1 Without loss of generality assume $A \subvec{k} V$}
	\Explain{2 Represent $C$ as $v + \Cell(\sigma)$ with $\sigma \in V^\#_+ \And \UNI(V,\Reals)$ 
		and $v \in V$}
	\Explain{3 Note, that (1) implies that $v \neq 0$, furthermore $v \not \in A$}
	\Explain{4  By separation and domination theorem $\sigma(a - v) \ge 1$ for any $a \in A$}
	\Explain{5 define $f(a + \alpha v) = - \alpha$ on $A \oplus kv$}
	\Explain{6 $f \le \sigma$ on $A \oplus kv$}
	\Explain{6.1 $f(a + \alpha v) = - \alpha \le 0 \le \sigma(a + \alpha v)$ if $\alpha \le 0$ }
	\Explain{6.2 $f(a + \alpha v) = - \alpha \le -\alpha\left( \alpha^{-1} a + v\right) 
			\le \sigma f(a + \alpha v) $ if $\alpha > 0$ }
	\Explain{7 Construct an extension $F$ of $f$ dominated by $\sigma$ by Hahn-Banach}
	\Explain{8 Then using $H = \ker F$ produces the desired result}
	\EndProof
	\\
	\Theorem{GeometricComplexHahnBanachTheorem}
	{
		\NewLine :: 		
		\forall V \in \TVS{\Complex} \.
		\forall C : \Convex \And \T(V) \.
		\forall A \subset_{k\hyph\mathsf{AFF}} V \.
		\forall \aleph : CA = \emptyset \. \NewLine \.
		\exists H : \TYPE{Hyperplane}(V) \.
		A \subset H \And CH = \emptyset
	}
	\Explain{1 Treat $V$ as a real vector space and construct $H'$ as in the previous theorem}
	\Explain{2 Then $H = H' \cap \i H'$ is a desired complex hyperplane}
	\EndProof
	\\
	\Theorem{PlaneOpenConvexSetSeparationReal}
	{
		\NewLine ::
		\forall V \in \TVS{\Reals} \.
		\forall C : \Convex \And \T(V) \.
		\forall A \subvec{k} V \.
		\forall \aleph : CA = \emptyset \. \NewLine \.
		\exists f \in V' \. f(A) = 0 \And \forall x \in C \. f(x) > 0 
	}
	\Explain{1 Just use the functional $-F$ of geometric Hahn-Banach theorem}
	\Explain{2 $F(H) = 0$, so $F(A) = 0$}
	\Explain{3 $-F$ is positive on $C$}
	\Explain{3.1 $v \in C$ and we know that  $-F(v) = 1$}
	\Explain{3.2 If $x \in C$, then $[v,x] \subset C$}
	\Explain{3.3 So, if $f(x) < 0$ there exists a midpoint $u \in [v,x]$ such that $f(u) = 0$
		by intermidiate value theorem}
	\Explain{3.4 But this means that $u \in CH$, which is imposible by construction}
	\EndProof
	\\
	\Theorem{PlaneOpenConvexSetSeparationComplex}
	{
		\NewLine ::
		\forall V \in \TVS{\Complex} \.
		\forall C : \Convex \And \T(V) \.
		\forall A \subvec{k} V \.
		\forall \aleph : CA = \emptyset \. \NewLine \.
		\exists f \in V' \. f(A) = 0 \And \forall x \in C \. \Re f(x) > 0 
	}
	\NoProof
}\Page{
	\Theorem{PlanePointSeparationTheorem}
	{
		\forall V \in \LCS{k} \.
		\forall A \subset_{\TVS{k}} V \.
		\forall v \in A^\c \.
		\exists f \in V' \. f(A) = 0 \And f(v) \neq 0 
	}
	\Explain{1 As $A$ is closed and $V$ is locally convex there exists a convex set $C \in \U_V(A)$
		such that $CA = \emptyset$}
	\Explain{2 Apply separation theorem to $A$ and $C$}
	\EndProof
	\\
	\Theorem{AbundanceOfContinuousFunctionals}
	{
		\forall V \in \LCS{k} \.
		\forall v \in \Big(\cl\{0\}\Big)^\c \.
		\exists f \in V' \. f(v) \neq 0
	}
	\Explain{Apply previous theorem to $\cl\{0\}$ and $v$}
	\EndProof
	\\
	\Theorem{ContinuousDualSeparetesLocallyConvexSpace}
	{
		\forall V \in \LCHS{k} \.
		\TYPE{Separates}(V,V')
	}
	\NoProof
	\\
	\Theorem{ContinuousDualIsTotal}
	{
		\forall V \in \LCHS{k} \.
		\TYPE{Total}(V,V')
	}
	\NoProof
	\\
	\Theorem{NontrivialDual}
	{
		\forall V \in \TVS{k} \.
		V' \neq \{0\} \iff
		\exists U \in \U_V(0) \. \Convex(V,U) \And U \neq V
	}
	\NoProof
	\\
	\Theorem{VectorValuedCauchyIntegralTheorem}
	{
		\NewLine 		
		\forall V \in \LCHS{\Complex} \.
		\forall (D,C) : \TYPE{JordanArc} \.
		\forall v  \in \TOP(D \cup C,V) \.
		\forall \aleph : \TYPE{Analytic}(v,D) \.
		\int_C v(s)ds = 0
	}
	\Explain{Take $f \in V'$}
	\Explain{Then $f(v)$ is analytic}
	\Explain{ Then $f\left( \int_C v(s)ds\right) = \int_C f\Big(v(s)\Big)ds = 0$
		by normal cauchy intergral theorem}
	\Explain{ But as $V'$ is total this means that $\int_C v(s)ds = 0$}
	\EndProof
}
\newpage
\subsubsection{From Geometry to Analysis}
\Page{
	\Theorem{GeneralHahnBanachTheorem}
	{
		\forall V \in \VS{\Reals} \.
		\forall p  : \Convex(V,V) \.
		\forall U \subvec{\Reals} V \.
		\forall f \in U^* \. \NewLine \.
		\forall [0] : f \le p \. 
		\exists F \in V^* : 
		F_{|U} = f \And F \le p
	}
	\Say{C}{\Big\{ (v,\alpha) \in V \times \Reals : \alpha > p(v) \Big\}}{?(V \times \Reals)}
	\AssumeIn{(v,\alpha),(w,\beta)}{C}
	\AssumeIn{t}{[0,1]}
	\Say{[1]}{\bd \CF(V,V)(p)(v,w,t)}
	{ p\Big(tv + (1-t)w \Big) \le t p(v) + (1-t)p(w) < t\alpha + (1 -t)\beta   }
	\Conclude{\Big[\big((v,\alpha),(w,\beta)\big).*\Big]}
	{ \ByConstr C [1]  }{ t(v,\alpha) + (1-t)(w,\beta) \in C}
	\Derive{[1]}{\bd^{-1} \Convex}{\TYPE{Convex}(C)}
	\Say{A}{\Big\{ (u,f(u)) \Big| u \in f(u) \Big\}}
	{
		\TYPE{VectorSubspace}(V\times\Reals)
	}
	\Say{[2]}{\ByConstr A \ByConstr C}{A \cap \core C = \emptyset}
	\Say{[3]}{\bd \CF(V,V)(p)\ByConstr C}{\core C \neq \emptyset}
	\Say{\Big(H,[4]\Big)}{\THM{SeparationTHM}(V \times \Reals,C,A)[2][3]}
	{
		\sum H : \TYPE{Hyperplane}(V\times\Reals) \. 
		\TYPE{Separates}(V\times\Reals,H,C,A)
	}
	\Say{[5]}{\bd \TYPE{Separates} [4]}{ A \subset H}
	\Say{\Big(g,r,[6]\Big)}{\bd \TYPE{Hyperplane}(V\times\Reals,H)}
	{
		\sum g \in (V \times \Reals)^* \. H = \H(g,r)
	}
	\Say{\Big(h,\gamma, [7] \Big)}{\bd (V \times \Reals)^*}
	{
		\sum h \in V^* \. \sum \gamma \in \Reals^\times \. 
		\forall (v,\alpha) \in V \times \Reals \. 
		g(v,\alpha) = h(v) + \gamma\alpha
	}
	\Say{[8]}{[5][6][7]}{\forall u \in U \. h(u) + \gamma f(u) = r}
	\Say{[9]}{[8](0)}{r = 0}
	\Say{[10]}{\bd \Field \Reals[8]}{ \forall u \in U \. f(u) = \frac{1}{\gamma} (r-h(u)) }
	\Say{F}{-\frac{1}{\gamma}h}{V^*}
	\Assume{v}{V}
	\Say{[11]}{\bd \TYPE{Separates}[4][6][7][9]}{h(v) + \gamma p(v) \ge 0}
	\Conclude{[v.*]}{\ByConstr F [11]}
	{
		F(v) = - \frac{1}{\gamma} h(v) \le p(v)
	}
	\DeriveConclude{[*]}{\bd^{-1} \TYPE{Ineq} }{ F \le p}
	\EndProof
}\Page{
	\Theorem{DieodonneConvexExtensionTHM}
	{
		\forall V \in \VS{\Reals} \.
		\forall p  : \Convex(V,V) \.
		\forall U \subvec{\Reals} V \. \NewLine \.
		\forall f : \Convex(V,U) \. 
		\forall [0] : f \le p \. 
		\exists F \in \Convex(V,V) : 
		F_{|U} = f \And F \le p
	}
	\Say{C}{\Big\{ (v,\alpha) \in V \times \Reals : \alpha > p(v) \Big\}}{\Convex(V \times \Reals)}
	\Say{C'}{\Big\{ (u,\alpha) \in U \times \Reals : \alpha > f(u) \Big\}}{\Convex(U \times \Reals)}
	\AssumeIn{u}{U}
	\Say{[1]}{\ByConstr C}{(u,f(u)) \in  \boundary C'}
	\Say{\Big(H',[2]\Big)}{\THM{ClosedSupportExists}(U\times\Reals,C',u)}{
		\sum H' : \TYPE{Hyperplane}(U\times\Reals) \. 
		\TYPE{Supports}(V,H',C')
	}
	\Say{[3]}{\ByConstr C \bd \TYPE{Supports}[2]}{C \cap H' = \emptyset}
	\Say{H,[4]}{\THM{ConvexBodyBound}(V,H')}
	{
		\sum H : \TYPE{Hyperplane}(V \times \Reals) \.
		\TYPE{Bounds}(V,H,C)
	}
	\Conclude{E_u}{\Big\{ (v,\alpha) \in V\times\Reals \Big| \exists (v,h) \in H : \alpha \le h \Big\}}
	{\Convex(V\times\Reals)}
	\Derive{\Big(E,[1]\Big)}{\Intro\Act{\prod}}{
		\prod_{u \in U} 
		\sum E_u : \TYPE{Convex}(V\times\Reals) \. 
		\TYPE{Bounds}(V,\lin E_u,C) \And \NewLine \And
		\TYPE{Supports}\Big(V,\lin E_u \cap U\times\Reals,\lin C',(u,f(u))\Big)
	}
	\Say{D}{\bigcap_{u \in U} E_u}{\Convex(V)}
	\Say{[2]}{\ByConstr D [1]}{ C \subset D}
	\Say{F}{
		\Lambda v \in V \. 
		\inf \Big\{ \alpha \in \Reals \Big| (v,\alpha) \in D  \Big\} 
	}
	{       
		V \to \Reals
	}
	\Say{[3]}{\ByConstr F \ByConstr D[1]}{F_{|U} = f}
	\Say{[4]}{\ByConstr F \ByConstr D[2]}{F  \le p}
	\Conclude{[*]}{\bd \Convex(V,D) \ByConstr F}{\CF(V,V,F)}
	\EndProof
}
\newpage
\subsubsection{Smooth Norms}
\Page{ 
	\DeclareType{SmoothAtPoint}
	{
		\prod V \in \TVS{k} \.
		\prod C \in \Convex \.
		?\boundary C
	}
	\DefineType{p}{SmoothAtPoint}
	{
		\# \TYPE{Support}(V,C,p) = 1
	}
	\\
	\DeclareType{SmoothBody}
	{
		\prod V \in \TVS{k} \. ?\Convex 
	}
	\DefineType{C}{SmoothBody}
	{
		\forall p \in \boundary C \. \TYPE{SmoothAtPoint}(p)
	}
	\\
	\DeclareType{SmoothNorm}
	{
		\prod V \in \TVS{k} \. \TYPE{Norm}(V) \to ?V
	}
	\DefineType{\nu}{SmoothNorm}
	{
		\TYPE{SmoothBody}(V,\Cell(\nu))
	}
	\\
	\Theorem{SmmothNormIfDifferentiable}
	{
		\NewLine ::		
		\forall V \in \TVS{k} \. 
		\forall \nu : \TYPE{Norm}(V) \.
		\TYPE{SmoothNorm}(V,\nu)
		\iff
		\nu \in \mathsf{Diff}(V,V\setminus \{0\},\Reals)        
	}
	\NoProof
}
\newpage
\subsubsection{Sandwich Theorems}
\Page{
	\DeclareFunc{combinedAuxilarlyFunctional}
	{
		\prod_{V \in \VS{\Reals}}
		\prod_{ \sigma \in V^\#} 
		\prod_{X \subset V}
		\prod_{f : X \to \Reals}
		(f \le \sigma) \to  (V \to \Reals)
	}
	\DefineNamedFunc{combinedAuxilarlyFunctional}{\aleph}{(\sigma,f)_X^\#}
	{
		\Lambda v \in V \. \inf \{ \sigma(v + \lambda x) - \lambda f(x)  | x \in X, \lambda \in \Reals_{++}\}
	}
	\Explain{
		$
			\sigma(v + \lambda x) - \lambda f(x) \ge  \sigma(\lambda v)  - \sigma(-v) - \lambda f(x) =
			-\sigma(-v)  + \lambda(\sigma(x) - f(x)) \ge - \sigma(-v)
		$
	}
	\Explain{So $(\sigma,f)_X^\#(v) \ge -\sigma(-v) > - \infty$ and this means that
		$(\sigma,f)_X^\#$ is well defined }
	\EndProof
	\\
	\Theorem{combinedAuxilarlyFunctionalBound1}
	{	
		\NewLine ::		
		\forall V \in \VS{\Reals} \.
		\forall \sigma\in V^\# \.
		\forall X \subset V \.
		\forall f : X \to \Reals  \.
		\forall \aleph  : f_{|X} \le \sigma \.
		(\sigma, f)_X^\# \le \sigma
	}
	\Explain{
			$
				(\sigma, f)_X^\#(x) \le  
				\sigma(v + \lambda x) - \lambda f(x) \le    
				\sigma(v) + \lambda \sigma(x) -\lambda f(x)  = 
				\sigma(v) + \lambda \big( \sigma(x) - f(x) \big)
			$
	}
	\Explain{
		By taking $\lambda \to 0$ one gets $(\sigma, f)_X^\#(v) \le \sigma(v)$
	}
	\EndProof
	\\
	\Theorem{combinedAuxilarlyFunctionalBound2}
	{	
		\NewLine ::		
		\forall V \in \VS{\Reals} \.
		\forall \sigma\in V^\# \.
		\forall X \subset V \.
		\forall f : X \to \Reals  \.
		\forall \aleph : f_{|X} \le \sigma \. \NewLine \.
		\forall h \in V^* \.
		h \le (\sigma, f)_X^\#
		\iff
		f \le h_{|X} \And h \le \sigma 
	}
	\Explain{1 $(\Rightarrow)$ assume $h \le (\sigma, f)_X^\#$}
	\Explain{1.1 $ h(x) =  -h(-x) \ge - (\sigma, f)_X^\#(-x) \ge 
	 -\sigma(-x + x)  +  f(x) = f(x) $ for any $x \in X$}	
	\Explain{1.2  $h \le (\sigma, f)_X^\# \le \sigma$  }
	\Explain{2 $(\Leftarrow)$ assume $f \le h_{|X}$ anf $h \le \sigma$}
	\Explain{2.1
		Write
		$
			\sigma(v + \lambda x) - \lambda f(x) \ge 
			h( v + \lambda x) - \lambda h(x) = h(v) 		
		$}
	\Explain{ 2.2
		Then by taking infimum $ (\sigma,f)^\#_X(v) \ge h(v)$ 
	}
	\EndProof
	\\
	\Theorem{combinedAuxilarlyFunctionalBound2}
	{	
		\NewLine ::		
		\forall V \in \VS{\Reals} \.
		\forall \sigma\in V^\# \.
		\forall X : \Convex(V) \.
		\forall f : \TYPE{Concave}(V,V) \.
		\forall \aleph : f_{|X} \le \sigma \. \NewLine \.
		(\sigma,f)^\#_X \in V^\#
	}
	\Explain{ 1 Positive homogenety is obvious}
	\Explain{ 2 So we investigate subadditivity}
	\Explain{ 2.1 Select $v,w \in V$}
	\Explain{ 2.2
		Also select $\alpha,\beta \in \Reals_{++}$ and $x,y \in X$}
	\Explain{ 2.3 $\lambda = \frac{\alpha}{\alpha + \beta} \in \Reals_{++}$}
	\Explain{ 2.4 Then $u = \lambda x + (1 - \lambda)y \in X$ by convexity of $X$}
	\ExplainFurther{
			2.5 Then
			$
				\sigma(v + \alpha x) - \alpha f(x) +
				\sigma(w + \beta y) - \beta f(y) \ge$ (by subbaditivity of $\sigma$)}
  \ExplainFurther{ 
				$\ge \sigma(v + w + \alpha x + \beta y) -  (\alpha + \beta) \lambda f(x) 
				- (\alpha + \beta)(1 -\lambda) f(y) \ge$ (by concavity of $f$)  }
	\Explain{ 
				$\ge \sigma( v + w + (\alpha + \beta)u) - (\alpha + \beta) f(u) \ge 
				(\sigma,f)^\#_X(v + w)$}
\Explain{ 2.6 By taking infimum of both summands separadly one getas 
	$(\sigma,f)^\#_X(v + w)  \le (\sigma,f)^\#_X(v) + (\sigma,f)^\#_X(w)$   }
\EndProof
}\Page{
	\Theorem{SandwichTheorem}
	{
		\forall V \in \VS{\Reals} \.
		\forall \sigma\in V^\# \.
		\forall X : \Convex(V) \.
		\forall f : \TYPE{Concave}(V,V) \.
		\forall \aleph : f_{|X} \le \sigma \. \NewLine \.
		\exists  h \in V^* \.
		f \le h_{|X} \And h \le \sigma 
	}
	\Explain{1 In the conditions of the theorem the fucntional $(\sigma,f)^\#_X$ is sublinear}
	\Explain{2 So by Hahn Banach theorem there are an extension $h$ of $0$ dominated by 
		$(\sigma,f)^\#_X$}
	\Explain{3 But the bounding theorems above imply that $f \le h_{|X}$ and  $h \le \sigma$ }
	\EndProof
}
\newpage
\subsubsection{Paired Spaces and  Weak Topologies}
\Page{
	\Conclude{\PS}
	{
		\sum_{V,W\in\VS{k}} \L(V,W;k)
	}{\Type}
	\\
	\DeclareFunc{pairing}{\prod (V,W,B) : \PS(k) \to \L(V,W;k)}
	\DefineNamedFunc{pairing}{}{\Lambda v \in W \. w \in W \. \langle v, w \rangle}{B}
	\\
	\DeclareType{DistinguishesPoints}
	{
		 ? \PS(k)
	}
	\DefineType{(V,W,\ldots)}{DistinguishesPoints}
	{
		\forall w \in W \. w \neq 0 \Imply \exists  v \in V \.  \langle v, w \rangle \neq 0 
	}
	\\
	\DeclareType{DualPair}
	{
		 ? \PS(k)
	}
	\DefineType{(V,W,B)}{DualPair}
	{
		\TYPE{DistinguishesPoints}(V,W,B) \And \TYPE{DistinguishesPoints}(W,V,\FUNC{swap}B) 
	}
	\\
	\DeclareFunc{naturalMap}{\prod (V,W,\ldots) : \PS(k) \.  \VS{k}(W,V^*)}
	\DefineNamedFunc{naturalMap}{w}{ w^*}{\Lambda v \in V \. \langle v, w \rangle }
	\\
	\Theorem{DualSpaceHasInjectiveNaturalMap}
	{
		\forall (V,W,\ldots) : \DP \.       
		\TYPE{Injective}\Big(W, V^*, \bullet^*\Big)
	}
	\Explain{ Obvious}
	\EndProof
	\\
	\DeclareFunc{algebraicDualPair}{\VS{k} \to \DP(k)}
	\DefineNamedFunc{algebraicDualPair}{V}{(V,V^*)}{\Lambda v \in V \. \Lambda f \in V^* \. f(v) }
	\\
	\DeclareFunc{subalgebraicDualPair}{\prod_{V \in \VS{k}} \TYPE{Total}(V) \to \DP(k)}
	\DefineNamedFunc{algebraicDualPair}{V,U}{(V,U)}{\Lambda v \in V \. \Lambda f \in U \. f(v) }
	\\
	\DeclareFunc{analyticDualPair}{\LCHS{k} \to \DP(k)}
	\DefineNamedFunc{analyticDualPair}{V}{(V,V')}{\Lambda v \in V \. \Lambda f \in V^* \. f(v) }
	\\
	\DeclareFunc{weakTopology}{\prod (V,W,\ldots) \to \Top(V)}
	\DefineNamedFunc{weakTopology}{}{\sigma(V,W)}{\W_V(W,k,\bullet^*)}
	\\
	\DeclareFunc{weakStarTopology}{\prod (V,W,\ldots) \to \Top(V)}
	\DefineNamedFunc{weakStarTopology}{}{\sigma(W,V)}{\W_W(V,k,\bullet^*)}
	\\
	\Theorem{DualPairsHasHausdorffTopology}
	{
		\forall (V,W,\ldots) : \DP \. \TYPE{T2}\Big(V,\sigma(V,W)\Big) \And \TYPE{T2}(W,\sigma(V,W))
	}
	\Explain{ Obvious}
	\EndProof
}\Page{
	\Theorem{WeakConvergence}
	{
		\forall V \in \TVS{k} \.
		\forall (\Delta,v) : \TYPE{Net}(V) \.
		\forall w \in V \.
		\lim_{\delta \in \Delta} v_\delta =_{\sigma(V,V')} w \iff \NewLine \iff
		\forall f \in V' \.
		\lim_{\delta \in \Delta} f(v_\delta) = f(w)
	}
	\Explain{ Straightforward properties of the weak topology}
	\EndProof
	\\
	\Theorem{OrthogonalSequenceWeaklyConvergesToZero}
	{
		\forall V \in \HIL{k} \.
		\forall e : \TYPE{Orthogonal}(\Nat,V) \.
		\lim_{n \to \infty} e_n =_{\sigma(V,V')} 0
	}
	\Explain{ 1 Take $f \in V^*$}
	\Explain{ 2 By Hilbert space theory there is a representation $f=\langle \bullet, v \rangle$ for 
		some $v \in V$}
	\Explain{ 3
		By Bessel's inequality $\sum_{n=1} \Big|\langle e_n, v \rangle\Big| \le \| v \| < + \infty$	
	}
	\Explain{ 4 This implies that $f(e_n) = \langle e_n, v \rangle \to 0$}
	\Explain{ 5 As $f$ was arbitrary by the previous theorem this implies the weak convergence}
	\EndProof
	\\
	\DeclareType{WeakCauchyNet}{\prod (V,W,\ldots) : \PS \. ?\TYPE{Net}(V)}
	\DefineType{(\Delta,v)}{WeakCauchyNet}{
		\forall w \in W \. 
		\TYPE{CauchySequence}\Big(k,(\Delta,\langle v, w \rangle)\Big)}
	\\
	\DeclareType{WeaklyCompleteSpace}{?\PS}
	\DefineType{(V,W,\ldots)}{WeaklyCompleteSpace}{
		\forall (\Delta,v) : \TYPE{WeakCauchyNet}(V,W,\ldots) \.
		\TYPE{Convergent}\Big( V,\sigma(V,W), (\Delta,v) \Big)		
		}
	\\
	\Theorem{WeakBoundednessTheorem}
	{
		\NewLine ::		
		\forall (V,W,\ldots) : \DP \.
		\forall A \subset V \.
		\TYPE{Bounded}\Big(V,\sigma(V,W),A\Big) \iff \TYPE{TotallyBounded}\Big(V,\sigma(V,W),A\Big)
	}
	\Explain{ 1 $(\Rightarrow)$  Assume $A$ is weakly bounded}
	\Explain{ 1.1 Take $U \in \U_{V,\sigma(V,W)}(0)$}
	\ExplainFurther{ 1.2 There is a finite number of $w  : \{1,\ldots,n\} \to W$ 
		and $I : \{1,\ldots,n\} \to \U_k(0)$ such that} 
	\Explain{$\quad E =  \bigcap^n_{i=1} w^{*-1}_i(I_i)  \subset U$}
	\Explain{1.3 As $A$ is bounded there is a scalar $\lambda \in \Reals_{++}$
		such that $A \subset \lambda E =  \bigcap^n_{i=1} w^{*-1}_i(\lambda I_i)$}
	\Explain{1.4 As $(V,W)$ is a dual pair for each $w_i$ to select $v_i$
		such that $\langle w_i,v_i \rangle  > 0$ and $v_i \in U$}
	\Explain{1.5 Then for every $i \in \{1,\ldots,n\}$ there is some
		$m_i \in \Nat$ such that $\langle w_i,v_i \rangle m_i \ge 
			\sup \Big\{ |\alpha| \Big| \alpha \in \lambda I_i   \Big\}$ 
	}
	\Explain{
		1.6 Then  
		$
				A \subset \lambda E \subset				
				U + \sum^n_{i=1} \sum^m_{j=0} j v_i $}
	\Explain{
		1.7 So $A$ is totally Bounded
	}
	\Explain{
		2 $(\Leftarrow)$ this direction holds in any topology}
	\EndProof
}\Page{
	\Theorem{AlgebraicDualIsWeaklyStarComplete}
	{
		\NewLine ::		
		\forall V \in \VS{k} \.
		\TYPE{WeaklyComplete}(V^*,V)
	}
	\Explain{ 1 Assume $(\Delta,f)$ is weakly Cauchy in $V$}
	\Explain{ 2 Then, define $g(v) = \lim_{\delta \in \Delta} f_\delta(v)$}
	\Explain{ 2.1 This is possible as $k$ is complete}
	\Explain{ 3 Then $g \in V^*$}
	\EndProof
	\\
	\Theorem{WeakPepresentationTheorem}
	{
		\NewLine::		
		\forall (V,W,\ldots) : \PS  \.
		\forall f \in \TVS{k}\bigg(\Big(V,\sigma(V,W)\Big), k \bigg) \. \exists w \in W \. f = w^* 
	}
	\Explain{1 Assume $f$ as in the hypothesis}
	\Explain{2 Define siminorm $\phi = \Lambda v \in V \. |f(v)|$}
	\Explain{3 By hypothesis $\phi$ is continuous}
	\Explain{4 Then $\Cell(\phi) \in \U_V(0)$}
	\ExplainFurther{5 So by definition of weak topology 
		there exists $u : \{1,\ldots,n\} \to W$  and $I : \{1,\ldots,n\} \to \U_k(0)$}
	\Explain{ such that 
		$\bigcap^n_{i=1} u^{*-1}_n(I_n) \subset \Cell(\phi)$}
	\Explain{6 By Vector Spaces theorem 1.3 Span by Kernel Containments $f \in \Span(u^*)$}
	\Explain{7 But this means that that there is $w \in W$ such that $f = w^*$}
	\EndProof
	\\
	\DeclareFunc{leftOrthogonal}
	{
		\prod (V,W,\ldots) : \PS(k) \. ?V \to ?W
	}
	\DefineNamedFunc{leftOrthogonal}{A}{A^\bot}{\Big\{ w \in W \. \forall a \in A \. w^*(a) = 0\Big\}}
	\\
	\DeclareFunc{rightOrthogonal}
	{
		\prod (V,W,\ldots) : \PS(k) \. ?W \to ?V
	}
	\DefineNamedFunc{rightOrthogonal}{A}{A^\bot}{\Big\{ v \in V \. \forall a \in A \. a^*(v) = 0\Big\}}
	\\
	\Theorem{WeakDualRepresentation}
	{
		\forall (V,W,\ldots) : \PS(k) \. 
		\Big(V,\sigma(V,W)\Big)' \cong_{\TVS{K}} \frac{W}{V^\bot}
	}
	\Explain{Follows from previous theorem and the isomorphism theorem}
	\EndProof
}
\newpage
\subsubsection{Polarity}
\Page{
	\DeclareFunc{leftPolar}
	{
		\prod (V,W,\ldots) : \PS(k) \. ?V \to \TYPE{Disc}(W)
	}
	\DefineNamedFunc{leftPolar}{A}{A^\circ}{\Big\{ w \in W \. \forall a \in A \. |w^*(a)| \le 1\Big\}}
	\\
	\DeclareFunc{rightPolar}
	{
		\prod (V,W,\ldots) : \PS(k) \. ?W \to \TYPE{Disc}(V)
	}
	\DefineNamedFunc{rightPolar}{A}{A^\circ}{\Big\{ w \in W \. \forall a \in A \. |a^*(w)| \le 1\Big\}}
	\\
	\Theorem{WeeklyBoundedIffAbsorbentPolar}
	{
		\forall (V,W,\ldots) : \PS(k) \. 
		\forall A \subset V \. \NewLine \.
		\TYPE{Bounded}(V,\sigma(W,C),A)
		\iff
		\TYPE{Absorbent}(W,A^\circ)
	}
	\Explain{ Pretty obvious}
	\EndProof
	\\
	\Theorem{WeeklyClosedPolars}
	{
		\forall (V,W,\ldots) : \PS(k) \. 
		\forall A \subset V \. \NewLine \.
		\TYPE{Closed}(W,\sigma(W,C),A^\circ)
	}
	\Explain{ Pretty obvious}
	\EndProof
	\\
	\Theorem{PolarMonotonicity}
	{
		\forall (V,W,\ldots) : \PS(k) \. 
		\forall A,B \subset V \. \NewLine \.
		A \subset B \Imply B^\circ \subset A^\circ
	}
	\Explain{ Pretty obvious}
	\EndProof
	\\
	\Theorem{PolarScaling}
	{
		\forall (V,W,\ldots) : \PS(k) \. 
		\forall A \subset V \. \NewLine \.
		\forall \alpha \in k \.
		(\alpha A)^\circ = \alpha A^\circ  = |\alpha| A^\circ
	}
	\Explain{ Use the fact that $A$ is a disc, hence balanced}
	\EndProof
	\\
	\Theorem{BipolarSubset}
	{
		\forall (V,W,\ldots) : \PS(k) \. 
		\forall A \subset V \. \NewLine \.
		A \subset A^{\circ \circ}
	}
	\Explain{ Pretty obvious}
	\EndProof
	\\	
	\Theorem{TripolarStability}
	{
		\forall (V,W,\ldots) : \PS(k) \. 
		\forall A \subset V \. \NewLine \.
		A^{\circ \circ \circ} = A^{\circ}
	}
	\Explain{ Pretty obvious}
	\EndProof
}\Page{
	\Theorem{BalancedHullPolar}
	{
		\forall  (V,W,\ldots) : \PS(k) \.
		\forall  A \subset V \.
		A^\circ = (\bal A)^\circ
	}
	\Explain{ Pretty obvious}
	\EndProof
	\\
	\Theorem{ConvexHullPolar}
	{
		\forall  (V,W,\ldots) : \PS(k) \.
		\forall  A \subset V \.
		A^\circ = (\conv A)^\circ
	}
	\Explain{ Pretty obvious}
	\EndProof
	\\
	\Theorem{PolarClosure}
	{
		\forall  (V,W,\ldots) : \PS(k) \.
		\forall  A \subset V \.
		A^\circ = ({\cl}_{\sigma(V,W)} A)^\circ
	}
	\Explain{ Pretty obvious}
	\EndProof
	\\
	\Theorem{PolarFullClosure}
	{
		\forall  (V,W,\ldots) : \PS(k) \.
		\forall  A \subset V \.
		A^\circ = ({\cl}_{\sigma(V,W)} A)^\circ
	}
	\Explain{ Pretty obvious}
	\EndProof
	\\
	\Theorem{BipolarTheorem}
	{
		\forall (V,W,\ldots) : \PS(\Complex) \.
		\forall A \subset V \.
		A^{\circ \circ}  = {\cl}_{\sigma(V,W)} \conv \bal A
	}
	\Explain{ 1 It follows from the general definition of hulls that 
		${\cl}_{\sigma(V,W)} \conv \bal A \subset A^{\circ \circ}$}
	\Explain{ 1.2 Any polar set is a weakly closed disc}
	\Explain{ 2 Assume $u \in ({\cl}_{\sigma(V,W)} \conv \bal A)^\c$}
	\ExplainFurther{ 3 Then by Hahn-Banach there exists a real functional $f \in (V,\sigma(V,W))'$} 
	\Explain{	such that $\alpha  = \sup f({\cl}_{\sigma(V,W)} \conv \bal A) < f(u)$}
	\Explain{
		4  Without loss of generality assume $\alpha = 1$
	}
	\Explain{
		4.1  $0 \in {\cl}_{\sigma(V,W)} \conv \bal A$ as this set obiously balanced
	}
	\Explain{ 4.2 So $f(u) > 0$ and we can compute a renormalization $\frac{f}{\alpha}$}
	\Explain{ 5  Define complex functional $g(v) = f(v) - \i f(\i v)$}
	\Explain{ 6  By representation theorem there is $w \in W$ such that $g = w^*$}
	\Explain{ 7 It follows that $w \in A^\circ$}
	\Explain{ 8 By (3) and (7) it follows that $\langle u, w \rangle > 1$, so $u \not \in A^{\circ \circ}$}
	\EndProof
	\\
	\Theorem{UnionPolar}
	{
		\forall (V,W,\ldots) : \PS(k) \.
		\forall I \in \SET \.
		\forall A : I \to ?V \.
		\left( \bigcup_{i \in I} A_i \right)^\circ=  \bigcap_{i \in I} A_i^\circ
	}
	\Explain{ Pretty straightforward}
	\EndProof
}\Page{
	\Theorem{IntersectionPolar}
	{
		\NewLine ::
		\forall (V,W,\ldots) : \PS(\Complex) \.
		\forall I \in \SET \.
		\forall A : I \to \Closed(V,\sigma(V,W)) \And \TYPE{Disc}(V) \. \NewLine \.
		\left( \bigcap_{i \in I} A_i \right)^\circ=  {\cl}_{\sigma(V,W)} \conv \bal \bigcup_{i \in I} A_i^\circ
	}
	\Explain{ 
		$
			\left( \bigcap_{i \in I} A_i \right)^\circ =
			\left( \bigcap_{i \in I} A_i^{\circ \circ} \right)^\circ =
			\left( \bigcup_{i \in I} A_i^{\circ} \right)^{\circ\circ} =
			\cl_{\sigma(V,W)} \conv \bal \bigcup_{i \in I} A_i^\circ
		$ by the use of the bipolar theorem}
	\EndProof
	\\
	\Theorem{BanachAlaogluTHM}
	{
		\forall V \in \TVS{k} \.
		\forall N \in \N_V(0) \.
		\Compacts\Big(W, \sigma(V',V), N^\circ\Big)
	}
	\Explain{ 1 $U$ is absorbent}
	\Explain{ 2 $U \subset U^{\circ \circ}$}
	\Explain{ 3 From (1) and (2) $U^{\circ \circ}$ is absorbent}
	\Explain{ 4  This implies that $U^\circ$ is weakly bounded}
	\Explain{ 5 As $(V,V')$ is a dual pair $U^\circ$ is actually totally bounded}
	\Explain{ 6 Moreover, it also totally bounded in $V^*$}
	\Explain{ 7 As polars in $V'$ and $V^*$ coincide it must the case that $U$ is algebraically compact}
	\Explain{ 8 But then it is also weakly compact}
	\EndProof
}
\newpage
\subsubsection{Polar Topologies}
\subsubsection{Orthogonality}
\subsubsection{Adjoints}
\subsubsection{Conjugates}
\subsubsection{Constructions}
\subsubsection{Open Maps}
\subsubsection{HBEP}
\subsubsection{Extreme Points}
\subsubsection{Krein-Milman Theorems}
\subsubsection{The Choquet Boundary}
\subsubsection{Banach-Stone Theorem}
\subsubsection{Non-Archimedean Case}
\subsection{Barelled Spaces}
\subsection{Bornological Spaces}
\subsection{Towards Approximation Theory}
\section{Spaces of Distributions}
\newpage
\section{Ordered Topological Vector Spaces}
\subsection{Reisz Spaces and Banach Lattices}
\subsubsection{Order Unit Norm}
\Page{
	\Theorem{OrderUnitDefinesASublinear}
	{
		\NewLine ::		
		\forall V : \OVS(\Reals) \. 
		\forall u : \OU(V) \.
		\TYPE{Sublinear}(V, \Lambda v \in V \. \inf \{ \lambda \in \Reals_{++} : v \le \lambda u \} )
	}
	\Explain{ 1 Write $\omega(v) = \inf \{ \lambda \in \Reals_{++} : v \le \lambda u \}$}
	\Explain{ 2 Obviously $\omega$ is positively homogeneous}
	\Explain{ 3 Now take $v,w \in V$}
	\Explain{ 3.1 Define $\alpha = \omega(v) + \omega(w)$}
	\Explain{ 3.2 Then $ v + w \le \Big(\omega(v) + \omega(w)\Big)u = \alpha u$}
	\Explain{ 3.3 So $\omega(v + w) \le \alpha = \omega(v) + \omega(w)$ }
	\EndProof
	\\
	\DeclareFunc{orderUnitFunctional}
	{
		\prod V : \OVS(\Reals) \. 
		\OU(V) \to \TYPE{Sublinear}(V)
	}
	\DefineNamedFunc{orderUnitFunctional}{u}{\omega_u}
	{\inf \{ \lambda \in \Reals_{++} : v \le \lambda u \}}
	\\
	\DeclareFunc{orderUnitSeminorm}
	{
		\prod V : \AVS(\Reals) \. 
		\OU(V) \to \SMN(V)
	}
	\DefineNamedFunc{orderUnitFunctional}{u}{\nu_u}
	{\Lambda v \in V \. \max\Big(\omega_u(v),\omega_u(-v)\Big)}
	\\
	\Theorem{UnitDiscIsAnInterval}
	{
		\forall V : \AVS(\Reals) \.
		\forall u : \OU(V) \.
		\Disc(\nu_u) = [-u,u] 
	}
	\Explain{1 Obvious}
	\EndProof
}
\newpage
\subsubsection{Topological Vector Lattices}
\Page{
	\DeclareType{TopologicalVectorLattice}
	{
		? \TVS{\Reals} \And \RS
	}
	\DefineType{V}{TopologicalVectorLattice}
	{
		\Closed(V,\C_V) \And \NewLine \And 
		\exists \B : \NbhdBase(V,0) \.
		\forall B \in \B \.
		\TYPE{OrderConvex}(V,B) 
	}
	\\
	\DeclareType{BanachLattice}
	{
		? \NS \And \RS
	}
	\DefineType{V}{BanachLattice}
	{
		\forall v,w \in V \. 
		|v| \le |w| \Imply \|v\| \le \|w\|  
	}
	\\
	\DeclareType{MSpace}
	{
		? \NS \And \RS
	}
	\DefineType{V}{MSpace}
	{
		\forall v,w \in V_+ \. 
		\| v \vee w \| = \|v\| \vee \|w\|
	}
	\\
	\DeclareType{LSpace}
	{
		? \NS \And \RS
	}
	\DefineType{V}{LSpace}
	{
		\forall v,w \in V_+ \. 
		\| v + w \| = \|v\| + \|w\|
	}
}
\newpage
\subsubsection{Lattice of Continuous Functions}
\Page{
	\Theorem{ExtremallyDisconnected}
	{ 
		\NewLine ::		
		\forall X \in \TOP \.
		\ED(X) \iff 
		\forall U,V \in \T(X) \.
		UV = \emptyset 
		\Imply
		\cl_X U \cl_X V = \emptyset 
	}
	\\
	\Theorem{OrderCompletenessOfContinuousFunctions}
	{
		\NewLine ::		
		\forall X \in \ED \. 
		\OComplete\Big( C(X) \Big)
	}
	\NoProof
	\\
	\Theorem{OrderCompletenessOfContinuousFunctions}
	{
		\NewLine ::		
		\forall X : \TYPE{T3.5} \. 
		\OComplete\Big( C(X) \Big)
		\Imply
		\ED(X)
	}
	\NoProof
}
\newpage
\section*{Sources}
\begin{enumerate}
\item Shaeffer H.H - Topologival Vector Spaces (1966)
\item Horvath H. - Topological Vector Spaces and Distributions (1966)
\item K\"othe G. - Topological Vector Spaces (1969)
\item Trevis F.  - Topological Vector Spaces, Distributions and Kernels (1970)
\item Grothendieck A. - Topological Vector Spaces (1973)
\item Hogbe-Nlend H.  - Bornologies and Functional Analysis (1977)
\item Wilansky A. - Modern Methods in Topological Vector Spaces (1978) 
\item Rudin W.  - Functional Analysis (1991) 
\item Fabian M. et al.   - Functional Analysis and infinite-dimensional geometry (2001)
\item Peter Schneider - Nonarchimedean FUnctional Analysis (2005)
\item Charalambos D.A. ; Tourky R. - Cones and Duality (2007)
\item Fremlin T. - Measure Theory 35: Riesz Spaces (2009)
\item Naricci L. ; Beckenstein E. - Topological Vector Spaces I (2010)
\item Perez-Garcia C. ; Schikhof W. H. - Locally Convex Spaces over Non-Archimedean Valued Fields (2010)
\item  . ;  . ; C . . -     (2012)
\item Ptotasov I. V. - Notes on Bornology
\item Chernikov A. ; Mennin A.  -  Combinatorial properties of non-archimedean convex sets  (2021)
\end{enumerate}
\end{document}